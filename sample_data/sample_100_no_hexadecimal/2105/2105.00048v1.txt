Learning fluid physics from highly turbulent data using sparse physics-informed
discovery of empirical relations (SPIDER)
Daniel R. Gurevich
Program in Applied and Computational Mathematics,
Princeton University, Princeton, NJ 08544, USA

Patrick A. K. Reinbold

arXiv:2105.00048v1 [physics.flu-dyn] 30 Apr 2021

Data, Analytics, and Computational Intelligence,
Lowe's Companies, Inc., Mooresville, NC 28117, USA

Roman O. Grigoriev
School of Physics, Georgia Institute of Technology, Atlanta, GA 30332, USA
(Dated: May 4, 2021)
We show how a complete mathematical description of a complicated physical phenomenon can
be constructed from observational data via a hybrid approach combining three simple and general
ingredients: physical assumptions of smoothness, locality, and symmetry, a weak formulation of
differential equations, and sparse regression. To illustrate this, we extract a complete system of governing equations describing flows of incompressible Newtonian fluids – the Navier-Stokes equation,
the continuity equation, and the boundary conditions – from numerical data describing a highly
turbulent channel flow in three dimensions. The hybrid approach is remarkably robust, yielding
accurate results for very high noise levels, and should thus work equally well for a wide range of
experimental data. In addition, this approach provides easily interpretable information about the
relative importance of different physical effects (such as viscosity) as well as useful insight into the
quality of the data, making it a useful diagnostic tool.

Physical theories are traditionally constructed in an iterative manner. At each step, discrepancies between predictions and existing experimental observations are used
to improve the theory, making it more general and accurate. These improvements are usually instructed and
constrained by first principles, including both general and
domain knowledge. After this, new predictions are made
and new experiments are designed to test these predictions, closing the loop. Humans play a key role in all
aspects of this traditional procedure and can become a
weak link when the amount of data becomes overwhelming or the patterns in the data are too complex.
Recent advances in machine learning have started to
change the scientific paradigm guiding the construction
of physical theories by gradually taking humans out of
the loop. For low-dimensional systems, physical relations
in the form of algebraic and even differential equations
can be constructed using symbolic regression directly
from experimental data without using any physical intuition [1–3]. For high-dimensional systems, purely datadriven approaches become intractable, and some physical intuition becomes necessary to guide the process [4].
The question is therefore what physical considerations
can and should be used to constrain the problem sufficiently for the data-driven analysis to become tractable
while leaving enough freedom to enable identification of
physically meaningful relationships.
For instance, an equation describing the evolution of
momentum for a weakly turbulent flow in a thin layer of
fluid could be identified from either synthetic [5] or exper-

imental data [6] after the form of the equation was constrained by a few extremely general physical constraints:
smoothness, locality, and the relevant symmetries. For
nonrelativistic systems, the symmetries include translations in time and Euclidean symmetry (translations,
rotations, and reflections) in space. In fact, many of
these constraints have been implicitly assumed in most
efforts to identify evolution equations from synthetic data
generated by a variety of canonical PDEs [7–11]. However, evolution equations are just one type of a relation
that may be required to fully describe a physical process. Other examples include physical constraints, such
as energy and mass conservation for an inviscid, incompressible fluid or the curl-free condition for the electric
field in electrostatics, as well as boundary conditions.
In this letter, we introduce a flexible data-driven approach for identifying a complete mathematical description of a physical system, which we call sparse physicsinformed discovery of empirical relations (SPIDER). We
illustrate SPIDER by discovering the evolution equations, constraints, and boundary conditions governing
the flow of an incompressible Newtonian fluid from noisy
data using only the assumptions of smoothness, locality, and symmetry. To enable this, the data have to
exhibit sufficient variation to sample the state space of
the physical problem [12]. Here, this is accomplished by
using the numerical solution of a high-Reynolds number flow through a rectangular channel from the Johns
Hopkins University turbulence database [13]. The data
set includes the flow velocity u and pressure p fully re-

2

1

0.2

0

0

-0.2

-1
4

5

6

FIG. 1: Snapshot of the spanwise velocity uz over a
portion of the entire domain. Sample integration
domains (shown as dotted boxes) near the edge of the
channel are much narrower than those in the center due
to the non-uniform grid spacing in the y direction.

solved in space and time. The channel dimensions are
Lx × Ly × Lz × Lt = 8π × 2 × 3π × 26 (in nondimensional units) and the data are stored on a spatiotemporal
grid of size 2048 × 512 × 1536 × 4000. The viscosity is
ν = 5 × 10−5 and the corresponding friction Reynolds
number is Reτ ∼ 1000. A representative snapshot of the
data is shown in Figure 1.
The immense size of the entire data set comprising
2.6×1013 "measurements" illustrates the challenges faced
by a purely data-driven approach. The locality property
radically reduces the number of possible functional relations between measurements by constraining these to a
small spatiotemporal neighborhood of a given point. In
particular, for smooth continuous fields, such functional
relations have to be expressed in terms of their values and
partial derivatives. For systems that are invariant with
respect to spatial and temporal translation, a functional
relation can be expressed in the form of Volterra series
X

cn fn = 0

(1)

n

where cn are coefficients and fn are multiplicative functions of the fields and their partial derivatives. For systems with translational symmetry in space and time, the
most general relations of this type are nonlinear partial
differential equations (PDEs) with constant coefficients.
Most prior work focused on evolution equations, which
are special cases of (1) where c1 = 1 and f1 is the firstorder temporal derivative of one of the fields. Other
special cases include differential equations that do not

involve temporal derivatives and algebraic relations between the fields that involve no derivatives at all.
Our aim here is to identify a parsimonious mathematical model of the flow in the form of a system of PDEs
involving the velocity and pressure fields, u and p, with
appropriate boundary conditions. The key observation
here is that the form of the functional relations (1) can
be restricted sufficiently using the rotational symmetry
constraint. All terms fn have to transform in the same
way under rotations and reflections, with the transformation rule corresponding to a particular representation
of the rotational symmetry group. For instance, for nonrelativistic systems, the symmetry group involves rotations about any axis in three-dimensional space, with the
representations corresponding to tensors of various ranks.
Here we will restrict our attention to the two lowest rank
tensors, i.e., scalars and vectors, although the same approach is trivially extended to tensors of any rank.
In the present problem, the data consist of a scalar
field p and a vector field u. The differential operators
that transform as a scalar and a vector, respectively, are
∂t and ∇. Using these objects, we can construct tensors
of any rank as tensor products. For instance, the terms
u, ∂t u, and ∇p all transform as vectors. To illustrate
the procedure, we will restrict the terms fn to be at most
cubic in p, u, ∂t , and ∇, which yields a scalar equation
c1 p + c2 ∇ * u + c3 ∂t p + c4 p2 + c5 u2
+ c6 (u * ∇)p + c7 ∇2 p + c8 ∂t (p2 ) + c9 ∂t2 p
2

(2)

2

+ c10 p(∇ * u) + c11 u p + c12 ∂t (u ) = 0
and a vector equation
c1 u + c2 ∂t u + c3 ∇p + c4 pu + c5 (u * ∇)u + c6 ∇2 u
+ c7 ∂t2 u + c8 u2 u + c9 p2 u + c10 ∇(p2 ) + c11 u(∇ * u)
+ c12 ∇u2 + c13 ∇(∇ * u) + c14 p∂t u + c15 u∂t p = 0.
(3)
Reflection symmetry ensures that pseudovectors such as
∇ × u do not appear in the latter equation. These two
PDEs will form the libraries of the candidate relations
describing fluid physics in the bulk. It is straightforward
to expand these by including higher-order terms.
Parsimonious scalar and vector relations between velocity and pressure can be identified by performing sparse
regression using the libraries (2) and (3), respectively.
Terms involving higher-order derivatives, such as ∇2 p
and ∇2 u, can be very sensitive to noise [9, 14], which
is present in any experimental measurements. To make
the regression more robust, we use the weak form of both
PDEs following the approach introduced in our earlier
work [15]. Specifically, we multiply each equation by
a smooth weight function wj (x, t) and then integrate
it over a rectangular spatiotemporal domain Ωk of size
Hx × Hy × Hz × Ht (cf. Table I). The derivatives are
shifted from the data (u and p) onto the weight func-

3
Hx
Hy
Hz
Ht
edge 1/3 (27) 1/50 (34) 1/5 (33) 1/4 (38)
center 1/3 (27) 1/5 (32) 1/5 (33) 1/4 (38)

TABLE I: Dimensions of the integration domains Ωk in
physical units and grid points (in parentheses).

tions wj whenever possible via integration by parts, after which the integrals are evaluated numerically using
trapezoidal quadratures. For equation (2), we use scalar
weight functions of the form
wj (x, t) = w̃j1 (x̄)w̃j2 (ȳ)w̃j3 (z̄)w̃j4 (t̄),
w̃l (s) = (s2 − 1)β Pl (s),

(4)

where Pl is the lth Legendre polynomial and the bar denotes nondimensionalization relative to the size of the integration domain, e.g., x̄ = 2(x − xk )/Hx . Here we chose
l = 0 or 1 for each of the coordinate directions, yielding
2d+1 different weight functions for an integration domain
with one temporal and d spatial dimensions. We choose
β = 6 to (i) ensure that all the boundary terms vanish
after integration by parts and (ii) increase the accuracy
of numerical quadrature [15]. To integrate (3), we instead use vector weight functions wji (x, t) = wj (x, t)î for
i = 1, * * * , d varying over the indices of the spatial dimensions, resulting in a total of d 2d+1 different weight
functions.
By repeating this procedure for a number of integration domains Ωk centered at different locations and for
different weight functions wj , the problem of determining
the unknown coefficients c = [c1 , * * * , cN ] is recast as the
solution of an overdetermined linear system of the form
Qc = 0,

(5)

where Q = [q1 . . . qN ] and the columns qn correspond to
the integrals of the terms fn in (1). We sampled the data
using 30 rectangular domains chosen to lie either in the
center or at the edge of the channel, as shown in Fig. 1,
and randomly distributed in the spanwise (z), streamwise
(x), and temporal directions, yielding 30 × 2d+1 linear
equations on the coefficients cn in (2) and 30d × 2d+1
linear equations on the coefficients in (3).
Solutions of (5) have a degree of freedom corresponding to the normalization of c, which is conventionally
eliminated by setting one of the coefficients, say c1 , to 1.
However, we generally cannot guarantee that any given
term is present in the correct sparse model. Instead, we
treat all of the terms on even footing and compute c
as the right singular vector of Q corresponding to the
smallest singular value. In fact, this is the solution of a
constrained least squares problem for QT Qc = 0:
c = arg min kQT Qck.
kck=1

(6)

It is worth noting that, when multiple singular values of
Q are small, there may be several "good" solutions for c.
In order to obtain a parsimonious model, we must find
a sparse coefficient vector c∗ such that the residual kQc∗ k
is comparable to the residual kQck with c given by (6).
If the parsimonious model contains multiple terms, it can
usually be identified by an iterative greedy algorithm. At
each iteration, we use the singular value decomposition
of Q(N ) = [q1 . . . qN ] to find c(N ) as described previously. We also compute the residual η (N ) = kQ(N ) c(N ) k.
Next, we consider all of the candidate models formed
by dropping one of the terms and eliminating the corresponding column from Q(N ) . We select the candidate
model with N − 1 terms that achieves the smallest residual and then repeat until only one term remains. This
yields a sequence of increasingly sparse models described
by N -dimensional coefficient vectors cN (forming an approximately Pareto optimal set [16]).
There are many reasonable ways to select a final model
from this collection based on the trade-off between their
parsimony (i.e., number of terms N ) and accuracy, quantified by the residuals η (N ) . For instance, one might select
the simplest model which achieves a relative residual of
less than, say, 1% or the model for which discarding a
single term results in the largest relative increase in the
residual. In this letter, we follow Ref. [15]: specifically,
we choose the model described by the coefficient vector
c(N ) where N = max{n : η (n) /η (n−1) > γ}, where the parameter γ = 3 was selected empirically. This procedure
was repeated for 10 replications with random choices of
domain locations and, for noisy data, realizations of noise
in order to verify that the results are reproducible.
To test the effects of noise on the results of sparse
regression, in addition to the original simulation data, we
also used synthetic data with varying levels of additive
white Gaussian noise. Specifically, we define the noisy
data by pσ = p + σN1 sp and uσ = u + σ diag{N2 }su ,
where σ is the scalar noise level (ranging from 0 to 50%).
N1 and the three components of N2 are independently
sampled standard normal random variables at each point
in space and time, and sp and su are the sample standard
deviations of the pressure and each component of the flow
velocity computed across the original dataset.
Figure 2 illustrates the sparsification of the vector relation (3) for a representative distribution of integration
domains (with d = 3). Both near the wall of the channel
and in the center, the residual η remains nearly constant
until only four or five terms remain and grows quickly
when more terms are discarded. In the noiseless case
shown in Figure 2(a), the magnitude of the residual for
N > 5 is essentially determined by the discreteness of the
data (both in the numerical simulations and in evaluating
the integrals using quadratures) [15]. In the noisy case,
shown in Figure 2(b), the magnitude of the residual is
determined by the level of noise and is higher than in the
noiseless case, as expected. However, qualitatively, the

4

1

1

10-1

10-1

Euler
Navier-Stokes

10

-2

10

-3

10

-4

10

Navier-Stokes

-2

Augmented NS
10-3

1

5

10

9

(a)

-4

1

5

9

(b)

FIG. 2: Dependence of the residual kQck on the number of terms N retained in the vector relation (3) for (a)
noiseless data and (b) data with 50% noise. Black (white) squares represent data collected near the edge (in the
middle) of the channel. The models selected by the greedy algorithm in each case are shown by the arrows.

dependence of η on the number of terms N remaining in
the model is the same in all of the cases.
The relations selected by the greedy algorithm are
summarized in Table II, which shows the surviving terms
fn , their coefficients cn , and the respective contributions
of different terms in each relation. The table also shows
the standard deviation of the coefficients found across different replications. For data from the edge of the channel,
sparse regression consistently identifies the Navier-Stokes
equation with correct coefficients, including the viscosity
ν, for noise levels up to at least 50%. For data from the
middle of the channel with low noise (up to ∼4%), sparse
regression yields the Navier-Stokes equation with an additional, linear term, which is discussed further below.
For more noisy mid-channel data with σ up to 48%, the
Euler equation, also with correct coefficients, is reconstructed instead.
While the greedy sparsification algorithm was found
to be well-suited for identifying relations involving multiple terms, it fails for single-term relations. This difficulty, which is not adequately addressed by past sparse
regression literature, is illustrated well by the regression
problem for the scalar library (2). The data describe an
incompressible fluid, for which
∇*u=0

(7)

As a result, the terms ∇ * u, u(∇ * u), and ∇(∇ * u) in
(2) all have very small magnitudes and are thus quickly
discarded from the library by the greedy algorithm. For
this reason, we start by computing the magnitude kqn k
of each term, which equals the residual of the corresponding single-term model. Comparing kqn k with the residual
η for the identified multi-term model allows determination of whether the parsimonious relation should include
one or several terms. With this enhancement, SPIDER

correctly identified the continuity equation (7) from the
scalar library (2) for data from either the edge or the
center of the channel, across all replications and for all
noise levels up to the maximum, σ = 50%.
SPIDER can also be used to discover boundary conditions. In this case the rotational symmetry is partially
broken: instead of rotations in all three spatial directions, the problem is only invariant with respect to rotations about the normal n to the boundary. The library
of terms that transform as vectors near the boundary include n in addition to u and ∇. We exclude time derivatives, because these can be eliminated with the help of
the bulk equations. We also exclude the dependence on p
to keep the library to a reasonable size (this dependence
is trivial to restore). Retaining terms that contain each
of u and ∇ at most once yields a vector equation
c1 u + c2 n + c3 (u * n)n + c4 ∇(u * n)
+ c5 (n * ∇)u + c6 n(∇ * u) = 0

(8)

Next we separate the normal and tangential components
by applying the projection operators P⊥ = nn and Pk =
1 − nn to the library (8), where nn represents the tensor
product of the normals. We eliminate all terms which
have identically vanishing projections. Furthermore, we
can also eliminate all terms involving ∇ * u, since we have
already identified the continuity equation (7).
Since the boundary conditions only hold on the solid
walls y = ±1, each projection of the relation (8) is integrated over rectangular (2 + 1)-dimensional domains Ωk
of size Hx × Hz × Ht constrained to one of the walls.
Respectively, the weight functions wj are constructed as
products of three one-dimensional functions w̃l (s) where
s = x̄, z̄, or t̄. Note that the derivatives of the data
with respect to the wall-normal (y) coordinate cannot be
eliminated using integration by parts in this case; instead,

5
σ
∂t u (u * ∇)u
∇p
∇2 u
c̄n 0% 0.999
1
0.995 −4.93 × 10−5
50% 1.002
1
0.989 −4.97 × 10−5
−4
−4
sn 0% 4×10
8×10
1×10−3
6×10−8
−3
−3
−3
50% 7×10
8×10
8×10
1×10−6
χn 0% 0.905
1
0.407
0.487
50% 0.908
1
0.405
0.489

σ
∂t u (u * ∇)u
c̄n 0% 1.000
1
48% 1.000
1
sn 0% 2×10−4 2×10−4
48% 1×10−2 1×10−2
χn 0% 0.987
1
48% 0.986
1

(a)

∇p
∇2 u
u
1.000 −5.26×10−5 −0.0022
0.998
0
0
3×10−4
4×10−7
7×10−6
3×10−2
0
0
0.0528
0.0027
0.0065
0.0529
0
0
(b)

TABLE II: Vector relations identified from data with different noise levels (described by σ) (a) near the edge of the
channel and (b) in the center. The rows show the mean values of the coefficients c̄n , their standard deviation sn ,
and the magnitudes of terms χn = kcn fn k (normalized relative to the largest term).

we evaluate them directly using finite differences. For all
noise levels up to the maximum σ = 50%, valid singleterm boundary conditions were always identified. Specifically, for the normal component, two equivalent relations
P⊥ u = P⊥ (u * n)n = u * n = 0 are identified. For the
tangential component, Pk u = 0 is identified. These can
be combined into the algebraically "simplest" boundary
condition u = 0, which is the well-known no-slip boundary condition.
As we have shown, physically-informed sparse regression can successfully identify a complete, quantitatively
accurate mathematical model of the fluid flow using a
tiny fraction of the available data, even when the data
are extremely noisy. In fact, at low noise levels, such
a model can be identified using only a single integration
domain in the bulk and its projection onto the boundary,
provided sufficiently many weight functions are used. In
particular, the no-slip boundary condition u = 0 and
the incompressibility condition (7) are always correctly
identified.
The most general vector relation identified is a generalization of the Navier-Stokes equation
∂t u + (u * ∇)u + ∇p − ν∇2 u − αu = 0,

(9)

with some nonnegative ν and α. The last two terms may
or may not be identified depending on the sampled region
of the flow and the magnitude of noise in the dataset.
The term ν∇2 u represents the effect of viscosity, which
is well-known to play an important role in the boundary
layer, as reflected by its large relative magnitude χn ≈
0.5 in that region. In fact, in the boundary layer, the
greedy algorithm selects the Navier-Stokes equation for
any level of noise with all of the terms having comparable
magnitudes, as shown in Table II.
In the center of the channel, the effect of viscosity is
negligible due to the lack of small-scale structures, so the
flow is described quite accurately by both the NavierStokes and the Euler equation. Indeed, in that region
of the flow, the dominant balance is between the terms
∂t u and (u * ∇)u, while the viscous term is more than
two orders of magnitude smaller. The linear term αu is
similarly small. It is then not surprising that, at higher

noise levels, the greedy algorithm discards both the viscous and the linear term, yielding the Euler equation.
The unexpected observation is the presence of the linear term αu, which does not appear in the Navier-Stokes
equation, in the relation identified from mid-channel data
with low levels of noise. This term is larger in magnitude
than the viscous term and is reliably identified by the
greedy algorithm regardless of the distribution of the integration domains or noise realization, suggesting that it
is not spurious. The sign of α indicates that this term
is destabilizing, unlike the viscous term, indicating a numerical instability in the simulation used to generate the
data. The computational grid is non-uniform in y and
is coarsest in the middle of the channel, which explains
why numerical instability is found there but not near the
wall of the channel.
In conclusion, it should be noted that other physical relations can also be identified using the approach outlined
here. For instance, the energy equation can be derived
by multiplying the vector relation (9) by u. It can also
be obtained from data by applying the greedy algorithm
to the scalar library (2), provided the latter is expanded
to include terms up to quadratic in both u and ∇.
To summarize, we have shown that a combination of
very general physical constraints, weak formulation of
PDEs, and sparse regression yields an extremely powerful model discovery tool, which we call SPIDER. It
allows one to identify complete and easily interpretable
quantitative mathematical models of continuum systems,
not limited to evolution equations, from even very noisy
data. Moreover, SPIDER provides information about the
relative importance of different physical phenomena and
can also serve as a valuable diagnostic tool for validating
and troubleshooting numerical simulations or experimental setups.
This material is based upon work supported by NSF
under Grants No. CMMI-1725587 and CMMI-2028454.

[1] J. P. Crutchfield and B. S. McNamara, Equation of motion from a data series, Complex systems 1, 417 (1987).

6
[2] J. Bongard and H. Lipson, Automated reverse engineering of nonlinear dynamical systems, Proceedings of the
National Academy of Sciences 104, 9943 (2007).
[3] M. Schmidt and H. Lipson, Distilling free-form natural
laws from experimental data, science 324, 81 (2009).
[4] A. Karpatne, G. Atluri, J. H. Faghmous, M. Steinbach,
A. Banerjee, A. Ganguly, S. Shekhar, N. Samatova, and
V. Kumar, Theory-guided data science: A new paradigm
for scientific discovery from data, IEEE Transactions on
knowledge and data engineering 29, 2318 (2017).
[5] P. A. Reinbold, D. R. Gurevich, and R. O. Grigoriev, Using noisy or incomplete data to discover models of spatiotemporal dynamics, Physical Review E 101, 010203
(2020).
[6] P. A. Reinbold, L. M. Kageorge, M. F. Schatz, and R. O.
Grigoriev, Robust learning from noisy, incomplete, highdimensional experimental data via physically constrained
symbolic regression, Nature Communications (2021), to
appear, arXiv:2102.12006.
[7] M. Bär, R. Hegger, and H. Kantz, Fitting partial differential equations to space-time dynamics, Physical Review
E 59, 337 (1999).
[8] D. Xu and O. Khanmohamadi, Spatiotemporal system
reconstruction using fourier spectral operators and struc-

ture selection techniques, Chaos 18, 043122 (2008).
[9] S. H. Rudy, S. L. Brunton, J. L. Proctor, and J. N. Kutz,
Data-driven discovery of partial differential equations,
Science Advances 3, e1602614 (2017).
[10] H. Schaeffer, Learning partial differential equations via
data discovery and sparse optimization, Proceedings of
the Royal Society A: Mathematical, Physical and Engineering Sciences 473, 20160446 (2017).
[11] M. Raissi and G. E. Karniadakis, Hidden physics models:
Machine learning of nonlinear partial differential equations, Journal of Computational Physics 357, 125 (2018).
[12] H. Schaeffer, G. Tran, and R. Ward, Extracting sparse
high-dimensional dynamics from limited data, SIAM
Journal on Applied Mathematics 78, 3279 (2018).
[13] Johns Hopkins turbulence database, channel flow, http:
//turbulence.pha.jhu.edu/Channel_Flow.aspx.
[14] P. A. Reinbold and R. O. Grigoriev, Data-driven discovery of partial differential equation models with latent
variables, Physical Review E 100, 022219 (2019).
[15] D. R. Gurevich, P. A. Reinbold, and R. O. Grigoriev,
Robust and optimal sparse regression for nonlinear pde
models, Chaos 29, 103113 (2019).
[16] K. Miettinen, Nonlinear multiobjective optimization,
Vol. 12 (Springer Science & Business Media, 2012).

