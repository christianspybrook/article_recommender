selfsupervised augmentation consistencyadapting semantic segmentationarxiv210500097v1 cscv 30 apr 2021nikita araslanov1stefan roth12department science tu darmstadtabstractmiou1 introductionunsupervised domain adaptation uda variantsemisupervised learning 6 available unlabelled data comes different distribution annotated dataset 4 case point exploit syntheticdata annotation accessible comparedcostly labelling realworld images 59 60success addressing uda semantic segmentation 67 69 80 91 developed methods growingincreasingly sophisticated combine style transfer networks adversarial training network ensembles39 46 68 77 increase model complexity impedesreproducibility potentially slowing progresswork propose uda framework reachingstateoftheart segmentation accuracy measuredintersectionoverunion iou incurring substantialtraining efforts goal adopt simple semisupervised approach selftraining 12 42 91 recent works conjunction adversarial trainingcode available httpsgithubcomvisinfdasachessianaimean iou cityscapes val adaptation gta5 vgg16499propose approach domain adaptation semantic segmentation practical highly accurate contrast previous work abandon usecomputationally involved adversarial objectives networkensembles style transfer instead employ standarddata augmentation techniques photometric noise flippingscaling ensure consistency semantic predictions image transformations developprinciple lightweight selfsupervised frameworktrained coevolving pseudo labels needcumbersome extra training rounds simple trainingpractitioners standpoint approach remarkably effective achieve significant improvements stateoftheart segmentation accuracy adaptation consistentdifferent choices backbone architectureadaptation scenariosselftrainingnumber roundsadversarial trainingensemble4362019423424pitfdatir422390372style transfer465449438sai2i55 cdamldr fada77 70lse 6520202021pycda 47figure 1 results preview unlike recent work combines multiple training paradigms adversarial trainingstyle transfer approach retains modest singleround training complexity selftraining improves state artadapting semantic segmentation significant marginnetwork ensembles 17 39 54 70 80 87 86 contrastuse selftraining standalone compared previous selftraining methods 9 43 65 91 92 approachsidesteps inconvenience multiple training roundsrequire expert intervention consecutiverounds train model coevolving pseudo labelsendtoend needmethod leverages ubiquitous data augmentationtechniques fully supervised learning 11 85 photometric jitter flipping multiscale cropping enforceconsistency semantic maps produced modelimage perturbations following assumption formalises key premiseassumption 1 let f m represent pixelwisemapping images semantic output m denotephotometric image transform similarly 0 spatial similarity transformation0 p control variables following predefined density p n 0 1 imagef invariant equivariant 0f f f 0 0 fintroduce training framework momentumnetwork slowly advancing copy original modelappear proceedings ieeecvf conference vision pattern recognition cvpr virtual 20212021 ieee personal use material permitted permission ieee obtained uses current future media includingreprintingrepublishing material advertising promotional purposes creating new collective works resale redistribution servers listsreuse copyrighted component work worksmomentum network provides stable recent targetsmodel updates opposed fixed supervisionmodel distillation 15 87 86 revisit problemlongtail recognition context generating pseudolabels selfsupervision particular maintainexponentially moving class prior discount confidence thresholds classes samplesincrease relative contribution training lossframework simple train adds moderate computationaloverhead compared fully supervised setup setsnew state art established benchmarks cf fig 1featurespitadversarial training1round trainingsotavggsotaresnetldrsai2iiastrpttable 1 relation state art previous work reachesstate art terms iou vgg16 sotavggresnet101 sotaresnet framework uses adversarial training multiple training rounds given parentheses outperforms state art consistently cases2 related workselftraining pseudo labels computationally lightweight approach selftraining seeks highqualitypseudo supervision coming form class predictionshigh confidence work belongs categoryprevious methods precompute labels offline subsequently update model repeatprocess rounds 43 65 91 92 recent frameworks following strategy compositenature rely adversarial pretraining 14 20 86style translation 17 80 54 46 39 70 73training coevolving pseudo labels computationally unstable requires additional regularisationchen et al 13 minimise entropy improved behaviour gradient near saturation pointsfixed representations frozen network 15 86fixed set global 53 selfgenerated local labels47 68 81 improves training robustnessoverconfident predictions 28 direct consequencesquality pseudo labels zou et al 92 attaindegree confidence calibration regularising lossprediction smoothing akin temperature scaling 28averaging predictions classifiers 87dropoutbased sampling 7 88 achieves goalwork scene adaptation semantic segmentation influenced parallel stream workdomain adaptation da semisupervised learningimage classification 23 24 27 45 50 main ideamethods formulate upper boundtarget risk socalled hhdivergence 3nutshell defines discrepancy marginalssource target data means binary classifierfollowing briefly review implementation variantsidea context semantic segmentationlearning domaininvariant representationsadversarial feature alignment follows gan framework 24 26 minimises gap sourcetarget feature representations terms distancewasserstein 41 discriminator employed multiple scales 15 67 77 use local spatial priors 83 conditional 33 classspecific22 52 align features hard easy targetsamples 56 selfsupervised losses entropyminimisation 69 conservative loss 90 assistalignmentalternative adversarial feature alignmentinterpretable constraints feature priors 51 bijective sourcetarget association 37 aligning domainsdirectly image space style transfer 89 74 commonly jointly adversarial feature alignment 8 16 25 55 78 79 82 issue style translation ensure semantic consistencydespite changes appearance address hoffman et al 32 use semantic cycleconsistency lossesyang et al 77 reconstruct original imagelabelspace representationmethods tend computationally costlychallenging train require concurrent trainingindependent networks discriminatorsstyle transfer networks yang soatto 80 obviate need style networks incorporating phasefouriertransformed target image source samplemultiple networks trained predefined phase bandspatial priors different da classificationcharacteristic feature adaptation methods segmentation use spatial priors local priorsenforced patchwise 15 47 68 form precomputed superpixels 81 83 global spatialpriors 91 success hingessimilarity semantic layout current benchmarksrelation approach shown table 1 workstreamlines training process use adversarial training feature invariance guarantee label invariance 36 84 second train modelcoevolving pseudo labels round framework bears resemblance noisy mean teacher 76combines consistency regularisation 2 61 64 75selfensembling 40 66 similar approaches explored medical imaging 44 58 concurrent udawork 71 albeit limited scope admissible aug2masksmomentum netmultiscalecrops flipsmultiscalefusioninput sampleinput batchoutput masksfused predictionpseudo labelsmomentum updatesgradientphotometricnoisesegmentation netmaskstarget lossframework overviewb multiscale crops flipsc multiscale fusionfigure 2 overview segmentation network framework maintains slow copy momentum networkprovides stable targets selfsupervision addition encouraging semantic invariance wrt photometric noise facilitateconsistent predictions multiple scales flips b feeding random multiscale crops flips momentum networkc fusing predictions simple averaging produce pseudosupervision targetsmentations leverage photometric invariance scaleflip equivariance 72 extract highfidelity pseudo supervision instead computationally expensive samplingtechniques 38 contrary 65 scalepredictive label quality averagepredictions produced multiple scales flips parallels uncertainty estimation testtime augmentation1 training time 5networks fig 2b demonstrates process following noisy student model image classification 76input segmentation network additionally undergoes photometric augmentation add random colourjitter smooth images gaussian filter random momentum network hand receivesclean input augmentationsencourage model invariance photometric perturbations33 selfsupervision3 selfsupervised augmentation consistencymultiscale fusion reproject output masksmomentum network original image canvassize h w illustrated fig 2c pixeloverlapping areas average predictions notepixels lie outside crops contain resultsingle forward pass original imagepredictions intact merged mapsextract pseudo masks selfsupervisionshort longtail interlude handling rare classesclasses training samples notoriously difficult recognition 29 semantic segmentationdistinguish classes low imageleveltruck bus pixellevel traffic lightpole frequency generating selfsupervisionspecial care cases encourage lowerthresholds selecting pseudo labels ii increasedcontributions gradient focal loss iii employ importance samplingsamplebased moving threshold previous workselftraining employs multiround training requires interrupting training process regeneratingpseudo labels 43 46 54 65 91 reasons need recompute thresholds filteringpseudo labels supervision requires traversing predictions complete target datasetmodel parameters fixed pursuit goal enablingendtoend training expert interventiondifferent approach compute thresholds onthegomain ingredient maintain exponentially moving class prior softmax predictionmomentum network compute prior estimate31 framework overviewshown fig 2a framework comprises segmentation network intend adapt target domainslowly changing copy updated momentummomentum network perform selfsupervised sceneadaptation supply batch random cropshorizontal flips sample image target domainnetworks pixel average predictionssemantic masks momentum networkappropriate inverse spatial transformation createpseudo ground truth selecting confident pixelsaveraged map thresholds based running statistics capable adapting individual samplesfinally segmentation network uses stochastic gradientdescent update parameters wrt pseudo labelsapproach closely resembles mean teacher framework 23 66 temporal ensembling 35 40empirically ensembling property plays auxiliary role importantly akincritic network reinforcement learning 48momentum encoder unsupervised learning 30 momentum network provides stable targets selfsupervisedtraining segmentation network view allowsfocus targetgenerating process detailed32 batch constructionsampled target image generate n cropsrandom scales flips locations preservingaspect ratio rescale crops original image fixed input resolution hw pass in3probability pixel sample n belongs class c1 xcnmcnijhw ij00200300434 trainingpretraining sourceonly loss following 47 83use adaptive batch normalisation abn 45 jumpstart model segmentation task minimisingcrossentropy loss source data experiments unnecessary recompute meanstandard deviation end traininginstead pretraining alternate batches sourcetarget images ignore loss targetbatch implies updating running mean standard deviation batch normalisation bn 34 layersleaving remaining model parameters untouchedimportance sampling loss function eq 6 accounts longtail classes high image frequencytraffic light pole effectiveclasses appearing samples bustrain alleviate imbalance use importancesampling 21 increase sample frequencylongtail classes minimise expected target lossresampling target images density ptmin enpt ltnfig 3 plots eq 3 function moving class prior cselection predominant classes roadexponential term nearly effect thresholdstatic wrt peak class confidence cn mcnlongtail classes c threshold lower upper bound pixelsclasses selected supervision obtainpseudo labels apply threshold cn peak predictions merged output momentum networkmc nij cnmnijignorec arg maxc mcnij dominant classpixel note pixels confidence values lowerthreshold nondominant predictionsignored selfsupervised lossfocal loss confidence regularisation loss function incorporates focal multiplier 49 increasecontribution longtail classes gradient signal unlike previous work 49 65 movingclass prior c regulates focal termltn m m mcn 1 c logmcn001figure 3 samplebased moving threshold thresholdingscheme hyperparameters examplemcn 1 075 predominant classes roadc fl 0 threshold approximates mcn longtailclasses traffic light c 0 thresholdsreduced steepness controlled eq 3hyperparameters mcn predicted peak confidence score class c0005001002samplebased moving threshold cn takes lower valuesmoving prior c 0 longtail classesbounded c 1 definecn 1 ec mcnmcn max mcnijmcn mask prediction class c resolution h w exponentially moving averagetraining iteration t momentum 0 1tc 1 cnobtain pt use pretrained segmentation networkprecompute cn class prior estimate image n eq 1 training time sample semantic class c uniformly ii obtain target samplel probabilitycl pn cnm prediction segmentation networkparameters pseudo label c derives m eq 5hyperparameter focal term recall lowvalues c signify longtail categoryhigher weight high values 1 increase relative weighting longtail classes setting 0disables focal term note regularise lossconfidence value momentum network mc neq 4 case incorrect pseudo label expectconfidence low regularise training owingcalibration multiscale fusion minimiseloss eq 6 applied pixel wrttwostep sampling process ensures imagesnonzero sample probability owing prevalent classescl 0 l road urban scenesjoint targetsource training train segmentationnetwork stochastic gradient descent crossentropy loss source focal loss targetinputb segmentation net outputc momentum net outputd fused predictione pseudo labelsfigure 4 selfsupervision example image sample crops segmentation network b tends mistake motorcyclebicycle momentum network c improves prediction produce inconsistent labelling averagingpredictions multiple scales d corrects inconsistency allowing produce highprecision pseudo labels e selfsupervisiondata sampled pt defined eqs 6 7 fig 4illustrates synthesis pseudo labels periodicallyupdate parameters momentum networkt1 t 1report results validation split measuresegmentation accuracy perclass intersectionoverunion iou average mean iou miou41 implementation detailsparameters segmentation networkregulates pace updates low values result fasterunstable training high leads prematuresuboptimal convergence moderateupdate momentum network t iterationsimplement framework pytorch 57 adoptdeeplabv2 10 segmentation architecture evaluate method backbones resnet101 31vgg16 63 following recent work 39 67 68 69 73backbones initialise models pretrainedimagenet 19 train models abn 45cf sec 34 implemented syncbn 57 multiscale crops resized 640 640 batch size 16training proceeds selfsupervised target losscf sec 33 batchnorm layers 34 frozenbatch size 16 comprises 8 source images 8 target images resolution 1024 512 common practice70 80 target batch contains image samples3 random crops n 3 sec 32downscaled factor 05 photometric noiseuse colour jitter random blur greyscaling appendix b details optimisation uses sgdconstant learning rate 25 104 momentum 09weight decay 5104 accumulate gradient alternating sourcetarget forward passes memoryfootprint check focal term eq 6 reducestarget loss magnitude wrt source loss scalefactor 5 2 vgg16 train vggbased framework titan x gpus 12gbresnetbased variant requires substantially reduced requirement compared recent work4 experimentsdatasets experiments use datasetscityscapes dataset 18 contains 2048 1024 imagesrealworld traffic scenes split 2975 images training 500 validation gta5 dataset 59 contains 24 966 synthetic scenes resolution 1914 1052pixelwise annotation aided gta5 game engineuse synthiarandcityscapes subsetsynthia dataset 60 contains 9400 synthetic images resolution 1280 760 semanticannotation compatible cityscapessetup adopt established evaluation protocolprevious work 47 67 69 synthetic traffic scenesgta5 59 synthia 60 serve sourcedata real images cityscapes datasettarget obviously ignoring available semantic labelsresults domain adaptation scenarios dependingchoice source data gta5 cityscapessynthia cityscapes previous work trainingtime use training split cityscapes datasetmethodroad sidew build wall fence pole light sign vegterrsky pers ridecar truck bus train moto bicymioucycada 32advent 69cbst 91pycda 47pit 53fda 80ldr 77fada 70cdam 78sai2i 55852869904867862861901923901911313264251289318303375326414409607702708588819736814853789823769815769804804817830835831812286240269152278337354361361372418422436438449465baselinesac815 286900 531795 232 211 313 282 185 756 149 722 580 171 811 197 263 137 129 21862 338 327 382 460 403 842 264 884 658 280 856 406 529 173 137 238371499pycda 47cdam 78fada 70ldr 77fda 80sai2i 55pit 53iast 54rpt 83905913925908925912875938892844845851847824852788851861493422395381464378499396568474492492495505504506515526baselinesac802 293904 539768 238 219 377 354 211 798 213 750 595 175 835 224 334 130 307 123866 424 273 451 485 427 874 401 861 675 297 885 491 546 98 266 453408538backbone vgg16372287508248350351412511467464765787720809821806822837827829218285183214311308303331342332150252273221204213291253279238171272302232275183285213206229203266294300335280330290215109141211285260230210220282805800824866793821841826844845505471426532521525542552555524145179232217243288258244171260188295240276244249218282172125224269305320374314448189307299206315117140205146297211252265backbone resnet101363460475414533433434578433324344376351265386312395395287297328275276259302267299346326334312364347363262402364358338380406413399431496315364184328389410420347331868845853856823855792849874379432377421398460371329385785830835849780865793880860623600632596626617654626644215322397344344338375290251856832875850849855832873885279350329428341344460392366348467478527531487456496458180169257232239229337349309277361235347365denotes use pspnet 85 instead deeplabv2 10table 2 perclass iou comparison gta5 cityscapes adaptation evaluated cityscapes validation setgta5 cityscapes table 2 method achievesclear improvement best published results 55 8334 12 vgg16 resnet101backbones respectively note rpt 83 sai2i55 substantially higher model complexity rpt83 uses pspnet 85 higher upper bounddeeplabv2 fully supervised setup 57iou pascal voc 85 requires extracting superpixels training encoderdecoder lstm increasing model capacity computational overheadsai2i 55 initialises stronger baseline bdl 46relies style transfer network adversarial training rpt 83 sai2i 55 require multiplerounds training 3 6 bdl 46 respectivelytrain target loss single pass notably compared previous best approach vgg resnetevaluation sai2i 55 improvement resnet101substantial 34 comparable respectivemargin vgg16fada 70 requires 4 tesla p40 gpus 24gb memory note momentum network evaluation mode gradient tracking disabled adds35 memory overhead momentum network fix 099 t 100 experiments hyperparameters use 099075 103 3 appendix c2 provideshyperparameter selection sensitivity analysis framework wrt inference follows usual procedure single forward passsegmentation network original image resolution postprocessing42 comparison state artcompare approach current stateart domain adaptation scenarios gta5cityscapes table 2 synthia cityscapestable 3 fair comparison numbers originatesinglescale inference cases approachdenoted sac selfsupervised augmentation consistency substantially outperforms baselinesourceonly loss model abn sec 34fact sets new state art terms miou importantly ranking previous works dependsbackbone choice source data reach rankconsistently settingssynthia cityscapes table 3 resultconsistent previous scenario approach attainsstateoftheart accuracy backbones improving76 14 vgg16 resnet101 backbonesbest results previously published 55 83method resnet101 outperforms previous bestmethod evaluation pycda 47 59 ioumethodmiou13miou359381395405408411415335 119 183 664 704 521 161 646 155 115 264382 413 279 808 830 643 212 783 385 326 621391562344491259218327343323385330313320439511447457278527561524525531551412440467452498512369 76 200 729 755 467 167 745 158 208 217430 455 320 871 893 636 254 869 356 304 530410593363526road sidew build wall fence pole light signvegskypers ridecarbus moto bicypycda 47pit 53fada 70fda 80cdam 78ldr 77sai2i 55806817804842730737791266269359351311296340745784809780771776783181198304270270260267808767818772812806810710741836796810818811480475489555590572555723760777748750761772225217311249263276235baselinesac607779269386671 83835 158advent 69pit 53pycda 47cdam 78fda 80ldr 77sai2i 55fada 70iast 54rpt 83856831755825793851877845819889422276309422350445497401415465797 87815 89833 208813732810816831 48833 177845 151baselinesac639893259472710 110855 265backbone vgg16137134113147159142174223221274266295190224168199256245219121196135143101136118181277179407474466475backbone resnet101264273183199164193201309395338335159240152185272288301804764847806617801811848834859841788850835826848837840850858579642641614614594587535655598238276254332311319318226308261733796850729839732733854865881364312452393408410479437382468142310212266384326371268331277denotes use pspnet 85 instead deeplabv2 10 miou13 average iou 13 classes excluding wall fence poletable 3 perclass iou comparison synthia cityscapes adaptation evaluated cityscapes validation setmiouconfiguration419435460473475480482483484493augmentation consistencymomentum net 0 t 1photometric noisemultiscale fusionfocal loss 0min entropy fusion vs averagingclassbased thresholding 0confidence regularisationimportance samplinghorizontal flipping499framework vgg16setting vgg16 backbone independentlyswitch component report results table 4components augmentation consistencymomentum network play crucial role disablingmomentum network leads 64 iou decreaseabolishing augmentation consistency leads drop80 iou recall augmentation consistency comprises augmentation techniques photometric noisemultiscale fusion random flipping assessindividual contributions training photometric jitter deteriorates iou severely 39compared disabling multiscale fusion 26flipping 06 hypothesise encouraging modelrobustness photometric noise additionally alleviatesinductive bias inherited source domain relystrong appearance cues colour texturesubstantially different target domainfollowing intuition highconfidence predictionspreferred 65 study alternative implementation multiscale fusion overlapping pixels instead averaging predictions pool prediction minimum entropy accuracy drop19 somewhat expected averaging predictions dataaugmentation previously shown produce wellcalibrated uncertainty estimates 1 importantmethod relies confidence values select predictions use selfsupervision importancesampling contributes 15 iou total accuracytable 4 ablation study use gta5 cityscapes settingvggbased model study effect componentsframework individually removing reportmean iou cityscapes validation splitremarkably settings approach accurate competitive recent works 65 70 77weaker backbone vgg16 insteadresnet101 significant improvementsincreased training complexity model capacity contrast previous works additional results including evaluation cityscapes test shownappendices c d43 ablation studyunderstand makes framework effectiveconduct ablation study gta5 cityscapesground truthadapted vgg16 baselineadapted resnet101 baselinegta5 cityscapesb synthia cityscapesfigure 5 qualitative examples approach rectifies appreciable erroneous predictions baselinesurprisingly significant despite estimates clapproximate cf sec 34 overall benefitline previous work 29 recall eq 3confidence thresholds computed class encouragelower values longtail classes disabling schemeequivalent setting 0 eq 3 reducesmean iou 17 confirms observationmodel tends predict lower confidences classesoccupying pixels similarly loss eq 6focal term 0 confidence regularisation mcn 1 24 16 iou inferiorsurprisingly significant contribution negligible computational costalign object boundaries imageframework explicit encoding spatial priorspreviously deemed necessary 15 68 81 83believe enforcing semantic consistency dataaugmentation makes method prone contextual bias 62 blamed coarse boundaries5 conclusionpresented simple accurate approach domainadaptation semantic segmentation ordinary augmentation techniques momentum updates achievestateoftheart accuracy sacrifice modest training model complexity componentsframework strictly specialised build relativelyweak broadly applicable assumption cf sec 1 work focuses semantic segmentationkeen explore potential proposed techniquesadaptation dense prediction tasks opticalflow monocular depth panoptic instance segmentationcompositions multiple tasks44 qualitative assessmentfig 5 presents qualitative examples comparing approach naive baseline sourceonlyloss abn particularly prominent refinementsclasses road sidewalk skysmallscale elements improve substantially personfence leftmost column surprising owing multiscale training thresholding technique initially ignores incorrectly predictedpixels selfsupervision initially tend lowconfidence remarkably segment boundaries tendacknowledgementswork cofundedloewe initiative hesse germany emergencitycenter calculations research partly conductedlichtenberg high performance tu darmstadtreferences16 yunchun chen yenyu lin minghsuan yang jiabin huang crdoco pixellevel domain transfer crossdomain consistency cvpr pp 17911800 2019 217 jaehoon choi taekyung kim changick kim selfensembling ganbased data augmentation domainadaptation semantic segmentation iccv pp 68296839 2019 1 218 marius cordts mohamed omran sebastian ramos timorehfeld markus enzweiler rodrigo benenson uwefranke stefan roth bernt schiele cityscapesdataset semantic urban scene understanding cvprpp 32133223 2016 519 jia deng wei dong richard socher lijia li kai lifeifei li imagenet largescale hierarchical imagedatabase cvpr pp 248255 2009 520 jiahua dong yang cong gan sun yuyang liu xiaowei xu cscl critical semanticconsistent learningunsupervised domain adaptation eccv vol viii pp745762 2020 221 arnaud doucet nando freitas neil j gordonintroduction sequential monte carlo methods sequential monte carlo methods practice pp 314 springer2001 422 liang du jingang tan hongye yang jianfeng feng xiangyang xue qibao zheng xiaoqing ye xiaolinzhang ssfdan separated semantic feature based domainadaptation network semantic segmentation iccv pp982991 2019 223 geoffrey french michal mackiewicz mark h fisherselfensembling visual domain adaptation iclr2018 2 324 yaroslav ganin evgeniya ustinova hana ajakan pascal germain hugo larochelle franois laviolette mariomarchand victor lempitsky domainadversarial training neural networks j mach learn res 17120962030 2016 225 rui gong wen li yuhua chen luc van gool dlowdomain flow adaptation generalization cvprpp 24772486 2019 226 ian goodfellow jean pougetabadie mehdi mirza bingxu david wardefarley sherjil ozair aaron courvilleyoshua bengio generative adversarial nets nips pp26722680 2014 227 yves grandvalet yoshua bengio semisupervisedlearning entropy minimization nips pp 5295362004 228 chuan guo geoff pleiss yu sun kilian q weinbergercalibration modern neural networks icml vol 70pp 13211330 2017 229 agrim gupta piotr dollr ross b girshick lvisdataset large vocabulary instance segmentation cvprpp 53565364 2019 3 830 kaiming haoqi fan yuxin wu saining xieross b girshick momentum contrast unsupervised visual representation learning cvpr pp 97269735 20201 murat seckin ayhan philipp berens testtime data augmentation estimation heteroscedastic aleatoric uncertainty deep neural networks midl 2018 3 72 philip bachman ouais alsharif doina precup learning pseudoensembles nips pp 33653373 20143 shai bendavid john blitzer koby crammer alexkulesza fernando pereira jennifer wortman vaughantheory learning different domains mach learn7912151175 2010 24 shai bendavid john blitzer koby crammer fernandopereira analysis representations domain adaptationnips pp 137144 2006 15 david berthelot nicholas carlini ian j goodfellow nicolas papernot avital oliver colin raffel mixmatchholistic approach semisupervised learning neuripspp 50505060 2019 36 avrim blum tom mitchell combining labeled unlabeled data cotraining colt pp 92100 19987 minjie cai feng lu yoichi sato generalizing handsegmentation egocentric videos uncertaintyguidedmodel adaptation cvpr pp 1438014389 2020 28 weilun chang huipo wang wenhsiao peng weichen chiu structure adapting structural information domains boosting semantic segmentationcvpr pp 19001909 2019 29 liangchieh chen raphael gontijo lopes bowen chengmaxwell d collins ekin d cubuk barret zoph hartwigadam jonathon shlens naivestudent leveragingsemisupervised learning video sequences urban scenesegmentation eccv vol ix pp 695714 2020 110 liangchieh chen george papandreou iasonas kokkinoskevin murphy alan l yuille deeplab semantic image segmentation deep convolutional nets atrous convolution fully connected crfs ieee trans patternanal mach intell 404834848 2018 5 6 711 liangchieh chen yukun zhu george papandreou florianschroff hartwig adam encoderdecoder atrousseparable convolution semantic image segmentationeccv vol vii pp 833851 2018 112 minmin chen kilian q weinberger john blitzer cotraining domain adaptation nips pp 245624642011 113 minghao chen hongyang xue deng cai domain adaptation semantic segmentation maximumsquares loss iccv pp 20902099 2019 214 yihsin chen weiyu chen yuting chen bocheng tsaiyuchiang frank wang min sun discrimination cross city adaptation road scene segmentersiccv pp 20112020 2017 215 yuhua chen wen li luc van gool road reality oriented adaptation semantic segmentation urban scenescvpr pp 78927901 2018 2 831 kaiming xiangyu zhang shaoqing ren jian sundeep residual learning image recognition cvpr pp770778 2016 532 judy hoffman eric tzeng taesung park junyan zhuphillip isola kate saenko alexei efros trevor darrell cycada cycleconsistent adversarial domain adaptation icml vol 80 pp 19942003 2018 2 633 weixiang hong zhenzhen wang ming yang junsongyuan conditional generative adversarial network structured domain adaptation cvpr pp 13351344 201834 sergey ioffe christian szegedy batch normalizationaccelerating deep network training reducing internal covariate shift icml vol 37 pp 448456 2015 4 535 pavel izmailov dmitrii podoprikhin timur garipovdmitry p vetrov andrew gordon wilson averagingweights leads wider optima better generalizationuai pp 876885 2018 336 fredrik d johansson david sontag rajesh ranganath support invertibility domaininvariant representations aistats vol 89 pp 527536 2019 237 guoliang kang yunchao wei yi yang yueting zhuangalexander g hauptmann pixellevel cycle associationnew perspective domain adaptive semantic segmentation neurips pp 35693580 2020 238 alex kendall yarin gal uncertainties needbayesian deep learning vision nips pp55745584 2017 339 myeongjin kim hyeran byun learning texture invariant representation domain adaptation semantic segmentation cvpr pp 1297212981 2020 1 2 540 samuli laine timo aila temporal ensembling semisupervised learning iclr 2017 2 341 chenyu lee tanmay batra mohammad haris baigdaniel ulbricht sliced wasserstein discrepancy unsupervised domain adaptation cvpr pp 10285102952019 242 donghyun lee pseudolabel simple efficientsemisupervised learning method deep neural networksicml workshops vol 3 2013 143 guangrui li guoliang kang wu liu yunchao weiyi yang contentconsistent matching domain adaptivesemantic segmentation eccv vol xiv pp 4404562020 1 2 344 xiaomeng li lequan yu hao chen chiwing fuphengann heng semisupervised skin lesion segmentation transformation consistent selfensembling modelbmvc 2018 245 yanghao li naiyan wang jianping shi xiaodi houjiaying liu adaptive batch normalization practical domain adaptation pattern recognition 80109117 2018 24 546 yunsheng li lu yuan nuno vasconcelos bidirectionallearning domain adaptation semantic segmentationcvpr pp 69366945 2019 1 2 3 647 qing lian lixin duan fengmao lv boqing gongconstructing selfmotivated pyramid curriculums crossdomain semantic segmentation nonadversarial approachiccv pp 67576766 2019 1 2 4 5 6 7timothy p lillicrap jonathan j hunt alexander pritzelnicolas heess tom erez yuval tassa david silverdaan wierstra continuous control deep reinforcementlearning iclr 2016 3tsungyi lin priya goyal ross b girshick kaimingpiotr dollr focal loss dense object detection ieeetrans pattern anal mach intell 422318327 2020 4mingsheng long zhangjie cao jianmin wangmichael jordan conditional adversarial domain adaptation neurips pp 16471657 2018 2yawei luo ping liu tao guan junqing yu yi yangsignificanceaware information bottleneck domain adaptive semantic segmentation cvpr pp 67786787 2019yawei luo liang zheng tao guan junqing yu yiyang taking closer look domain shift categoryleveladversaries semantics consistent domain adaptationcvpr pp 25072516 2019 2fengmao lv tao liang xiang chen guosheng lincrossdomain semantic segmentation domaininvariantinteractive relation transfer cvpr pp 43334342 20201 2 6 7ke mei chuang zhu jiaqi zou shanghang zhang instance adaptive selftraining unsupervised domain adaptation eccv vol xxvi pp 415430 2020 1 2 3 6luigi musto andrea zinelli semantically adaptiveimagetoimage translation domain adaptation semantic segmentation bmvc 2020 1 2 6 7fei pan inkyu shin franois rameau seokju leekweon unsupervised intradomain adaptation semantic segmentation selfsupervision cvpr pp37633772 2020 2adam paszke sam gross francisco massa et al pytorch imperative style highperformance deep learninglibrary neurips pp 80248035 2019 5christian s perone pedro l ballester rodrigo c barros julien cohenadad unsupervised domain adaptation medical imaging segmentation selfensemblingneuroimage 194111 2019 2stephan r richter vibhav vineet stefan roth vladlenkoltun playing data ground truthgames eccv vol ii pp 102118 2016 1 5germn ros laura sellart joanna materzynska davidvzquez antonio m lpez synthia datasetlarge collection synthetic images semantic segmentation urban scenes cvpr pp 32343243 2016 1mehdi sajjadi mehran javanmardi tolga tasdizenregularization stochastic transformations perturbations deep semisupervised learning nips pp 11631171 2016 2rakshith shetty bernt schiele mario fritz car sidewalk quantifying controllingeffects context classification segmentationcvpr pp 82188226 2019 877 jinyu yang weizhi sheng wang xinliang zhuchaochao yan junzhou huang labeldriven reconstruction domain adaptation semantic segmentationeccv vol xxvii pp 480498 2020 1 2 6 778 jinyu yang weizhi chaochao yan peilin zhao junzhou huang contextaware domain adaptation semanticsegmentation wacv pp 514524 2021 1 2 6 779 yanchao yang dong lao ganesh sundaramoorthi stefano soatto phase consistent ecological domain adaptationcvpr pp 90089017 2020 280 yanchao yang stefano soatto fda fourier domainadaptation semantic segmentation cvpr pp 40844094 2020 1 2 5 6 781 yang zhang philip david boqing gong curriculum domain adaptation semantic segmentation urbanscenes iccv pp 20392049 2017 2 882 yiheng zhang zhaofan qiu ting yao dong liu taomei fully convolutional adaptation networks semanticsegmentation cvpr pp 68106818 2018 283 yiheng zhang zhaofan qiu ting yao chongwah ngodong liu tao mei transferring regularizing prediction semantic segmentation cvpr pp 961896272020 2 4 6 7 884 han zhao remi tachet des combes kun zhang geoffrey j gordon learning invariant representationsdomain adaptation icml vol 97 pp 75237532 201985 hengshuang zhao jianping shi xiaojuan qi xiaogangwang jiaya jia pyramid scene parsing networkcvpr pp 62306239 2017 1 6 786 zhedong zheng yi yang unsupervised scene adaptationmemory regularization vivo ijcai pp 10761082 2020 1 287 zhedong zheng yi yang rectifying pseudo label learning uncertainty estimation domain adaptive semanticsegmentation int j comput vis 129411061120 20211 288 qianyu zhou zhengyang feng guangliang cheng xintan jianping shi lizhuang ma uncertaintyaware consistency regularization crossdomain semantic segmentation arxiv200408878 cscv 2020 289 junyan zhu taesung park phillip isola alexeiefros unpaired imagetoimage translation cycleconsistent adversarial networks iccv pp 224222512017 290 xinge zhu hui zhou ceyuan yang jianping shidahua lin penalizing performers conservative losssemantic segmentation adaptation eccv vol viipp 568583 2018 291 yang zou zhiding yu bvk vijaya kumar jinsongwang unsupervised domain adaptation semantic segmentation classbalanced selftraining eccv voliii pp 297313 2018 1 2 3 692 yang zou zhiding yu xiaofeng liu bvk vijaya kumarjinsong wang confidence regularized selftrainingiccv pp 59815990 2019 1 263 karen simonyan andrew zisserman deep convolutional networks largescale image recognition iclr2015 564 kihyuk sohn david berthelot nicholas carlini zizhaozhang han zhang colin raffel ekin dogus cubuk alexeykurakin chunliang li fixmatch simplifying semisupervised learning consistency confidenceneurips pp 596608 2020 265 muhammad subhani mohsen ali learning scaleinvariant examples domain adaptation semantic segmentation eccv vol xxii pp 290306 2020 1 2 34 766 antti tarvainen harri valpola mean teachers betterrole models weightaveraged consistency targets improvesemisupervised deep learning results nips pp 11951204 2017 2 367 yihsuan tsai weichih hung samuel schulter kihyuk sohn minghsuan yang manmohan chandrakerlearning adapt structured output space semantic segmentation cvpr pp 74727481 2018 1 2 568 yihsuan tsai kihyuk sohn samuel schulter manmohan chandraker domain adaptation structured outputdiscriminative patch representations iccv pp 14561465 2019 1 2 5 869 tuanhung vu himalaya jain maxime bucher matthieucord patrick prez advent adversarial entropyminimization domain adaptation semantic segmentation cvpr pp 25172526 2019 1 2 5 6 770 haoran wang tong shen wei zhang lingyu duantao mei classes matter finegrained adversarial approach crossdomain semantic segmentation eccvvol xiv pp 642659 2020 1 2 5 6 771 kaihong wang chenhongyi yang margrit betkeconsistency regularization highdimensional nonadversarial sourceguided perturbation unsupervised domain adaptation segmentation aaai 2021 272 yude wang jie zhang meina kan shiguang shanxilin chen selfsupervised equivariant attention mechanism weakly supervised semantic segmentationcvpr pp 1227212281 2020 373 zhonghao wang mo yu yunchao wei rogrio feris jinjun xiong wenmei hwu thomas s huang honghuishi differential treatment stuff things simpleunsupervised domain adaptation method semantic segmentation cvpr pp 1263212641 2020 2 574 zuxuan wu xintong han yenliang lin mustafa gkhanuzunbas tom goldstein sernam lim larry s davisdcan dual channelwise alignment networks unsupervised scene adaptation eccv vol v pp 535552 201875 qizhe xie zihang dai eduard h hovy thang luongquoc le unsupervised data augmentation consistencytraining neurips pp 62566268 2020 276 qizhe xie minhthang luong eduard h hovyquoc v le selftraining noisy student improves imagenet classification cvpr pp 1068410695 2020 2selfsupervised augmentation consistencyadapting semantic segmentationsupplemental materialnikita araslanov1stefan roth12department science tu darmstadtoverviewappendix provide trainingimplementation details frameworkcloser look accuracy longtail classesadaptation discuss strategy hyperparameter selection perform sensitivity analysisevaluate framework segmentation architecture fcn8s 98 finally discuss limitationscurrent evaluation protocol propose revisionbased best practices field largeimportimportimportimporthessianairandompiltorchvision transforms tftorchvision transforms functional fload imageimage pil image opengaussian blurrandomly sampled radiusradius random uniform 1 2gaussian pil imagefilter gaussianblur radiusimage image filter gaussianb technical detailsphotometric noise recall framework uses random gaussian smoothing greyscaling colour jitteringimplement photometric noise reuse parameters operations mocov2 framework 93kernel radius gaussian blur sampled uniformly range 01 20 notecorrespond actual filter size1 colour jitterapplied probability 05 implements perturbationimage brightness contrast saturation factorsampled uniformly 06 14 hue factorsampled uniformly random range 09 11convert target image greyscale version probability 02 fig 6 demonstrates example implementationprocedure pythoncolour jitterprobability 0505 random randomjitter tf colorjitter brightness 04contrast 04saturation 04hue 01image jitter imageconvert greyscaleprobability 0202 random randomimage f tograyscale imagefigure 6 python implementation photometric noisetraining schedule framework typically needs 150200k iterations total including sourceonly pretraining convergence determined random subset 500 images training set discussionappendix d varies slightly dependingbackbone source data schedule translatesapproximately 3 days training standard gpustitan x pascal 12 gb memory vgg16 resnet101 backbones recall 4 gpusresnet version framework trainingtime comparable vgg variant uses 2gpus experiments use constant learning ratesimplicity advanced schedules cyclicallearning rates 35 cosine schedule 93 95 rampups40 improve accuracy frameworkconstraintfree data augmentation similarlymultiscale cropping target images scalesource images randomly factor sampled uniformly05 10 prior cropping enforce semantic consistency source dataground truth source images availabletarget source images use random horizontalflipping additionally experimented moderate rotation semantic consistencyobserve significant effect mean accuracy1 pillow library 94 internally converts radius r boxlength l 3 r2 1cbtsky pers ridecartruck bus train moto bicymiou881410857 308 306 331 370 229 866 368 907 671 271 868 344 304445894900893523471390860 340 326 385 433 306 852 309 885 667 280 857 356 396 00856 313 249 323 389 282 873 398 894 677 286 881 401 500 73851 332 261 324 418 252 863 274 904 664 282 875 329 454 110460468450893893897526522451860 334 300 380 449 343 869 353 880 654 273 862 376 440 209 96 65861 342 315 370 434 363 852 307 866 662 303 853 362 439 292 68 86856 296 283 317 419 275 872 374 898 669 292 875 373 316 247 119 202482484475900531862 338 327 382 460 403 842 264 884 658 280 856 406 529 173 137 238499terrroad sidew build wall fence pole light sign vegtable 5 perclass iou cityscapes val vgg16 backbone gta5 cityscapes setting study componentsclassbased thresholding cbt importance sampling focal loss fl miou settingsrows reproduced main text elaborate perclass accuracy broader context supplementaryexperiments rowsc additional experimentsiou classes benefitsindividual framework components understoodcontext aggregated effect multiple classesmean iou instance consider classtrain appears decrease ioucbt fl achieve 292 iou adding decreases iou 173 iou classesincreases motorcycle bicycle meaniou furthermore classes reach maximumaccuracy enable longtail componentssetting best accuracy tradeoff individual classes highest mean iouoverall longtail components improve framework54 mean iou combined substantial marginc1 closer look longtail adaptationrecall framework features componentsattune adaptation process longtail classes classbased thresholding cbt importance samplingfocal loss fl summarily refer longtail components following disabling longtailcomponents individually equivalent setting 0cbt uniform sampling target images insteadassigning 0 fl extend ablation study gta5 cityscapes setup vgg16cf table 4 main text experiment different combinations longtail components table 5details perclass accuracy possible compositionsobserve ubiquitous classes road building vegetation sky person car hardlyaffected primarily longtail categories changeaccuracy furthermore longtail components mutually complementary mean iou improvescomponents active 445 468boosted components enabled484 reaches maximum model 499components placeidentify following tentative patterns fltends improve classes wall fence pole cbtincreases accuracy traffic light categoryhigh image frequency occupies pixelsrare classes rider bus trainbenefit cbt especially conjunctionenhances mask quality classes bicyclemotorcycle urge caution interpreting results class isolation despitewidespread practice literature todays semantic segmentation models possess notion ambiguous class prediction pixel receives meaningfullabel pigeons hole principle implieschanges iou class immediate effectc2 hyperparameter search sensitivityselect experimented reasonable choices 07 08 00001 0012lightweight backbone mobilenetv2 97 measure performance use mean iou validationset 500 images cityscapes train main textstudy frameworks sensitivity particular choice results comparableprevious experiments use vgg16 reportmean iou cityscapes val table 7 observe moderate deviation iou wrt tangible dropaccuracy 001 expected leads lowconfidence predictions likely inaccurateincluded pseudo label note suboptimal choice hyperparameters leads inferiorresults standard deviation 14 miouweakest model 08 001 failconsiderably improve baseline 85 iou cftable 2 main text2interpretable maximum confidencethreshold reasonable range derived c longtail classes simply fraction pixels classes tendoccupy image eq 3methodroad sidew build wall fence pole light sign vegterrsky pers ridecar truck bus train moto bicymiougta5 cityscapesbaselinesacfcn767 282863 456744 127 190 272 287 122 770 180 706 548 206 796 190 192 206 279 112844 303 271 248 428 352 869 397 880 623 321 841 284 437 319 294 458367 371499 499609 18814 198316 344468 491synthia cityscapesbaselinesacfcn507 238747 34201 277 105 157 60119 272 348 272 800724 501 160 665863 615 208 82513731285 268320 539table 6 perclass iou cityscapes val vgg16 fcn8s reference numbers parentheses columnreport mean iou deeplabv2 architecture cf tables 2 3 main text075000014794864820001001d bestpractice evaluation488499498467463456current strategy evaluate domain adaptation damethods semantic segmentation use groundtruth 500 randomly selected images cityscapestrain split model selection report final modelaccuracy 500 cityscapes val images 47work adhered procedure enable fair comparison previous work evaluation approachevidently discord established best practicemachine learning benchmarking practicecityscapes 18 particulartest set holdout data unbiased performance assessment segmentation accuracyfinal model 96 conceivable consulttest set verifying number model variantsaccess unrestrained infeasible ensuretest set annotation public casecityscapes val benchmark websites traditionallyenable restricted access test annotation impartial submission policies limited number submissions time window user cityscapes officiallyprovides one3suggest simple revision evaluation protocol evaluating future da methodsuse cityscapes train training data targetdomain naturally ground truth model selection use cityscapes val imagesgroundtruth labels holdout test set reportingfinal segmentation accuracy adaptationcityscapes test results obtained submittingpredicted segmentation masks official cityscapesbenchmark serveradditional advantage strategy clear interpretation final accuracy context fully supervised methods routinely use evaluation setupnote cityscapes val contains images different cities cityscapes train differentcityscapes test suitable detecting cases model overfitting particularitiescity validation set previously subsettable 7 mean iou gta5 cityscapes val varying framework maintains strong accuracy different settings poor choice 08001 fares wrt state art outperformsprevious works cf table 2 main textc3 vgg16 fcn8snumber previous works 55 77 80fcn8s 98 architecture vgg16 opposeddeeplabv2 10 adopted works 39 70architecture exchange appearsdismissed previous work minorarchitectures experiments segmentation architecture contribute observeddifferences accuracy methods critically improvements attributed aspects approach facilitate transparencywork replace deeplabv2 fcn8s counterpart framework vgg16 backbonerepeat adaptation experiments sec 4source domains gta5 synthia cityscapestarget domain values hyperparameters exception learning rateincrease factor 2 5 104 table 6 reports results adaptation clearlyframework generalises segmentation architectures despite fcn8s baseline model sourceonlyloss abn achieving slightly inferior accuracy compared deeplabv2 316 vs 344 iou synthia cityscapes selfsupervised training attains remarkably high accuracy 468 iou vs 491deeplabv2 substantially higher previous best method fcn8s vgg16 backbone sai2i 55 34 gta5 cityscapes53 synthia cityscapes3 httpswwwcityscapesdatasetcomiiimethodroad sidew build wall fence pole light sign veg terr sky pers ride car truck bus train moto bicymiougta5 cityscapessacfcnsacvggsacresnet875 452915 539918 543850 292 264 233 442 320 883 526 912 652 350 860 244 328 314 369 405866 341 315 368 472 369 851 380 911 687 319 874 310 467 226 242 240874 362 302 437 497 421 893 543 905 718 349 898 388 473 249 383 438504 499510 499557 538669 259704 297874 410808 121836 116855 175458 468483 491527 526979 813974 784904 488 474 496 579 673 919 694 942 798 598 937 565 675 575 577 688892 349 442 474 601 650 914 693 939 771 514 926 353 486 465 516 668synthia cityscapessacfcnsacvggsacresnet20 244 371 275 788 889 639 250 84718 342 412 292 810 871 679 254 75926 405 447 344 879 912 680 310 893274343332369 502425 575386 499fully supervised cityscapesdeeplabresnet 10fcnvgg 98704653table 8 perclass iou cityscapes test column numbers parentheses report mean iou cityscapes valprevious evaluation scheme cf tables 2 3 main text reference sacfcn denotes vggbased modelfcn8s 98 appendix c3training imagesfuture reference evaluate frameworkdeeplabv2 fcn8s variants proposed setupreport results table 8 ease comparisonjuxtapose validation results reported maintext table 6 fcn8s4 finetunemethod cityscapes val following previous evaluation protocol expect test accuracy cityscapestest par previously reported accuracycityscapes val results table 8 clearly confirmexpectation segmentation accuracy cityscapestest comparable accuracy cityscapes val synthia cityscapes tangibly higher gta5cityscapes remark remaining accuracy gapfully supervised model considerable 704vs 557 iou achieved best deeplabv2 model653 vs 510 iou compared best fcn8s variantinvites effort research communityhope future uda methods semantic segmentation follow suit reporting results cityscapestest owing regulated access test set believe setting offer transparency fairnessbenchmarking process successfully driveprogress uda semantic segmentationpast fully supervised methodsreferences93 xinlei chen haoqi fan ross girshick kaimingimproved baselines momentum contrastive learningarxiv200304297 cscv 202094 alex clark pillow pil fork documentation 201595 ilya loshchilov frank hutter sgdr stochastic gradient descent warm restarts iclr 201796 brian d ripley pattern recognition neural networkscambridge university press 199697 mark sandler andrew g howard menglong zhu andreyzhmoginov liangchieh chen mobilenetv2 invertedresiduals linear bottlenecks cvpr pp 45104520201898 evan shelhamer jonathan long trevor darrell fullyconvolutional networks semantic segmentation ieeetrans pattern anal mach intell 394640651 20174 best knowledge previous work published resultsevaluation setting