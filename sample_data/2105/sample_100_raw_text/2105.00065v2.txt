Article

Quantum Foundations of Classical Reversible Computing
Michael P. Frank 1,†, *

and Karpur Shukla 2,†, *
1
2

*

arXiv:2105.00065v2 [quant-ph] 5 May 2021

†

Center for Computing Research, Sandia National Laboratories; mpfrank@sandia.gov
Department of Electrical and Computer Engineering, Brown University; karpur_shukla@brown.edu
Correspondence: mpfrank@sandia.gov, karpur_shukla@brown.edu; Tel.: +1-505-284-4103 (M.F.), +1-646-580-5277
(K.S.)
These authors contributed equally to this work.

Abstract: The reversible computation paradigm aims to provide a new foundation for general classical
digital computing that is capable of circumventing the thermodynamic limits to the energy efficiency of
the conventional, non-reversible paradigm. However, to date, the essential rationale for and analysis
of classical reversible computing (RC) has not yet been expressed in terms that leverage the modern
formal methods of non-equilibrium quantum thermodynamics (NEQT). In this paper, we begin developing an NEQT-based foundation for the physics of reversible computing. We use the framework of
Gorini-Kossakowski-Sudarshan-Lindblad dynamics (a.k.a. Lindbladians) with multiple asymptotic states,
incorporating recent results from resource theory, full counting statistics, and stochastic thermodynamics.
Important conclusions include that, as expected: (1) Landauer's Principle indeed sets a strict lower
bound on entropy generation in traditional non-reversible architectures for deterministic computing
machines when we account for the loss of correlations; and (2) implementations of the alternative
reversible computation paradigm can potentially avoid such losses, and thereby circumvent the Landauer
limit, potentially allowing the efficiency of future digital computing technologies to continue improving
indefinitely. We also outline a research plan for identifying the fundamental minimum energy dissipation
of reversible computing machines as a function of speed.
Keywords: non-equilibrium quantum thermodynamics; thermodynamics of computing; Landauer's
principle; Landauer limit; reversible computing; resource theory of quantum thermodynamics; GoriniKossakowski-Sudarshan-Lindblad dynamics; Lindbladians; von Neumann entropy; Rényi entropy;
open quantum systems



Citation: Frank, M.P.; Shukla, K.
Quantum Foundations of Classical
Reversible Computing. Preprints 2021,

1, 0. https://doi.org/
Received:
Accepted:
Published:

Publisher's Note: MDPI stays neutral
with regard to jurisdictional claims in
published maps and institutional affiliations.

1

1. Introduction
The concept of reversible computation, or computation without information loss (even
locally), played a centrally important role in the historical development of the thermodynamics
of computation [1–6]. It remains critically important today in the field of quantum computing,
where it is necessary for maintaining coherence in quantum algorithms [7]. However, the
original motivation for reversible computation, which was to circumvent the kT ln 2 Landauer
limit1 on energy dissipation in classical digital computing, is less often remembered today.
Some authors have critiqued the original arguments for Landauer's limit and reversible
computing as relying on equilibrium assumptions (e.g., [8]), but in fact, no such assumption
beyond the existence of an external heat sink at some temperature T is required. When properly
stated and interpreted, Landauer's limit holds regardless of whether the computing system is
at (or even close to) equilibrium internally. This statement follows directly from elementary
statistical physics and information theory [9].
Indeed, Landauer's limit has also been derived directly for systems out of equilibrium
[10,11]. This nonequilibrium limit is expressed purely in terms of the non-unitality of the

In this expression, k = kB ' 1.38 × 10−23 J/K is Boltzmann's constant, which is the natural logarithmic unit of entropy, and T is temperature.

2 of 68

quantum channel evolving the system and heat bath. In other words, Landauer's limit has
been derived solely as a consequence of thermal operations (as defined in NEQT) acting on
the joint quantum mechanical evolution of a system and a bath. This directly reinforces the
motivation for reversible computing, which is to avoid the Landauer cost of ejecting correlated
information into the environment. The free energy2 cost of operations that do not eject
correlated information can be made arbitrarily small, a fact rigorously proven using resource
theoretic techniques in NEQT [12]. We discuss these connections in some detail in later
sections. Further, the enterprise of recasting the classic understanding of the thermodynamics
of computing in more modern terms offers other benefits. In particular, it allows the theoretical
apparatus of the modern NEQT formalism to be brought to bear on the problem of analyzing
the potential capabilities of, and fundamental limits on, classical reversible computational
processes.
This problem is of far more than just academic interest. Today, an increasingly serious
concern is that the conventional non-reversible paradigm for general digital computation is
approaching firm limits to its energy efficiency and cost efficiency. These limits ultimately
trace back to the kT energy scale. Since reversible computing is, broadly speaking, the only
non-conventional computing paradigm that can potentially offer a sustainable path forward
capable of circumventing the efficiency limits associated with that energy scale in general digital
computing, it is therefore critically important to the prospects for medium- and long-term
improvement in the efficiency and economic utility of general digital computing to determine
exactly what the potentialities and limitations of reversible computational mechanisms may
be, according to fundamental theory.
In this paper, we aim to carry out the essential groundwork for this enterprise, laying
down low-level theoretical foundations upon which a comprehensive NEQT-based treatment
of physical mechanisms for reversible computation may be based. It is essential for any
such effort to identify the most appropriate definitions for key concepts, and we do this
throughout, taking special care with the definitions of the appropriate physical concepts
corresponding to classical digital computational states and operations. On this ground, we
advocate for our position that the most appropriate understanding of Landauer's Principle is
to view it as comprising, most essentially, a statement about the strict entropy increase that is
required due to the loss of mutual information that necessarily occurs whenever (nontrivially)
deterministically computed (ergo correlated) bits are thermalized in isolation. There are other,
oft-cited forms of the Principle that deal only with a transfer of entropy between computational
and non-computational forms; but we instead refer to these as The Fundamental Theorem of the
Thermodynamics of Computation to avoid confusion, since it has long been known that simple
transfers of entropy between different forms can occur in a thermodynamically reversible
way. The inappropriate conflation of Landauer's Principle proper, as we identify it, with
the Fundamental Theorem is what we believe has been the root cause of a great deal of
confusion in the thermodynamics of computing field. As we suggest, simply appropriately
distinguishing these concepts permits the straightforward resolution of many long-standing
controversies.
Another central aim of this work is to go beyond discussions of Landauer's limit, to develop a first-principles model of classical RC operations using information-theoretic techniques
in nonequilibrium quantum thermodynamics. These techniques allow us to understand the
fundamental quantum mechanical expressions of, and restrictions on, classical RC operations
in several ways. From resource theory and fluctuation theorems [12,15], these techniques provide us with a way of understanding the overall limitations of state transitions, including those
2

The free energy referred to here is the α = 1 free energy in particular; i.e., the (nonequilibrium) Helmholtz free energy. In the words of [12] directly,
that work shows that the most general possible type of catalytic thermal operation (and thus the most general type of transition possible in quantum
thermodynamics) "restores the distinguished role of the Helmholtz free energy."

3 of 68

that correspond to classical RC operations. In addition to constraints, the framework of GoriniKossakowski-Sudarshan-Lindblad operators (GKSL operators, also known as Lindbladians)
with multiple asymptotic states [17–19] offer a framework by which explicit nonequilibrium
quantum thermodynamic expressions of classical RC operations can be realized. As such,
these techniques offer a natural language for expressing the dynamics of RC operations, and
provide us with an understanding of the fundamental quantum mechanical restrictions on the
way these operations can manifest in physical systems. Fundamental bounds on quantities
of interest, such as the dissipation of an operation as a function of its speed, will necessarily
have to arise from NEQT.
Here, we provide a description of RC operations via the theory of open quantum systems.
In this formulation, we can examine the joint evolution of the computing system with a thermal
environment (a.k.a. heat bath), using the machinery of completely positive trace preserving
maps (CPTP maps, a.k.a. quantum channels). In particular, we rely on the framework of
GKSL operators with multiple asymptotic states [17–19] to develop representations of classical
reversible information processing operations. Quite powerfully, this framework can directly
give us bounds on dissipation quantities of interest not only for RC operations, but for
quantum computation (QC) operations as well-since we express RC operations in terms of
quantum channels, the results we derive for RC operations can be directly extended to QC
operations in future work.
The structure of the remainder of the paper is as follows. Section 2 describes materials
and methods, including outlining a broad theoretical framework in §2.1, relating that broad
framework to the more detailed tools and methods of NEQT in §2.2, and reviewing a variety
of existing and proposed physical implementation technologies for reversible computing
in §2.3. Sec. 3 presents our early results, specifically reviewing how a few classic theorems
can be easily proven in our framework. These include (§3.1) The Fundamental Theorem of
the Thermodynamics of Computing, which we distinguish from (§3.2) Landauer's Principle
(properly stated); (§3.3) fundamental theorems of traditional and generalized reversible
computing; and the representation of classical reversible computational operations via the
frameworks of catalytic thermal operations and GKSL dynamics (§§3.4–3.5). Sec. 4 gives some
general discussion of results and outlines our research plan looking forwards, and Sec. 5
concludes.
2. Materials and Methods
As this article presents theoretical, rather than experimental work, there is no laboratory
apparatus to speak of; however, we provide a brief review of some of the existing and proposed
physical implementation technologies for reversible computing in §2.3. But first, we present
the key foundational definitions of our broad theoretical picture in §2.1. Please note that this
presentation roughly follows, but expands upon, that given in [9,20]. Then in §2.2, we tie this
broad picture to the much more detailed theoretical apparatus of NEQT.
2.1. Broad Theoretical Foundations
In this subsection, we present and review a number of important low-level definitions
that form the broad foundation upon which our overall approach to the physics of reversible
computing is built. This includes (§2.1.1) our overall picture based on a framework of open
quantum systems; (§2.1.2) our definition of classical digital computational states and their
physical representation, which invokes what we call a proto-computational basis, which may in
general be time-dependent; (§2.1.3) our definitions for classical computational operations, and
different types of operations, which are expressible in terms of (§2.1.4) primitive computational
state transitions; and (§2.1.5) the appropriate definition of what it means for a given unitary
time evolution to implement a classical computational operation.

4 of 68

2.1.1. Open Quantum Systems Framework
In this subsection, we briefly review the broad outlines of the open quantum systems
based picture that we are using in this paper. Further details will be developed in §2.2.
2.1.1.1. System and environment.
We begin with a fairly conventional picture of a physical computer system based on an
open quantum systems perspective. At the highest level, we assume that the model universe
U under study can be described as a composition of two subsystems S, E, where S is the
physical computer system in question, and E is its external environment (i.e., the rest of U,
outside of S). As an example, one could define the "computer system" S as consisting of
everything (i.e., all quantum fields) encompassed within some region of (3+1)D spacetime
circumscribed by some closed (2+1)-dimensional bounding surface. For simplicity, one could
think of a spatial boundary that is unchanging in time over some interval. Typically, our
analyses will treat the environment E as an (effectively infinitely large) uniform thermal
reservoir (heat bath) that is internally at thermal equilibrium, at some (effectively constant
over time) temperature T. The temperature may be treated as effectively constant when the
environment is large enough that its temperature is negligibly affected by heat transferred
from S.3
Meanwhile, we will treat the computer system S as an (in general) non-equilibrium system
which includes its own internal supply of free energy (e.g., this could be a battery or a fuel
reservoir). This is just a simplification of the overall picture, for our present purposes, to avoid
the need to explicitly represent a flow of work or free energy in from a separate "power supply"
system; i.e., the power supply is treated as internal to the computer. However, we will allow
that the system S is able to exchange thermal energy (and entropy) with its environment E
through (all or some portion of) its boundary. Typically, the computer would be assumed
to expel waste heat to its external environment E during operation in order to maintain its
(S's) own internal operating temperature (which will generally be non-uniform) within some
reasonable bounds. The mechanisms for managing the needed thermal flows are generally
assumed to be contained within S. See Figure 1.
2.1.1.2. Decoherence model.
A further important simplifying assumption is that we, as modelers, cannot effectively
track any (classical or quantum) correlations between the detailed states of S and E, or
internal correlations between different parts of E, on any practical timescales. Note, this
is not to say that such correlations do not exist physically, as they do under unitary time
evolution, but rather just that they are not reflected in our state of knowledge as modelers. A
typical assumption, which we adopt, is that it is also safe, or reasonable, to ignore any such
correlations that may exist.4
Stated slightly more formally, we first assume, for simplicity, that the Hilbert space HU
of the model universe U factorizes neatly into separate Hilbert spaces for the system S and
environment E, that is,
HU = HE ⊗ HS .
(1)
Given this, we can imagine that, within a negligible thermalization timescale subsequent to
the emission of any small increment ∆Q of waste heat out of S, the mixed state ρU of the
model universe would quickly degrade, for all practical purposes, into a (correlation-free)
3
4

Of course, this model is already somewhat of an idealization, since a typical real environment would attain a nonuniform temperature profile under a
steady-state thermal flow with constant power output from S, but it can nevertheless be considered an adequate model for an initial study.
Whether this is, in fact, a valid assumption is a broad question about the applicability of this open-systems perspective which we do not address in this
paper.

5 of 68

Figure 1. Simplified picture of our model universe U in an open quantum systems framework. Power
supplies and waste heat removal mechanisms are assumed to be included within the physical computer
system S. In general, we may assume there is a flow of waste heat from the system out to an (assumed
very large) external heat bath E.

product state ρU = ρE ⊗ ρS , where ρE is the maximum-entropy (equilibrium) mixed state of
energy QE which includes the heat increment ∆Q after it has diffused into the environment,
and ρS is a reduced density matrix for the mixed state of the computer system after one
has traced out any lingering correlations it may have had with the environment initially
upon emission of the waste heat. Note that in the absence of totally separable dynamics (i.e.,
bU = H
bE ⊗ H
bS ), a strict entropy increase is
a Hamiltonian over HU given at all times by H
implied by taking the trace over E (compared to the entropy of an immediately-prior joint state
0 briefly entangling the environment with the system) in the instant just after the emission of
ρU
the heat ∆Q. Thus, simply performing this state reduction results in global entropy increases
in the model universe even when all other dynamics (including the internal dynamics within
S) is taken to be unitary. This state reduction process models the effective decoherence of the
system S as a result of its interaction with the (modeled as thermal) environment E [21].
A slightly more general model (with weaker assumptions) can be provided by stipulating
that we take the trace over E only once, at the very end of an evolution of interest, rather than
continuously after each incremental emission ∆Q of heat into this environment. Postponing
the state reduction allows for the possibility that correlations/entanglements between the
system S and environment E, and within E may persist for some period of time, and affect
the evolution to some extent. However, it is not expected that this change will make very
much difference in practice.5
Modeling the allowed thermal transformations of open quantum systems in detail is the
topic of the resource theory of quantum thermodynamics (RTQT), which we review briefly in §

5

As a thought experiment, consider a computer system S in deep space, such that any thermal photons emitted from the system into the environment
would be expected to mostly just propagate to infinity, with only an astronomically tiny probability of reflecting off of interplanetary gas or dust in
such a way as to convey correlated quantum information back into the system. The analysis of such cases, at least, would clearly be only insignificantly
affected by treating state reduction as a continuous process.

6 of 68

2.2.1 below. But first, let us continue outlining our broad framework for studying the physics
of RC.
2.1.2. Computational States and the Proto-Computational Basis
We now discuss how to formally model, in both abstract and physical terms, the digital
computational states of a computer system S.
Note that our emphasis, in this paper, is on classical, not quantum, reversible computation,
and furthermore, we wish the scope of our model to include the usual case in real engineered
digital computing systems, which is that digital computational states may be encoded by
extended physical objects, whose detailed microstate is, in general, not fully determined by the
computational state being represented. As an example of this, consider a logic node (connected
conductor) within a digital CMOS circuit, where typically the digital symbols '0' and '1' may
nominally be represented by node voltages within certain pre-specified, non-overlapping
low-to-high ranges [V0L , V0H ] and [V1L , V1H ], respectively.
2.1.2.1. Designated times.
Given that we wish to model active computing machines in which the abstract computational state of the machine changes over the course of some time interval, we can expect
to encounter the difficulty that the classical digital state of the machine, which, as a discrete
entity, takes on values that range over some merely countable set, may not be well-defined
(in traditional terms, at least) at all moments during the (physically continuous) transition
from one state to the next. To avoid this difficulty, while maintaining simplicity in our model,
we will declare, for purposes of the present paper, that there exists some countable set { τ` }
of time points τ` ∈ R, labeled with integers ` ∈ Z, which we will call the designated times at
which the classical digital computational state of the machine is well-defined.
Note that this model is somewhat oversimplified, since a real engineered computing
system is typically not monolithic, but is broken down into subsystems, and it may be the case
that the larger system is globally asynchronous, in the sense that some subsystems may be in the
middle of state transitions while others are in well-defined states; indeed, depending on the
system architecture, there may be no moments at which the entire machine is simultaneously in
a nominally well-defined digital state. However, we will postpone elaboration upon methods
to handle this more general case to a later time, as it does not affect anything essential in the
present paper.6
2.1.2.2. Computational states correspond to sets of orthogonal microstates.
Regardless of what precise physical encoding of digital computational states is used,
we take it as fundamental to the concept of a classical digital computational state that at
any designated time t = τ` ∈ R, there exists some set C (t) = { ci (t) } of abstract entities
comprising all of the possible alternative well-defined computational states ci (t) of the computer
system S that the machine could occupy at the time t, and further, that, for any given
such state c = ci (t), there exists some corresponding set Bc ⊂ HS of mutually orthogonal,
normalized basis vectors ~b ∈ Bc , each of which represents a pure quantum state of S that
is unambiguously interpretable as representing the state c. In other words, there is some
orthonormal basis B ⊃ Bc for HS such that, if one were to hypothetically perform a complete

6

However, to just briefly preview one way in which a resolution of this problem can work, we can augment the concept of a well-defined state of a classical
computation with that of a well-defined state transition, as we do in §2.1.4; this can be meaningful even for non-reversible and/or stochastic operations.
Then, at any moment across an extended, asynchronous machine, we can say that each local subsystem is either in a well-defined computational state, or
is partway through a well-defined state transition.

7 of 68

projective measurement7 of the state of the entire computer system S down onto the basis
B at time t, and the measured state |ψi in that basis were found to be one of the basis states
~b ∈ Bc , then the computational state is unambiguously interpreted to be c. It follows from this
that any superposition of the ~b ∈ Bc must also be unambiguously interpreted as c, since such
a superposition is not distinguishable from the members of Bc ; if any such superposition state
were measured in the basis B , the projected state would necessarily be contained in the set Bc .
We note that, when the physical state of a machine is dynamically evolving over (continuous) time, the basis states making up the set Bc could also generally be evolving; for example,
consider an information-bearing signal pulse propagating down a transmission line, which
may be convenient to represent in terms of a basis that propagates down the line along with
the pulse. When discussing such cases, we can write Bc (t) to explicitly denote the possible
time-dependence of the physical basis-set representation of a given computational state.
However, as mentioned above, we will often assume, for simplicity, that there exists
some discrete set of designated time points τ` ∈ R (where ` ∈ Z) at which the computational
states are well-defined, and focus our attention on those; this will then allow us to characterize
non-reversible and stochastic computational evolutions in between those designated time
points, in which there are merging or splitting of computational states, at a more abstract level
in our model, without having to specify all details of the transition process, such as when,
exactly, the computational states split or merge (and indeed, physically, these transitions will
in general not be sharp).
However, it follows from the assumption that, at designated time points t = τ` , each
Bc (τ` ) identifies c(t) unambiguously, that, at least at these times, all of the Bc are mutually
orthogonal to each other, and thus can be taken to be disjoint subsets of a single "master"
orthonormal basis B(t); i.e., ∀c ∈ C (t) : Bc (t) ⊂ B(t). We call such a master basis a protocomputational basis for the system S; "proto" because the basis states unambiguously determine
the computational state, but are not in general uniquely determined by the computational
state. They are lower-level, physical entities, defined prior to the computational state itself.
Note that any particular proto-computational basis B(t) at a designated time point
t = τ` , since it is defined to be a complete basis for the Hilbert space HS of the physical system
comprising our computer, may in general include some basis states ~b that do not fall into any
of the sets Bc (t). These are microstates of the system that do not correspond to well-defined
computational states. Such microstates could arise in practice for any number of reasons;
e.g., such as if the machine has not yet been initialized, or it has broken down, or simply
gone out of spec. Regardless of the cause, we will group these "invalid" basis states together
S
into a special set B⊥ = B − c∈C Bc meaning that the computational state is undefined; for
convenience, we can also define an extra "dummy" computational state c⊥ representing this
undefined condition, and an augmented computational state set C ⊥ = C ∪ { c⊥ } so that then
we can say that the system S always has some computational state c ∈ C ⊥ , although it may be
the undefined state c⊥ . With this change, note that the set { Bc } of basis sets corresponding to
all of the computational states c ∈ C ⊥ (in the augmented set) now corresponds to a proper
set-theoretic partition of the full proto-computational basis B . See Figure 2.
Note that the foregoing treatment of computational states is really no different, fundamentally, from the case of identifying any other (potentially macroscale) classical discrete state
variable. In other words, a classical computational state, in our formulation, can be viewed as
simply being a discrete macrostate that we happen to consider as carrying some informational
significance within a computational system.

7

Please note that this definition of computational states does not require us to actually be able to do these complete projective measurements in practice; it
is sufficient, for purposes of the definition, that they could be done in principle, by (we can imagine) applying a suitable abstract operator that measures
some complete set of commuting observables of the system.

8 of 68

(a)

(b)

Figure 2. Model of classical digital computational states (at some particular time t = τ` ∈ R). (a) Abstract
computational states of a physical computer system S with n distinct states. The "catch-all" state c⊥
represents the condition that the physical state of S is such that the computational state is not otherwise
well-defined. (b) Basis sets Bi corresponding to the computational states ci , where i ∈ { ⊥, 1, . . . , n }.
Here, n = 2. These basis sets form a partition of the complete proto-computational basis B .

2.1.2.3. Computational and non-computational subsystems.
As an additional, but inessential assumption that will be useful in some derivations,
we can suppose that the Hilbert space HS of the system can be factored as a product of
subspaces corresponding to what we call computational and non-computational subsystems C, N
of the computer system S. That is, we write HS = HC ⊗ HN , with the idea being that the
computational states c correspond to basis vectors of HC , which are tensored with the basis
vectors of HN to obtain the protocomputational basis B for the entire system S.
However, this factorizability assumption is really a special case, which only holds when
the basis sets Bc of the whole system are identically sized. More generally, we can express HS
as a subspace sum:
M
c
HS =
HN
,
(2)
c∈C ⊥
c
HN

where
denotes the Hilbert space of the non-computational subsystem N, when restricted
to the case that the computational state is c; that is, it is the subspace spanned by the basis
vectors in Bc . See Figure 3.
2.1.2.4. Rapid collapse of superpositions.
In the course of the real physical evolution of the system S, it is of course possible, in
general, that quantum states could arise that are superpositions of basis states ~b from different
basis sets Bc and exist in the system briefly, yielding an indeterminate computational state
at such moments. However, since our primary focus, in the present paper, is on the analysis
of machines that are not even designed to carry out quantum computing, it is reasonable to
suppose that such superposition states will spontaneously decohere on very short timescales,
as they would naturally tend to do anyway in most large-scale systems. In other words, we
expect that, most of the time, our computational subsystem C will be living in a decoherencefree subspace (DFS), such that the computational states are naturally stable, as part of the
system's "pointer states" [21] towards which the system is continually being decohered by
its interactions with its environment. (In this context, the environment of the computational
subsystem C can include portions of the non-computational subsystem N of the computer
system, as well as the machine's external environment E.)

9 of 68

Figure 3. Breakdown of the computating system S into computational (C) and non-computational (N)
subsystems. The Hilbert space of S can be expressed as either a product HS = HC ⊗ HN of subsystem
L
c .
subspaces, or more generally as a subspace sum HS = c∈C ⊥ HN

Thus, at least in the case of a logically deterministic (non-stochastic) computational
process starting from a well-defined initial computational state c(τ0 ), we assume that each of
the system's pointer states will, at any designated time τ` (for ` > 0), have all (or nearly all) of
its probability mass concentrated within a single well-defined computational state c(τ` ). (And
even in a stochastic computation, we will obtain a classical statistical mixture of computational
states, not a quantum superposition over them.)
The challenge, in reversible computing, is then to arrange for the system's already naturally stable pointer states to (notwithstanding their stability) still remain subject to undergoing
a physically natural (if engineered) dynamics in which they will evolve, relatively quickly over
time, translating themselves (eventually) one-to-one into new computational states c(τ`+1 ),
which may bear new semantic interpretations. Such a system could thereby carry out useful
computations at useful speeds.
We will discuss computational operations, and their physical correlates, in more detail
in §§2.1.3–2.1.5. These can be very directly embedded in open quantum systems exhibiting
GKSL dynamics, which we discuss in detail in §3.5.
But, even just the above definitions already suffice to prove what we call The Fundamental
Theorem of the Thermodynamics of Computing; this is discussed in §3.1.
2.1.2.5. Timing variables.
One nearly ubiquitous feature of engineered physical computing systems is the concept
of a timing variable, that is, some non-computational, non-equilibrium degree of freedom
that influences when transitions between computational states will occur, and possibly how
long they will take. As an example, an ordinary synchronous digital computer normally
includes at least one clock oscillator, which outputs a periodic clock waveform at a prespecified
or controllable frequency which is used to control the timing of digital operations. In such a
situation, we can take the phase θ of the oscillator as a timing variable. In adiabatic circuits
(see §2.3.1), not only the frequency but also the speed (quickness) of digital state transitions is
controlled by the clock speed ω = dθ/dt.
Furthermore, even non-synchronous computing systems typically still have physical
degrees of freedom that influence the timing of transitions. For example, in the novel BARC
(Ballistic Asynchronous RC) computing paradigm being developed at Sandia, discussed
further in §2.3.5 below, individual bits propagate ballistically as flux solitons (fluxons) traveling

10 of 68

along interconnect lines between devices; the position x of a given fluxon (of a given velocity)
along the length of its interconnect can be considered a timing variable.
It is important to note that, while the values of timing variables are not digitally discretized, they are also generally not entirely random, or uncorrelated to other parts of the
machine, unlike thermal state variables. Thus, timing variables will be the one common
exception, in digital computating systems, to our general rule that non-computational degrees
of freedom will be assumed to rapidly thermalize.
Next, we define some key concepts of classical computational operations.
2.1.3. Computational Operations
In order to discuss in detail the thermodynamic implications and limits of performing
classical digital computational operations (including reversible operations), we first present
some basic terminology and definitions relating to such operations in this subsection.
As mentioned, in general the set C (τ` ) of well-defined computational states could be
different at different designated time points τ` , but, to simplify our presentation, we will
temporarily focus on the case where it is unchanging, i.e., ∀` ∈ Z : C (τ` ) = C.
To permit treatment of stochastic (randomizing) computational operations, we define
some related notation. Let P (C) denote the set of all (normalized) probability distributions
over C. For simplicity, to avoid having to deal with normalizability issues, we can assume
that C is finite.8
Then, a (possibly stochastic) computational operation O on C simply refers to some arbitrary
function O : C → P (C) mapping each initial state cI ∈ C to a probability distribution over
the possible final states cF ∈ C. For a given initial computational state ci , we can write
O(ci ) = Pi ∈ P (C) where Pi : C → [0, 1] denotes the resulting probability distribution over
final states. We can also allow O to be a partial function, e.g., when discussing operations that
are not defined over all states c ∈ C, which can be useful if the operation will only ever be
applied to states c ∈ dom[O] ⊂ C.
Note that it is sufficient, for our present purposes, to use probabilities in this definition
instead of complex amplitudes, since, for classical reversible computing systems, we are going
to assume that the system is highly decoherent in any case; any superposition over different
computational states would soon decohere to a classical statistical mixture.9
2.1.3.1. Deterministic operations.
A particular computational operation O is called (fully) deterministic (meaning, nonstochastic) if and only if all of its final-state distributions Pi have zero entropy, that is, ∀c ∈ C :
H (O(c)) = 0 (adopting here the standard entropy functional H (*)). If an operation is not fully
deterministic, we say it is stochastic. We could also have that O is deterministic over a subset
A ⊂ C of initial states, whilst not being deterministic over the entire set C. Such an O can also
be called conditionally deterministic under the precondition that the initial state c ∈ A.
2.1.3.2. Reversible operations.
We say that an operation O is (unconditionally, logically, fully) reversible if and only if there
is no state ck ∈ C such that for two different i, j (i 6= j), both Pi (ck ) > 0 and Pj (ck ) > 0.
Otherwise, we say that O is logically irreversible. We say that O is conditionally (logically)
reversible under the precondition that c ∈ A, for some A ⊂ C, if and only if there is no state

8
9

Indeed, due to the holographic bound [22], if the minimal bounding surface of S has finite area, then the Hilbert space HS , and therefore also HC , must
be finite-dimensional in any event.
However, in the future, we anticipate that the present line of work may usefully be extended to explore dissipation limits for quantum computation as
well; at that point, it would be appropriate to replace the probability distribution Pi (c) with a more general density operator ρi .

11 of 68

ck ∈ C such that, for two different i, j (i 6= j) with ci , c j ∈ A, it is the case that Pi (ck ) > 0 and
Pj (ck ) > 0. In such a case, we could also say that O is reversible over A.
2.1.3.3. Time-dependent case.
Note that it is easy to generalize the above definitions to situations in which the set C
of computational states may be different at different designated times. Let s = τ` , t = τm be
two different designated times, with s < t; then we can write Ost to denote a computational
operation being performed over the time interval from start time s to end time t. Then we
have that Ost : C (s) → P (C (t)), and the remaining definitions (for determinism, reversibility,
etc.) also change accordingly, in the natural way. For an operation taking place between times
s and t (s < t), we can define d = t − s as the delay or latency of the operation, and q = d−1 as
its quickness or speed.
The above definitions are illustrated in Figure 4 below.
2.1.4. Computational State Transitions
We can describe the computational operations from the previous subsection as a combination of various primitive computational state transitions, such as those illustrated in Figure 5
below. Other types of transitions may be described as combinations of these. For example,
the lower-left operation in Figure 4 includes a transition of { c1 , c2 } from time s to t that
exhibits both splits and merges. But, as suggested by the arrows in the diagram, it could be
decomposed into a sequence of a split of c2 into two (unlabeled) states, followed by a merge
of c1 into one of those states.
2.1.5. Correspondence Between Classical Operations and Quantum Evolution
In this subsection, we give a general theoretical picture regarding how a real (ergo,
quantum-mechanical) physical process may effectively implement classical computational
state transitions, and computational operations, such as described above.
2.1.5.1. Unitary dynamics.
As before, we focus our attention on a computational process taking place between two
designated time points s = τ` and t = τ`+1 (where t > s). Consider, now, the joint Hilbert
space HU of the model universe (the environment together with the computer). Whatever is
happening physically in the universe over the time interval [s, t] (including the performance
of the computational operation) will be encompassed, in a theoretical perspective assuming
perfect knowledge of the universe's dynamics, by the overall time evolution operator, which
b =U
b st (U), that applies between those times in HU . Formally, if we describe
we will denote U
the initial quantum state of the model universe as a mixed state using an initial density matrix
ρs , then the final density matrix ρt is given by
b sU
b †.
ρt = Uρ

(3)

This overall time evolution process includes activities such as the dynamical details of the
computation process itself, together with the incremental delivery of some needed free energy
from the power supply (e.g., battery) into that process, and the transport of some incremental
amount of dissipated energy (waste heat) away from that process, or more precisely, the
incremental progression of a continuous flow of waste heat that is propagating away from the
computational mechanism, and out towards the environment E-since in general, the waste
heat that resulted from prior operations will still be traveling outwards when subsequent
operations occur. We call this picture the open system case.

12 of 68

Figure 4. Illustration of different types of computational operations Ost on a set C of 3 computational states. Examples shown
here are partial functions-O(c3 ) is not defined. At upper-left is a conventional (deterministic but non-reversible) computational
operation which merges two initially distinct computational states. At upper-right is a deterministic, reversible operation which
is injective (one-to-one) over the subset A = { c1 , c2 } of initial states for which it is defined. At lower-right is a stochastic but
reversible operation which does not merge any states, but splits the state c2 (with some nonzero probability to transition to
either c1 or c3 ). Finally, at lower-left is a stochastic, irreversible operation which includes both splits and merges.

Now, let us restrict attention temporarily to the subspace of HU that is the Hilbert space
HS of the closed spacelike hypersurface (slice of spacetime volume) enclosing the computer
system. Ignoring, for the moment, the flow of waste heat through the system's bounding
surface, let us pretend for a moment that the dynamics within the surface itself can also be
b st (S) over HS , the quantum subsystem
described by a unitary time-evolution operator U
contained within the boundary. We call this the closed system case.
Of course, the closed-system picture is a simplification, since in reality, no thermal
isolation is perfect, and so there will also be interactions across the surface, to transport
heat out. However, we expect that theoretical developments for the closed-system case can
generally be preserved when re-expanding the model to include the outward thermal flow,
since the net effect of that flow will just be to maintain a reasonable temperature inside the
boundary, by exporting excess thermal entropy to the environment.
An easy way to see that this translation from the closed-system to the open-system case
ought to work, in general, is simply to note that if the bounding surface of S is taken to be
extremely distant to begin with, then there will be negligible practical difference between the
open-system and closed-system cases. I.e., a real computer with an internal power supply
would operate just fine, at least for a while, even if enclosed in a very large, but finite, perfectly
thermally insulated box.

13 of 68

(a)

(b)

(c)

Figure 5. Illustration of different types of computational state transitions between two designated time points s and t, showing
the protocomputational basis state sets Bc corresponding to computational states c. All of the individual basis states ~b = ~b(τ )
are also implicitly time-dependent in general. Reversible computational operations include only one-to-one transitions such
as (a). In such transitions, the initial and final basis state sets may be the same size N, even in a closed system. Irreversible
computational operations include at least some examples of many-to-one transitions (merges), such as (b). In a closed system,
the basis state set resulting from a merge must be (at least) as large as the sum of the merged sets, due to unitarity. Stochastic
operations include one-to-many transitions (splits), such as (c). Each of the basis state sets resulting from a split may be smaller
than the original set, even in a closed system, although their aggregate size must be at least as large.

b st to be the one for
Thus, henceforth in this subsection, we will take the time-evolution U
the computer system S, in the closed-system picture, while remembering that we can revert
to the open-system view when necessary.
Earlier, we noted that the protocomputational basis B may, in general, be time-dependent,
so that the two bases B(s) and B(t) may not correspond to exactly the same set of physical
quantum states. However, the effect of any change in the protocomputational basis B between
b B(t) . Then,
times s and t can also just be represented as a unitary operator, which we denote U
B(s)

b st (S) as:
we can define a suitably "basis-corrected" version of U
b st (S, B) = U
b B(t) * U
b st (S).
U
B(s)

(4)

2.1.5.2. Quantum statistical operating contexts.
Next, we need to define a computational process in a statistically-contexualized form. Earlier, we abstractly defined computational state transitions and computational operations, but
this definition said nothing whatsoever about the statistics of the initial state (either computational or physical) before the operation was performed. We require a formalism for describing
such information in order to speak meaningfully about the informational or thermodynamic
effect of performing a computational operation within a particular, statistically-defined scenario.
The following presentation generalizes the discussion of (classical) statistical operating
contexts that can be found in, e.g., [9], to a quantum context.
Since we want to produce a quantum-mechanical model of classical computation (including reversible computation), we require a quantum statistical picture. Thus, let us define ρs
to be a mixed quantum state (i.e., a statistical mixture of pure states, in some diagonal basis)
that encompasses all of our uncertainty, as modelers, regarding what the initial quantum

14 of 68

Figure 6. Block-diagonal density matrix for an initial quantum statistical operating context ρs . In this example, we imagine
there are 3 computational states c1 , c2 , c3 (and let c⊥ = c3 , say) with corresponding basis state sets B1 , B2 , B3 (left). At the center,
we illustrate a corresponding block-diagonal quantum statistical operating
D contextE or initial density matrix ρs . Rows and columns

are labeled in gray with the corresponding basis vectors; note that bi ρs b j = rij . This is an Hermitian matrix, so rij = r ∗ji .
Also Tr[ρs ] = 1. Matrix entries left blank are 0. At right is a simplified depiction of ρs .

state of the physical computational system S is at time s, prior to performing the desired
computational operation Ost .
We further require that ρs must have a block-diagonal structure in the initial protocomputational basis B(s), such that the blocks correspond to the partition { Bc } of basis vectors
corresponding to the (augmented) initial computational state set C ⊥ (s). Stated more formally,
the density matrix representation of ρs in the B(s) basis must not include any nonzero, offdiagonal terms between basis states ~b p ,~bq ∈ B(s) such that ~b p ∈ Bi and ~bq ∈ B j where Bi , B j
are the subsets of B(s) corresponding to two distinct computational states ci , c j ∈ C ⊥ (s), i.e.,
with i 6= j. See Figure 6.
This block-diagonal structure models our assumption, mentioned earlier, that a classical
computer is highly decoherent; thus, there are no quantum coherences between the blocks
corresponding to different computational states. However, it is permissible for coherences to
exist within blocks. This is just another way of saying that the choice of protocomputational
basis vectors is completely arbitrary within the subspace corresponding to each block; the
sub-basis for any block can be freely rotated within its subspace, and we still will have a valid
protocomputational basis for time s.
2.1.5.3. Quantum contextualized computations.
Now that we have defined the quantum version of a statistical operating context, we can
define what a "quantum-contextualized computation" means. This generalizes the discussion
of (statistically contextualized) computations that can be found in [9].
A quantum-contextualized computational process or just quantum-contextualized computation,
denoted Cst (Ost , ρs ), refers to the act of carrying out a specified computational operation Ost
from time s to t > s within the computer system (S) in a quantum statistical operating context
wherein the initial mixed state of S at time s is given by ρs ; where ρs meets the conditions
(i.e., block-diagonal structure) described above, given the protocomputational basis B(s) and
computational state set C (s). (Note that B(s) and C (s) are left implicit in the Cst (*) notation
for brevity.)
2.1.5.4. Implementation of classical computation by unitary dynamics.
Given the above definitions, we can now formally define what it means for a system's
unitary dynamics to implement a given (classical) computation.

15 of 68

b st (S, B) implements the quantum
We say that the basis-adjusted time-evolution operator U
t
t
contextualized computational process Cs (Os , ρs ), written
b st (S, B)
U

Cst (Ost , ρs ),

(5)

if and only if the final density matrix
b st (S, B)ρs U
b st (S, B)†
ρt = U

(6)

b st (S, B) to ρs has the property that, for any initial computational state
generated by applying U
ci (s) ∈ C (s) that has nonzero probability under ρs , if we were to zero out all elements of ρs
outside of the rows/columns corresponding to ci (s)'s basis set Bi (s) and renormalize, and
b st (S, B) to this restricted ρ0s , the resulting final mixed state ρ0 would imply the
then apply U
t
same probability distribution Pi (t) over final computational states in C (t) as is specified by
applying the stochastic map Ost to the initial computational state, that is, Pi = Ost (ci (s)).
One can see by inspection that this is a very straightforward and natural definition.
Since, by assumption, the initial quantum statistical operating context ρs has no coherences
between different initial computational states, it is impossible for the transition amplitudes
from initial to final basis states to interfere with each other in ways that would disrupt the
overall probability distribution over final computational states from what one would obtain
by simply combining the results from treating the initial computational states separately.10
Note that the above definition doesn't by itself immediately require that the unitary evolub st (S, B) can't introduce any immediate coherences between different computational states
tion U
ci (t), c j (t), where i 6= j, but, this is unproblematic, since one of our background assumptions
throughout this treatment is that the system will naturally decohere very quickly to a definite
computational state, so, any off-diagonal matrix elements between different computational
states that may arise will naturally decay by themselves very quickly. This can happen via
the usual Zurek process [21], wherein the decoherent state variables entangle with nearby
non-computational degrees of freedom, which then-at least, in the open-system version
of this treatment-carry the associated quantum information out to the external thermal
environment E. Once it's in that environment, taking the trace over the environment state
to reflect our ignorance about the environment's detailed evolution then effectively erases
the entanglement between the system S and the environment, and decays the coherences
between the different naturally-stable "pointer states" of the computer. In Zurek's terms, the
natural interaction between the computer system and its environment effectively "observes"
the state of the system, and this effective measurement of the system by the environment
collapses the system down to (what is then effectively just a classical statistical mixture of) the
observably distinct classical computational states.
At this point, having described what it means, in quantum physical terms, to perform
classical digital computational operations, our problem in building quantum physical models
of reversible computing has now been reduced to:
1.

10

b st (S, B) that meet the above
Finding specific closed-system time-evolution unitaries U
definition of the "implements" operator for the case of desired reversible (and/or
conditionally reversible) operations Ost in specific physical setups-and, it's easy to see
that there's no essential loss of generality in starting with the closed-system case, since,
for large enough systems, closed-system evolution should work just fine for a while,
until the system runs out of free energy or overheats.

As discussed in 2.1.5.2, each computational state corresponds to an orthogonal subspace; indeed, for classical computing, each computational state must
be an orthogonal subspace, to prevent quantum coherences between computational degrees of freedom in different computational states. Then, this
statement is a direct consequence of the fact that the full space can be decomposed into the sum of projectors over all of its orthogonal subspaces.

16 of 68

2.

3.

b st (S) can then be extended appropriately
Showing that the closed-system definition of U
to the open-system case where there may be a heat flow out from the system's bounding
b st (U) for the
surface, for consistency with the existence of a global unitary evolution U
model universe that includes the process of heat outflow to the environment-but this
part is expected to be a relatively easy formal technicality. And finally,
Showing that some such unitaries can indeed be implemented via realistic, buildable
physical computing mechanisms. Of these three steps, this one is expected to be the most
difficult one to accomplish in practice.

However, the supposition that the above physical picture of classical reversible computing can, in fact, be realistically implemented is supported by the illustration of a number of
existing and proposed examples of concrete physical implementation technologies which
appear to accomplish this, which are briefly reviewed in §2.3 below.
But first, we now review some relevant tools and methods from NEQT which can be
used to flesh out the general theoretical framework presented above in more detail.
2.2. Tools and Methods from Non-equilibrium Quantum Thermodynamics
In this section, we review some key theoretical tools and methods from non-equilibrium
quantum thermodynamics (NEQT) that we believe will prove to be invaluable in the effort to
arrive at a more complete understanding of the physics of reversible computing, and relate
them to the more general picture presented above in §2.1.
2.2.1. Resource Theory of Quantum Thermodynamics
First, we review several theoretical tools relating to what is known as the resource theory of
quantum thermodynamics (RTQT), in order to relate them to the broad framework presented
above.
2.2.1.1. Stinespring dilation theorem and thermomajorization.
We briefly summarized the overall open quantum systems perspective in §2.1.1 earlier.
The rules of quantum thermodynamics let us turn the broad intuitions summarized there
into specific statements about the types of transformations allowable on the system S. The
evolution of a general density matrix ρ is given by a completely positive trace-preserving (CPTP)
map ρ 7→ Λt [ρ], also known as a quantum channel or (quantum) dynamical map. The map Λt
maps the initial density matrix to a final density matrix. (Here, t represents the time interval
from the initial time t0 to the final time tf .11 )
Λt [ρ] represents the most generic type of transformation that we can apply to ρ. In
general, the density matrices ρ and Λt [ρ] aren't required to be taken over the same Hilbert
space. In our setup, however, we stipulate that the initial and final Hilbert spaces are the
same (namely, HS ). As the name "CPTP map" suggests, in order for the map ρ 7→ Λt [ρ] to
satisfy the laws of quantum mechanics, we need Λt to preserve the trace of ρ, to preserve
the positivity of ρ, and to preserve the positivity of ρ even when ρ is part of a larger system
(which Λt acts on as a whole). Furthermore, we need Λt to be Hermitian, to be linear, and
finite under the trace norm.
The Stinespring dilation theorem [23] provides a very natural representation of this channel.
This theorem gives the evolution of an open quantum system S in terms of the unitary joint
evolution of the system and the environment together, which together comprise the entire

11

Most generally, a t subscript for a time interval can be taken to specify an ordered pair (t0 , tf ) of start and end times: i.e., the notation doesn't need to
assume time translation invariance per se; but, in the usual case when it is present, for t to specify just the time difference d = tf − t0 is sufficient.

17 of 68

universe (i.e., U = SE). If S starts in the state ρin,S and E starts in the state ρE , the evolution
appears as:
h
i
†
b t,SE (ρin,S ⊗ ρE )U
b t,SE
ρin,S 7→ Λt [ρin,S ] := TrF U
(7)
h
i
b
b
= TrF e−i H (tf − t0 ) (ρin,S ⊗ ρE ) ei H (tf − t0 ) .
As we noted earlier, the final state may not be in the same Hilbert space as the initial state; i.e.,
Λt may not necessarily map S to itself. This is reflected in the fact that we take the final trace
over F ⊆ U, where F may not necessarily be the same space as E. However, for our purposes,
we will always have F = E.
b t,S0 E := e−i Hb (tf − t0 ) as the global unitary evolution operator over all
In (7), we defined U
b=H
bS + H
bE + H
bI,SE is the global Hamiltonian over all of SE, divided
of U = SE. Here, H
bS over S alone, the Hamiltonian H
bE over E alone, and the interaction
into the Hamiltonian H
b
Hamiltonian HI,SE between S and E. This representation forms the basis for both the existing
NEQT results on Landauer's principle, as well as the GKSL framework for examining open
quantum systems. Beyond the rules of quantum mechanics, the only additional assumptions
here are that S is coupled to some environment E which it jointly evolves with unitarily, and
that the initial state of SE can be factorized [24].
In terms of the dilation theorem, the set of transformations on ρin,S allowed by thermob t,SE that preserves the total energy
dynamics is simply the set of unitary transformations U
over all of SE. These transformations are explicitly described by the resource theory of quantum thermodynamics (RTQT) [25,26]. In general, quantum resource theories (QRT) provide
a information-theoretic framework for describing all possible operations on a given state ρ,
by describing the information cost of operations and states (in terms of new information we
require about the system) [27]. In particular, QRTs describe the conditions on operations to
act at no additional information cost and provide the conditions on the types of states of new
systems that can be prepared at no additional information cost and appended to the overall
system. These are respectively known as the free operations and free states. In addition to these,
the quantum resource theory provides the conditions on transformations on ρ, known as
the state conversion conditions. The nature of free operations, free states, and the conversion
conditions depends on the specific resource theory.12
bS and the (inverse) environment temIn RTQT, we start with the system Hamiltonian H
h
i

perature β = 1/T. The thermal (Gibbs) states τ := e− β H /Tr e− β H are the maximum-entropy
states, which must necessarily be preserved by energy-preserving unitary operations [28].
Thus, these are the free states of the environment. As such, if we examine a system using the
dilation theorem, it takes no additional information to set the initial state of the environment E
to be the thermal state τE . (Conversely, selecting any other state does involve extra information
not specified in the resource theory; namely, information about the distribution of states over
E.) Setting F = E, this gives us a direct expression for the free operations, which are known as
the thermal operations:
h
i
†
b t,SE (ρin,S ⊗ τE )U
b t,SE
ρin,S 7→ Ξt [ρin,S ] := TrE U
.
(8)
b

12

b

As an example, the resource theory of asymmetry tells us the free operations and states of a system with an overall symmetry described by a compact Lie
group G, with the free operations and conversion conditions given in terms of the unitary representations of G. Operations that are covariant with G and
states that are invariant under G require no additional information beyond the group already specified; thus, these are respectively the free operations
and free states of this resource theory. This example is expanded upon in [27], which also provides the illustrative example of the resource theory of
bipartite entanglement.

18 of 68

The necessary conditions for these transformations
h
i to occur are called the thermomajorization
bS = 0 (i.e., when the final state of S has
conditions. When the commutator Ξt [ρin,S ], H
a definite energy value, as is the case for all of the systems we will be considering), these
conditions are both necessary and sufficient.13
These conditions are defined in terms of the β-ordering hof a statei ρS , which has eigenbS (with ρS , H
bS = 0). The β-ordering
values { pi }in=1 and corresponds to a Hamiltonian H


p↓ = p1↓ , * * * , p↓n is defined [29] as an ordering of the pi that satisfies pi↓ e− βEi ≥ p↓j e− βEj
for all i < j, where Ei is the energy corresponding to pi . (Thus, the β-ordering of the { pi }s
is defined by decreasing values of pi↓ e− βEi .) From this ordering, we can define the thermomajorization curve as the curve defined by the points:14
(
!)

 

n
n
↓
↓
− βE1 ↓
− βE1
− βE2 ↓
− βEi
, p1 , e
+e
, p1 + p2 , * * * , ∑ e
, ∑ pi
.
(9)
(0, 0), e
i =1

i =1

Then, finally, the thermal operation ρin,S 7→ Ξt [ρin,S ] can occur if the thermomajorization
curve of Ξt [ρin,S ] is below or equal to the thermomajorization curve of ρin,S everywhere.
Collectively, the thermal states, thermal operations, and thermomajorization conditions give
us the complete set of states we can generate and transformations we can perform in quantum
thermodynamics.
2.2.1.2. Catalytic thermal operations and correlated systems.
The concept of a thermal operation can be extended to the case of a catalytic thermal
operation (CTO), in which a component of the system is a so-called catalyst subsystem which
cycles back to the initial state. This can be an appropriate model for certain types of subsystems
in a computer-for example, a periodic clock signal, such as a resonant clock-power oscillator
for an adiabatic circuit (see §2.3). Further, every digital data signal in a typical reversible
logic technology (e.g., [30]) cycles from a standard "neutral" or no-information state to an
information-bearing state, and then back to neutral; thus, every node in a typical reversible
circuit effectively acts like a catalyst. (This will be discussed in more detail in §3.4 and §4.2.)
We now present the most general type of CTOs explicitly, following the presentation in
[12]. (Note that this examines a more general class of transformations than the ones traditionally
examined in the second laws of thermodynamics framework; the relationship between this
presentation and the second laws is discussed in §2.2.1.3.) If we divide the overall system S
into the subsystems T and K, the catalyst K is defined as a subsystem which is required within
the overall dynamics of the system for the state transition ρin,T 7→ Ξt [ρin,T ].15 If the state of
the catalyst is given as σK , then the transition of the state (ρin,T ⊗ σK ) is given [12] by:
h
i
†
b t,TKE (ρin,T ⊗ σK ⊗ τE )U
b t,TKE
.
(10)
(ρin,T ⊗ σK ) 7→ ξ TK := TrE U
h
i
b t,TKE , H
bTKE = 0, and TrKE [ξ TK ] is arbitrarily close to Ξt [ρin,T ] under the
Here, we have U
trace norm: for all e ∈ R+ , there are allowed transformations with:

kTrKE [ξ TK ] − Ξt [ρin,T ]k1 < e.

(11)

13

h
i
bS 6= 0 remains an open question [27]; fortunately, that is also beyond the scope of our model.
The case of Ξt [ρin,S ], H

14

It's worth noting that the ordering of the { pi↓ }s may not be unique when some of the pi↓ e− βEi values are equal to each other, but even in this case the
thermomajorization curve is always unique.
The reasons the catalyst is required are not explored in the CTO framework; rather, the CTO framework merely assumes that a catalyst is required.

15

19 of 68

Meanwhile, the catalytic condition requires TrTE [ξ TK ] = σK . This is the most general type
of CTO, which can be realized if and only if the final Helmholtz free energy F is less than or
equal to the initial Helmholtz free energy. Out of equilibrium, the Helmholtz free energy of a
b is given by:
state ρ in a system governed by a Hamiltonian H
h i
b − kT S(ρ).
F (ρ) := Tr Hρ
(12)
Here, S(ρ) is the Rényi-1 entropy (i.e., the von Neumann entropy) of ρ. In terms of F , the
condition we require for the CTO in (10) to be realizable is:16

F (TrKE [ξ TK ]) ≤ F (ρin,T ).

(13)

Notably, these CTOs do not impose any additional major constraints on the shape of the
bK = 0
correlations between T and K: for any δ ∈ R+ , there exists some K and ξ TK such that H
and the quantum mutual information I (T : K) between T and K is bounded by δ:
I (T : K) := S(ξ TK k TrTE [ξ TK ] ⊗ TrKE [ξ TK ]) < δ.

(14)

In practical terms, this means that we can achieve state transitions from ρin,T to TrK [ξ TK ]
by engineering the catalyst and the CPTP map Ξt to minimize the correlation I (T : K). This
process of correlation engineering [9,12] lies at the heart of reversible computing: By engineering
interacting subsystems bearing computational degrees of freedom and the transformations
Ξt applied on them, we can achieve the CTOs given in (10), with the net energy dissipation
given by the free energy difference in (13).
2.2.1.3. Uncorrelated catalytic thermal operations.
The expressions in §2.2.1.2 may come as a surprise to those familiar with thermal operations and catalytic thermal operations. Conventionally, CTOs are defined [25] by the
transformation:
h
i
†
b t,TKE (ρin,T ⊗ σK ⊗ τE )U
b t,TKE
= Πt [ρin,T ] ⊗ σK .
(15)
(ρin,T ⊗ σK ) 7→ TrE U
The data processing inequality (DPI) can give us necessary
conditions for these
CTOs to be
h
i
bTK = 0 [25,31]. For
realized, which become necessary and sufficient when Πt [ρin,T ] ⊗ σK , H
any function f (ρkσ) of the density matrices ρ and σ, and for any CPTP map Λt , the DPI gives:
f (ρkσ ) ≥ f (Λt (ρ)kΛt [σ]).

(16)

In other words, the DPI is a requirement that must be satisfied for all functions f for Λt to
be a valid CPTP map. One family of such functions are the α-relative Rényi entropies (α-RRE),
which are defined [28,32,33] as:



sgn α Tr ρα σ1−α



ln
α ∈ (−1, 0) ∪ (0, 1);


α−1
Tr ρ



 h
 i


 Tr σ(1−α)/2α ρ σ(1−α)/2α α 


Sα (ρkσ ) := sgn α
(17)

ln
α ∈ (−∞, −1) ∪ (1, ∞);

α −1 

Tr
ρ









Tr [ρ (ln ρ − ln σ )]
lim α → 1.
16

In the case that F (ρin,T ) − F (TrK [ξ TK ]) = E, the condition (13) can be extended by including an uncorrelated source W of free energy. In this case, if W has
the states λW and κW with F (κW ) − F (λW ) ≥ E, then we can realize the CTO ρin,T ⊗ σK ⊗ κW 7→ ξ TK ⊗ λW when F (ρin,T ⊗ σK ⊗ κW ) ≥ F (ξ TK ⊗ λW ).
Here, the condition (14) remains. Naturally, if we generalize to the case where correlations between TK and W are permitted, we return to the CTO given
in (10).

20 of 68

The α → 1 limit provides us with the familiar expression for the quantum relative divergence
(QRD)17 . As such, the DPI imposes the requirement that the CTO (15) must satisfy
Sα (ρin,T ⊗ σK kτTK ) ≥ Sα (Πt [ρin,T ] ⊗ σK kτTK )

(18)

for all α as a necessary condition.18 In the case that we have transition from the product state
ρin,T ⊗ σK to the product state Πt [ρin,T ] ⊗ σK , these are in fact sufficient conditions, beyond
being simply necessary ones [36–38]. Thus, (18) tells us the constraints we need to satisfy the
CTOs (15). The Sα (ρkσ ) in turn define [28] the α-Helmholtz free energies:

Fα (ρin,S ) := −kT ln Z + Sα (ρin,S kτS ).

(19)

We can immediately recognize the α = 1 case as equivalent to the expression (12). The CTOs
defined in (15) are realized when we have

Fα (Πt [ρin,T ]) ≤ Fα (ρin,T )

(20)

for all α. These conditions are known as the second laws of thermodynamics [28].
2.2.1.4. Correlated vs. uncorrelated CTOs.
The expressions for the α-RREs in §2.2.1.3 might initially be cause for some concern, since
a CTO must satisfy (20) for all alpha to be a viable transition. This concern may escalate to
alarm when we consider that the α-RREs (and thus the α-free energies) are monotone in α; i.e.,
Fβ (ρ) ≤ Fγ (ρ) for all β ≤ γ. Beyond the standard Helmholtz free energy (F1 ), two notable
cases are the extractable work F0 and the work of formation F∞ . As their names imply, these are
respectively the amount of work we can extract from a given state and the amount of work
it takes to form that same state. Since in most cases we have F0 < F∞ , it would appear that
the energy difference F∞ − F0 is simply dissipated in the process of creating a state and then
extracting work from that state. As a corollary, this would imply that our only hope for a
viable reversible computing framework in this formulation is to find sets of states {ρi } where
the equality between Fα (ρi ) is satisfied for all α, which may be a highly restrictive condition.
As discussed in [12], however, the second laws of thermodynamics (and these attendant
issues) arise from an additional assumption about the shape of CTOs. Specifically, the CTOs
(15) that give rise to the second laws of thermodynamics assume that the final state of S
after the thermal operation is a product state of T and K, i.e., that catalytic thermal operations
transform the state ρin,T ⊗ σK to the state Πt [ρin,T ] ⊗ σK . However, by definition of the catalytic
thermal operation, we needed the presence of σK to induce the transformation to begin
with. Thus, the CTO on ρin,T ⊗ σK necessitates an increase in the QMI between T and K,
specifically given by (14). Indeed, as proven in [12], this mutual information can be made
to be infinitesimally small, but cannot be zero. Thus, the CTO in (15), in which we demand
that the final state of S be in the product state Πt [ρin,T ] ⊗ σK , is more precisely thought of as
performing the general CTO (10) and then ejecting the QMI (14). A direct consequence of this
is that, as proven in [12], in the general CTO (10) where we permit correlations to develop
17

18

The α → 1 limit can be taken either with a monotonically increasing sequence from the α ∈ (0, 1) case, or with a monotonically decreasing sequence from
the α ∈ (1, ∞) case. As with the QRDs, other familiar entropies are recovered as limiting cases of the α-RREs: the 0-RRE S0 (ρkσ) = ln Trsupp ρ [σ] is given

by the α & 0 limit, the max-RRE S∞ (ρkσ) = inf λ ∈ R | ρ ≤ eλ σ is given by the α % ∞ limit, and the S−1 (ρkσ) and S−∞ (ρkσ) cases are given by
interchanging ρ and σ in the arguments. It's also worth noting that the expression for α ∈ (1, ∞) in (17) is the conventional form for the α-RRE at these
values of α; this expression is called the sandwiched RRE. However, because in general ρ and σ do not commute with each other, there are an infinite
number of ways to arrange powers of ρ and σ that satisfy the Rényi entropy axioms [34] and retrieve the appropriate limiting cases. These can all be
expressed as a single two-parameter family of entropies [35], known as the the α-z-RREs.
Indeed, the DPI tells us that a necessary condition for the CTO (15) to be valid is that f (ρin,T ⊗ σK kτTK ) ≥ f (Πt [ρin,T ] ⊗ σK kτTK ) for all functions f of
ρin,T ⊗ σK and τTK .

21 of 68

(a)

(b)

Figure 7. Breakdown of subsystems for purposes of §2.2.2.1, etc. (a) For our purposes in this section, and in much of what
follows, we focus our attention on a subsystem S0 = M of the entire physical computer system (a "memory") that exists for the
purpose of passively registering some computational data of interest, but does not include any active mechanisms for controlling
the timing and performance of state transitions. (b) An example of a density matrix representation of a computational state
of M in the block-diagonal picture from Fig. 6. In this example, the non-computational subsystem of M is assumed to be in a
maximum-entropy mixed state conditioned on the computational state being c = c2 .

between the system and catalyst, the (α = 1) Helmholtz free energy uniquely specifies the
condition required for the transition to take place.19
Consequently, if we seek to develop a framework for computing which reduces energy
dissipation by avoiding the energy cost of expelling the built up QMI, our computing operations must follow the CTO expression given in (10). Since reversible computing is precisely
this framework, (10) provides an explicit expression for the shape of reversible computing
operations in terms of CTOs. As a trade-off, we achieve these operations via a buildup of QMI
(14), which can be made arbitrarily small but cannot be precisely zero. In the framework of
reversible computing, this is an acceptable (indeed, preferred) trade-off to make20 .
2.2.2. Quantum Mechanical Models of the Landauer Bound
The general CTOs given in [12] and discussed in §2.2.1.2 further give us a conceptual
framework for understanding the nonequilibrium Landauer bound [10] and the difference
between conditional and unconditional Landauer state reset [40]. First, we briefly review
the Landauer principle, following the excellent presentation found in [40], before connecting
these to the nonequilibrium Landauer bound and the general CTOs found in their respective
former references.
2.2.2.1. Conditional vs. unconditional Landauer erasure.
Here, and in much of what follows, we restrict our attention to a subsystem S0 = M
of the entire computer system S that plays the role of passively registering data; we can
generically call such a subsystem a "memory," without implying any particular architectural
structure (i.e., it could be any information-bearing set of signals in the machine). This is to
be distinguished from other components that actively manipulate the state of the machine
19
20

Thus, [12] verifies the conjecture first provided in [39]: in the words of [39] directly, "the [(α = 1) Helmholtz] free energy is singled out as a measure of
athermality".
As pointed out in [12], the more general CTOs (10) aren't necessarily an improved form of the CTOs (15), but rather simply offer a different setup. In lieu
of the unavoidable free energy differences F∞ − F0 , we've accepted the unavoidable buildup of QMI as a trade-off. For our purposes here, building up
QMI and engineering the system and CTO to minimize the QMI and the difference kTrK [ξ TK ] − Ξt [ρin,T ]k is preferred, but the optimal type of CTO will
in general be a function of the type of process we're interested in.

22 of 68

and control the timing of operations, which we will assume are separated into another
subsystem Z which will usually be left implicit. See Figure 7(a). However, note that even
M, as a physical system, can still be separated into computational and non-computational
subsystems as in Fig. 3, and thus (assuming, as usual, no coherences between digital states)
still has states in block-diagonal form as in Fig. 6. Each computational state ci ∈ C of M thus
has a unique corresponding representation ρi,M as a density matrix if we assume minimal
information about the non-computational part of the state, that is, taking it to have maximum
entropy, given the specifications as to what constitutes the set Bi of microstates of M validly
representing the given computational state ci in a given technological scenario. See Fig. 7(b).
Note that the following discussion blurs the distinction between these density matrices and
the abstract states ci that they represent, and calls them "computational states" even though,
in the density matrix form, they are also manifestly physical entities.
Now, for a subsystem S0 = M carrying some computational degrees of freedom, the
Landauer state reset process, following [40], is the process by which the state ρ`,S0 is set
to some standard reset state ρr,S0 . In a practical implementation of general computational
operations on the system S0 which bears computational degrees of freedom, the reset state is
essential to what we consider the sensible functioning of the operations on the system. The
reset state is a standard, known reference state; when we perform operations on the system
which correspond to operations, we transform the system from ρr,S0 in a known way such
that the operations we perform on ρr,S0 correspond to sensible computational operations. The
end result of this series of operations will be the final computational state, which we then
need to reset to the standard state in order to perform a new set of operations.
In general, we expect the computer to have a possibly large, but finite number N of total

N
possible computational states ρ`,S0 ` = 1 that it
 can be in at any time. Then, the reset process
we're interested in is the set of the CPTP maps ρ`,S0 7→ ρr,S0 for all ` ∈ {1, * * * , N }. We can
start by taking these operations to be thermal operations of the form (8):
h
i


 †
b `,t,S0 E ρ`,S0 ⊗ τE U
b
ρ`,S0 7→ Ξ`,t ρ`,S0 := TrE U
0
`,t,S E
(21)
= TrE [ρfc,U ] = ρr,S0 .
(As before, τX denotes the thermal / Gibbs state in the system / subsystem X.) Here, we've
defined ρfc,U as the final global state of the entire universe U = S0 E following application of

b `,t,S0 E evolution to ρ`,S0 ⊗ τE :
the U
 †
b `,t,S0 E ρ`,S0 ⊗ τE U
b
ρfc,U := U
`,t,S0 E .

(22)

b `,t,S0 E over all of U is to transform the
Crucially, the effect of the unitary evolution operators U
set of N initial states into the same final state over all of U, given by ρfc,U . The overall unitary
b `,t,S0 E are given by:
evolution operators U
b `,t,S0 E
U




i
= T exp −
 h̄



i
= T exp −
 h̄

Ztf

b
dt0 H



t0

Ztf
t0




h

b S0 + H
bE + H
bI,S0 E + V
b`r,S0
dt0 H


i

(23)
.



b we outlined in (7), we also explicitly pulled
Here, in addition to the terms contributing to H
b
out the reset Hamiltonian V`r,S0 . Note that the reset Hamiltonian is applied solely to S0 .

23 of 68

n
o
b `,t,S0 E of unitary operators is that we
An extremely important feature of the set U
have a unique operator for each state ρ`,S0 , and that the distinctiveness of each of these
b`r,S0 is individualized for
operators comes solely from the fact that the reset Hamiltonian V

each ρ`,S0 . Each of these operators gives us a distinct CPTP map Ξ`,t ρ`,S0 . As a result, the
expressions (21) and (23) correspond to conditional Landauer reset; i.e., the process of resetting
b `,t,S0 E is
the computational state ρ`,S0 to the standard state ρr,S0 where the reset protocol U
conditioned on the specific state ρ`,S0 . In other words, the process of conditional Landauer
b `,t,S0 E (and, even more specifically, selecting V
b`r,S0 ) for each ρ`,S0
erasure involves selecting U
such that the final state ρfc,U is the same for any initial state ρ`,S0 ⊗ τE we choose.
A central quantity of interest in the Landauer reset process is the lower bound on the
amount of energy transfer (a.k.a. the dissipation) from the system to the environment. This
can be calculated by examining the change in the environment energy ∆ E`,E during the
evolution (21). In terms of this evolution, the final state of the environment is given by:
h
i
 †
b `,t,S0 E ρ`,S0 ⊗ τE U
b
ρfc,E = TrS0 [ρfc,U ] = TrS0 U
(24)
0
`,t,S E .
Because ρfc,E is the same for all `, we can directly examine the energy increase of the environment as a result of conditional Landauer reset protocol applied to any of the initial
states:
h
i
h
i
bE − Tr τE H
bE
∆ E`,E = Tr ρfc,E H
c

h
h
i i
h
i
 †
b
b `,t,S0 E ρ`,S0 ⊗ τE U
bE − Tr τE H
bE .
= TrE TrS0 U
H
0
`,t,S E

(25)

(Here, the subscript c indicates that this is specifically for the conditional Landauer reset.)
From the strong subadditivity of the von Neumann entropy and from Partovi's inequality,
∆ E`,E c has a lower bound given by [40]:



∆ E`,E c ≥ −kT ln 2 ∆S`,S0 := −kT ln 2 S Ξ`,t ρ`,S0 − S ρ`,S0 .
(26)
Here, ∆S`,S0 is the change in the von Neumann entropy between the initial and final states
of S0 . Thus, when the reset protocol is given as in (21), the sole contribution to the bound
on dissipation into the environment is given by the change in entropy in S0 induced by the
b `,t,S0 E .21 Notably, when the initial states and final state have the
overall unitary evolution U
same von Neumann entropies, the expression ∆S`,S0 is zero, and thus the lower bound on
dissipation is zero in this case.
By contrast to the conditional Landauer reset, we can also define
 the unconditional Landauer reset protocol, in which transitions from each of the states ρ`,S0 to the reset state
br,S0 to any of the states ρin,S0 that
ρr,S0 are achieved by applying a single, standard potential V

21

As a reminder, the unitary dynamics over S0 E by construction cannot increase the entropy over S0 E as a whole [21,41]. Since we don't a priori assume
b `,t,S0 E maps S0 E product states to S0 E product states, however, this can still increase the subsystem entropy of S0 .
that U

24 of 68

S0 may be in. Thus, in lieu of the set of N unitary operators given in (21), we have a single
unitary operator for all of the states defined by:



b u,S0 E = T exp − i
U
 h̄



i
= T exp −
 h̄

Ztf

b
dt0 H





t0

Ztf

h

b S0 + H
bE + H
bI,S0 E + V
br,S0
dt0 H


i

(27)
.



t0

The corresponding set of thermal operations in this case are given by:
i
h

 †

b 0 = ρr,S0 .
b u,S0 E ρ`,S0 ⊗ τE U
ρ`,S0 7→ Ξ ρ`,S0 := TrE U
u,S E

(28)

The set of evolutions given in (28) provide a sharp contrast with those given in (21). In
b`r,S0 such that U
b `,t,S0 E mapped every ρ`,S0 ⊗ τE to the same final state ρf,U .
(21)), we chose V
By contrast, in (28) we have only a single unitary operator for every possible state under
b u,S0 E maps each ρ`,S0 ⊗ τE to a different global final state:
consideration. As a consequence, U
oN

n
ρ`, f ,U

`=1

n
oN
 †
b u,S0 E ρ`,S0 ⊗ τE U
b 0
:= U
u,S E

`=1

.

(29)

b u,S0 E is to produce a
In other words, for each ρ`,S0 , the result of the evolution given by U
distinct final state over all of U. The only constraints on the evolutions in (28) (and thus, on the
states ρ`, f ,U ) beyond the laws of quantum mechanics and quantum thermodynamics is that
h
i
the final subsystem state of S0 must be the reset state: we require TrE ρ`, f ,U = ρr,S0 for all `.
Because each of the final global states is different, the energy increase of the environment
(calculated as in (25) and (26)) will be a distinct expression for each initial state. However,
we can collect these expressions together by examining the average energy increase of the
conditional and unconditional Landauer resets, over a collection of reset operations performed
over a set of individual states. If the states ρ`,S0 appear in our collection a fraction of p` times,
then the average energy increase of the environment will be given by:22
"
"
# #
h
i
N
 †
b `,t,S0 E ρ`,S0 ⊗ τE U
b
bE − Tr τE H
bE ;
(30)
∆ E`,E
= TrE TrS0 ∑ p` U
H
0
c

`,t,S E

`=1

∆ E`,E

N

c

≥ −kT ln 2

∑

p` ∆S`,S0 .

(31)

`=1

We can compare these expressions to the average energy increase
 and average energy bound
of the unconditional Landauer reset protocol across all of the ρ`,S0 s. Since convex linear
combinations
 of density matrices form another density matrix, we can express the weighted
sum of the ρ`,S0 s as a new fiducial density matrix ρin,S0 :
N

ρin,S0 :=

∑

p` ρ`,S0 .

(32)

`=1

22

We can alternately think [40] of this as a series of conditional or unconditional Landauer resets, respectively, over a single joint system S0 E, with the
population fractions representing the number of times S0 E is set to that state.

25 of 68

Then, the average energy increase of the unconditional Landauer reset protocol corresponds
[40] to the average energy increase of ρin,S0 :
"
∆ E`,E

u

"

N

b t,S0 E
= TrE TrS0 U

∑

#

!

#

h
i
bE − Tr τE H
b† 0 H
bE
p` ρ`,S0 ⊗ τE U
t,S E

`=1

h

(33)

h

i

i

h

i

bE − Tr τE H
bE .
b t,S0 E ρin,S0 ⊗ τE U
b† 0 H
= TrE TrS0 U
t,S E


b t,S0 E is independent of `, we were able to move the sum inside the
(In this expression, since U
expression.)
As with (26), the strong subadditivity of the von Neumann entropy and Partovi's inequality gives [40] a lower bound on ∆ E`,E u in terms of the entropy:
∆ E`,E
∆ E`,E

N

u

≥ −kT ln 2

∑


p` ∆S`,S0 + log2 p` ;

`=1
N

u

≥ −kT ln 2

∑

(34)

!
p` ∆S`,S0 − ∆Ier,S0 .

`=1

Here, we recognize ∑`N= 1 p` log2 p` =: − H ({ p` }) = ∆Ier,S0 as the Shannon entropy of the
distribution { p` }, which is equivalent to the information quantity transferred from S0 to E.
As before, when the initial states and final state have the same von Neumann entropies, the
expression ∆S`,S0 is zero. In this case, the lower bound on the unconditional Landauer reset
protocol is given entirely by the amount of correlated information transferred from S0 to E.
In the last sentence, it may seem like the word "correlated" was picked out of the aether.
As presented thus far, it may be unclear what correlations arise in the Landauer protocol23 . In
fact, the correlated nature of ∆Ier plays a central role in understanding the conditional and
b`r,S0 and
unconditional Landauer bounds. Likewise, the details of where the reset potentials V
br,S0 come from will play a key role in understanding the distinction between these two. We
V
discuss these issues in §3.4, as we tie in this model to the CTO framework.
2.2.2.2. Nonequilibrium Landauer bound.
We can understand the expressions in §2.2.2.1 very straightforwardly from the NEQT
point of view, both from the point of view of quantum thermodynamic fluctuation relations
[10,11] and from the point of view of the general CTOs discussed in the previous section. We
start with a general CPTP map given in terms of the dilation theorem (7) with F = E and a
general environment state ρE ; i.e., a CPTP map given by (henceforth just writing S for S0 ):
h
i
†
b t,SE (ρin,S ⊗ ρE )U
b t,SE
ρin,S 7→ Λt [ρin,S ] = TrE U
.
(35)
If we label the eigenstates of ρE as |ea i, the eigenvalues of ρE as ea , and perform the partial
trace over the basis |vb i of E, then the expression of Λt [ρin,S ] expands to give:
!
!
!
†
b t,SE ρin,S ⊗ ∑ ea |ea ihea | U
b t,SE 1S ⊗ ∑|vb i .
(36)
Λt [ρin,S ] = 1S ⊗ ∑hvb | U
b

23

a

b

By process of elimination, as of now we can guess that these correlations have something to do with the process of conditioning the potential V`,S0 , since
that's the only thing that's different about these two protocols.

26 of 68

The distributivity of the tensor product allows us to write this expression solely in terms of
operators on S. This defines the system Kraus operators (usually simply the Kraus operators [42])
as:
E
√ D
b ab := ∑ ea vb U
b t,SE ea .
(37)
M
a, b

b t,SE and the
It's worth noting that the Kraus operators are dependent on the global operator U
environment expressions |ea i, ea , and |vb i, but as operators themselves solely map density
b ab dependent on quantities
matrices over HS to HS . In other words, even though we have M
b
outside of S, neverthelessnwe have
o Mab ∈ Aut(D(HS )) when considering it as an operator.
b
Also note that a given set Mab of Kraus operators is emphatically not unique: any unitary
rotation of the basis |vb i defines a new set of Kraus operators.
Any given set of Kraus operators satisfies the completeness relation:

∑ Mb ab† Mb ab = 1.

(38)

a, b

The Kraus operators in turn give the operator-sum representation of the CPTP map Λt [ρin,S ]:
Λt [ρin,S ] =

∑ Mb ab† ρin,S Mb ab = 1.

(39)

a, b

From the Kraus operator completeness relation (38), the (Hölder) dual of any CPTP map is
always unital; i.e., for any CPTP map Λt , we always have Λ†t (1S ) = 1S . The same may not
necessarily be true for Λt itself; instead, the unitality condition for Λt is given in terms of the
Kraus operators by the condition:

∑ Mb ab Mb ab† = 1.

(40)

a, b

Unital channels are notable since they map the identity 1S to itself (and thus the maximally
mixed state 1S /Tr[1] to itself): we have Λt [1S ] = 1S only when Λt is unital (by definition).
It's worth noting that even though the Kraus operators themselves can be arbitrarily changed
by a unitary transform, this sum is invariant under such a transform, so the unitality condition
is independent of the specific basis we evaluate the Kraus operators in.
We can very straightforwardly understand the difference between the conditional and
unconditional Landauer reset, and in particular the terms in the unconditional Landauer
bound (34), in terms of the Kraus operators and the unitality condition. In the same way
as we defined the system Kraus operators, we can define the environment Kraus operators
b cd ∈ Aut(D(HE )) as Kraus operators on E. Labelling the eigenstates of ρin,S as |sc i, the
N
b cd as:
eigenvalues of ρin,S as sc , and the basis of S as |wd i, we can define N
E
√ D
b cd := ∑ sc wd U
b t,SE sc .
N
(41)
c, d

Then, as with (8), (21), and (28), we examine the evolution of SE when we couple S initially
in the state ρin,S to the environment E, initially in the thermal state:
†
b t,SE (ρin,S ⊗ τE )U
b t,SE
ρin,S ⊗ τE 7→ U
.

(42)

27 of 68

As with (24), we're interested in the final environment state of E, which can tell us the bound
on the energy increase of E. The final state of the environment as a result of the transformation
(42) is given by:
h
i
†
b t,SE (ρin,S ⊗ τE )U
b t,SE
b cd τE N
b† .
ρf,E = TrS U
= ∑N
(43)
cd
c, d

From this, the probability distribution P( Q) of the environment heat Q in the eigenbasis |ea i
of τE is given [10] by:
D
E
D
E

b cd eh heh | τE | eh i eh N
b † e g δ Q − Eh − E g
P( Q) = ∑ e g N
cd
c, d; g, h

=

∑

D

b cd eh
eg N

E

*
eh

c, d; g, h

+
b
E
D

e− β HE
b † e g δ Q − Eh − E g .
h
i eh
eh N
cd
TrE e− β HbE

This gives the moment-generating function of the dissipated heat given by:
D
E
h
i
h
i
b † τE N
b cd N
b † τE .
b cd = ∑ Tr N
e− βQ = ∑ Tr N
cd
cd
c, d

(44)

(45)

c, d

Then, a direct consequence of Jensen's inequality is that the energy increase in this process is
given in terms of the Kraus operators:
"
#
b cd N
b † τE .
∆h EE i ≥ −kT ln Tr ∑ N
(46)
cd

c, d

This expression immediately helps us understand the conditional Landauer bound (26)
and the unconditional Landauer bound (34): the overall evolution (42) corresponds to a CPTP
map (a.k.a. quantum channel) over E24 . This channel may or may not be unital over E, and
the degree to which this channel fails to be unital is exactly the degree to which the channel
increases the overall entropy of S and expels the information quantity ∆Ier,S to E. The fact
that unital quantum channels map maximally mixed states to maximally mixed states is
essential: the degree to which this channel fails to be unital tells us the extent to which the
channel perturbs the maximally mixed state τE of the environment. Indeed, we see that for a
perfectly unital channel, the sum of the Kraus operators retrives 1E , and the energy bound is
zero.
The degree of unitality stands out as a key quantity of interest in examining the nonequilibrium Landauer bound in a given system. Using the technique of full counting statistics
[43] and the two-time measurement formalism [44], the expressions (45)–(46) can be extended
[11] to a one-parameter family of expressions (replacing β with a more general parameter).
b cd N
b † in the above
This technique gives an explicit way to quantify the non-unitality of N
cd
expressions:

NE :=

∑ Nbcd Nbcd† − 1E
c,d

24

.

(47)

2

It's worth noting that although (46) is slightly unclear compared to (26) and (34), in the sense that Kraus operator expression mixes both the entropy
increase contribution and the correlated information ejection contribution, it serves as the most clear expression from a quantum information theory
point of view, and is also the tightest bound available [10].

28 of 68

b
Here, A

2

represents the Hilbert-Schmidt norm. Finally, from (45), we have the average

energy dissipated into the environment given [10,11,43,45] by:
βh Qi(t) = −∆SS − I (S : E) − S(ρE (t)kτE )


= −S(Λt [ρin,S ]) + S(ρin,S ) − ∆Ier,S − I (S : E) − S ρf,E (t) τE .

(48)

We can immediately recognize this expression as simply the extension of the expressions (26)
and (34) to include the possibility of initial correlations between S and E and the possibility
that the environment may not start out in the thermal state. For our setup, neither of these
conditions are applicable, and thus the last two terms vanish.
We would expect that the environment is not a "special" subsystem in terms of these
derivations, and that an equivalent expression can be derived by considering the system. From
each subsystem's point of view, the other serves as the ancillary system in the dilation theorem
sense. Indeed, expanding the Kraus operators in terms of |sc i and |wd i, and rearranging terms
in the overall trace, provides us with an equivalent expression to (45):
D



E
h
i
†
b t,SE
b t,SE ρin,S .
e− βQ = TrS TrE U
(1S ⊗ τE )U

(49)

h
i
b † (1S ⊗ τE )U
b t,SE is an operator which
As with the Kraus operators, the expression TrE U
t,SE
depends on properties outside of S, but as an operator lives in Aut(D(HS )); i.e., it maps
density matrices in S to density matrices in S. The connection between these expressions to
the conditional and unconditional Landauer reset protocols is apparent, but the connection
between both of these to the CTO framework is slightly more subtle. The connection between
all three is discussed in §3.4.
2.2.3. Gorini-Kossakowski-Sudarshan-Lindblad (GKSL) Dynamics
Beyond providing NEQT justifications for Landauer's principle and providing a new
explanation for the difference between the conditional and unconditional Landauer recent
protocols, another central aim of this work is to lay out the foundations for representing
classical RC operations explicitly in terms of open quantum systems. Here, we discuss the
framework of GKSL equations with multiple asymptotic states [17–19], which we apply in §3.5 to
model reversible computing operations.
2.2.3.1. Markov assumption.
b and whose state at time t is given by
In a closed system governed by a Hamiltonian H
ρ(t), the dynamics are given by the Liouville-von Neumann (LvN) equation:
h
i
dρ(t)
b ρ .
= −i H,
dt

(50)

By analogy with the Liouville theorem of classical statistical mechanics
h and
i symplectic geˆ
b
ometry, we can define [46] the Liouville superoperator as L̂[ρ(t)] := −i H, ρ . This gives the
superoperator version of the LvN equation as:
i
h
dρ(t)
ˆ ρ(t)] := −i H,
b ρ .
= L̂[
dt

(51)

29 of 68

(This is also known in the literature as the quantum master equation or the Liouvillian.) As
with the unitary evolution of states, the formal solution to this is given by a Volterra integral
equation:


Zt


ρ(t) = T exp
dt0 L̂ˆ t0
ρ ( t ).
(52)

 0
t0

ˆ
In the specific case that L̂ˆ is independent of time, this simplifies to ρ(t) = etL̂ ρ(t0 ). In general,
this may not be guaranteed to converge, let alone have a closed-form solution [47–49].25
Nevertheless, this is the formal solution to the LvN equation (51). Using the dilation theorem,
we expect the time evolution of ρS (t) to follow the same principle; i.e., that we can determine
the dynamics of ρS (t) by examining the time evolution of the closed system U = SE and
taking the partial trace over E. Thus, we have the LvN equation for ρS (t) given by:


i
h
i
h
dρS (t)
†
b
bSE , U
b t,SE (ρS (t0 ) ⊗ ρE )U
b t,SE
.
= TrE − i HSE , ρSE (t) = −i TrE H
dt

(53)

(Just to be clear about the notation, in the last expression we're taking the partial trace over E
bSE with the state given by the unitary time evolution of ρS (ti ) ⊗ ρE .)
of the commutator of H
To find a solution to this equation for ρS , we would need to evaluate the Volterra integral
equation (52) for the global evolution over SE and then trace over E. This has the exact
same problems of convergence and closed form as before, since we haven't changed the
problem itself. Instead, as a first step to determining the dynamics of ρS , we can make the
simplifying assumption of Markovian dynamics; i.e., that over a differential time evolution
t 7→ t + dt, the properties of ρ(t + dt) are determined entirely by the properties of ρ(t). Since
this assumption explicitly states that ρS (t + dt) depends only on ρS (t), we must make the
Markov approximation in order to write down a differential evolution equation ρS that's
first-order in time. We might be concerned that this is an overly restrictive assumption for
a sensible model of reversible computing; fortunately, this assumption is in fact entirely in
line with some of the key assumptions we make in our generalized models of reversible
computing. The relation between these assumptions, and their suitability, is discussed in §4.3.
The map ρS (t0 ) 7→ ρS (t) is a quantum channel ρin,S 7→ Λt [ρin,S ]; thus, we can express ρ(t + dt) in terms of the operator-sum representation (39) of the CPTP map. In this
representation, the Markov approximation appears as:
ρS (t + dt) =

∑ Nbcd (dt) ρS (t) Nbcd† (dt).

(54)

c, d

We can retrieve a Liouville-type superoperator in the Markov approximation by examining
the differential evolution of a quantum channel:
Λ − Îˆ
Λdt [ρS ] = Îˆ + dt lim dt
+ * * * := Îˆ + dt L̂ˆ + * * * .
dt
dt → 0

(55)

By expanding the Kraus operators and keeping the terms up to order O(dt), we get the
Gorini-Kossakowski-Sudarshan-Lindblad (GKSL) superoperator / equation [50,51]:
h
i
dρS
ˆ ρ (t)] := −i H
b S , ρS + 1
= L̂[
S
dt
2
25

∑



†
† b
† b
κ ab 2 Fbab ρS Fbab
+ Fbab
Fab ρS + ρS Fbab
Fab .

(56)

a, b > 0

This is of course true for the unitary evolution of states as well; convergence is only guaranteed when the algebra of the argument of the integral has a
commuting structure (i.e., when the Volterra integral equation is over c-numbers).

30 of 68

(These are also referred to in the literature as Lindbladians or quantum Markov equation.) Here,
Fbcd are the so-called jump operators. These induce "quantum jumps"; i.e., the quantum state
bS .26 κ ab are the
transitions that are distinct from the (closed-system) evolution of ρS under H
rates corresponding to the abth jump.
The GKSL evolution equations (56) provide the evolution of the system in the Schrödinger
b ∈ B(HS ) on HS are stationary and the states (and thus
picture; i.e., when the operators A
the density matrices) evolve with time.27 We can examine the Heisenberg picture (where
the states are stationary and the operators evolve with time) using the adjoint differential
evolution expression:
b(t + dt) = ∑ N
b(t) N
b † (dt) A
b cd (dt).
A
(57)
cd
c, d

As with the GKSL equation (56), we can expand the Kraus operators (or alternately take the
adjoint of the GKSL equation directly) to get the adjoint GKSL equation governing the time
evolution of operators in the Heisenberg picture:
h
i
h
i
b
dA
b(t) := i H
b +1
bS , A
= L̂ˆ ‡ A
dt
2

∑



† bb
† b b
b Fb† Fbab .
κ ab 2 Fbab
A Fab + Fbab
Fab A + A
ab

(58)

a, b > 0

The adjoint GKSL superoperator provides us with the time evolution of operators, including
the conserved quantities of the system; these are discussed in more detail in §2.2.3.2. The
formal solution to this evolution equation is, as we'd expect:


Zt


b(t) = T exp
b(t0 ).
A
dt0 L̂ˆ t0
A
(59)


t0

b(t) = etL̂ˆ ‡ A
b(t0 ) when L̂ˆ ‡ is independent of time. Unfortunately,
As always, this simplifies to A
the expressions of L̂ˆ and L̂ˆ ‡ defined in (56) and (58) are not unique: we can have unitary transformations which redefine the jump operators or mix the jump operators and Hamiltonian (or
that do both) while leaving the overall forms of L̂ˆ and L̂ˆ ‡ invariant.28
The GKSL equation (56) also serves as the generator of the quantum dynamical semigroups
[52,55,56]. Starting with the dilation theorem (7), we as always select F = E. As discussed
before, seeking a first-order differential equation of the form (56) automatically imposes the
Markov property. If we consider the set of all of the CPTP maps which start at the same starting
environment state ρE and are evolved to various times t, the Markov property is equivalent to
the semigroup property Λt1 Λt2 = Λt1 + t2 . Thus, we define the quantum dynamical semigroup
as the family {Λt | t ≥ 0} that satisfies the Markov property.29
As always, the differential equation (56) is solved by (52), which simplifies to Λt [ρS (t0 )] =
ˆ
ρ (t) = etL̂ when L̂ˆ is independent of t. Since the family {Λ | t ≥ 0} is a one-parameter
S

26
27
28
29

t

† induces the jumps, and F
b† Fbab ρS + ρS Fb† Fbab normalizes the evolution in the case that there are no jumps.
More precisely, Fbab ρS Fbab
ab
ab
The notation B(H) represents the set of bounded operators on H with finite trace norm.
This is unfortunate but not surprising; we saw the same kind of ambiguity in the definition of the Kraus operators. Indeed, the first kind of unitary
transform is due to precisely that ambiguity from earlier.
According to Lindblad's theorem [50], any quantum operation that satisfies the semigroup property will satisfy the GKSL equation and vice versa.
However, note that not every CPTPh map satsifies
the GKSL equation [53,54]; it just so happens that we're only concerned with the ones that do.
i
b is a continuous function of t for all trace-norm-bounded operators A
b ∈ B(HS ) is also specified. However,
Oftentimes, the requirement that Tr (Λt [ρ]) A

b ∈ B(HS ) is a bounded function, and that the semigroup property is specified where
because we already specified that Λt is a CPTP map for all t, that A
t ∈ R is a continuous parameter, this requirement is a direct consequence of what we already have. Finally, we note that the notation Op(H) is sometimes
used for B(HS ), e.g., as in [17–19].

31 of 68

semigroup, we can recognize L̂ˆ as the generator [56,57] of this semigroup. As usual, we can
ˆ

then define etL̂ in terms of its Taylor-Madhava series expansion:
e

tL̂ˆ

:= lim

t→∞

tL̂ˆ
1−
n

!n
.

(60)

We see that the Markovian approximation gives a vital tool for explicitly calculating the
dynamics of the evolution of ρS : it gives us a first-order differential equation in time for
bS and N
b ab . Furthermore, by
the evolution of ρS , entirely in terms of the known quantities H
cleverly engineering S, these may even be controllable expressions in experiments.
2.2.3.2. GKSL dynamics with multiple asymptotic states.
Central quantities of interest in GKSL evolution are the asymptotic states, which are the
ˆ

set of states that ρS (t) evolves into in the infinite time limit under the etL̂ evolution:
ˆ

|ρ∞ ii := lim etL̂ |ρin,S ii.
t→∞

(61)

(Here, we've employed the "double-ket" notation that appears in the vectorization of B(HS );
this is discussed in more detail in Appendix B. This notation will be used for the remainder of
the text.)
Before continuing, it's worth noting an important subtlety in the time limit t → ∞. The
GKSL equation examines the process by which a system initially in a state |ρin ii relaxes to
one or more of the asymptotic state(s) |ρ∞ ii. This assumes that the relaxation occurs on a
timescale much faster than the timescale involved in the dynamics of the asymptotic state(s).30
Thus, implicit in this expression is the notion that t is a parameter that only sees timescales on
the order of the relaxation timescale. In other words, the GKSL dynamics is entirely before the
dynamics of the asymptotic states, and the limit as t → ∞ is then still before the asymptotic
state dynamics. For reference for later discussions, we label the relaxation timescale tre and
the asymptotic dynamics timescale sAs , with tre  sAs . Intuitively, the GKSL dynamics is
interested in the limit as t → tre , but due to the parametrization of the dynamics, we take the
limit as t → ∞. In order to describe the asymptotic dynamics, we use a separate parameter s.
We can determine the asymptotic states by examining the spectral decomposition of L̂ˆ .
Here, we follow the excellent presentation in [19], which is the thesis corresponding to the
original papers [17,18] which develop this framework. (This is simply an abbreviated version;
the reader interested in more details of the framework is highly encouraged to read these
references.) In general, L̂ˆ is not necessarily Hermitian. If it's still unitarily diagonalizable, we
denote the eigenvalues by λ a , the (right) eigenvectors by |pa ii, and the left eigenvectors by
hhqa | . Denoting D̂ˆ = diag(λ a ), P̂ˆ as the matrix formed by setting {|pa ii} as rows, and P̂ˆ −1
as the matrix formed by setting {hhqa |} as columns, we have |ρS (t)ii in terms of the spectral
decomposition of L̂ˆ given by:
ˆ
ˆ
|ρS (t)ii = etL̂ |ρin,S ii = P̂ˆ etD̂ P̂ˆ −1 |ρin,S ii

= ∑ |pa ii etλa hhqa |ρin,S ii = ∑ c a etλa |pa ii.
a

30

(62)

a

In fact, the GKSL equation involves three timescales, not just these two: the Markov assumption also involves an assumption about fluctuations between
S and E, corresponding to a statement about the timescale of these fluctuations. This is discussed in more detail in §4.3.

32 of 68

Here, c a = hhqa |ρin,S
 † ii are simply the coefficients of the (Hilbert-Schmidt) inner product
hhqa |ρin,S ii = TrS qa ρin,S . Since t ∈ R, the eigenvalues can only satisfy Re{λ a } < 0 or
Re{λ a } = 0 to have finite |ρ∞ ii. The eigenstates for Re{λ a } < 0 are the damped or decaying
states, while the eigenstates for Re{λ a } = 0 are the asymptotic states.31
In the case that L̂ˆ isn't diagonalizable, it still has a decomposition in Jordan normal form.
Each Jordan block has a specific eigenvalue, but eigenvalues could be spread over multiple
Jordan blocks. If we remove the assumption of unitary diagonalizability, the decomposition
given by (62) still holds for diagonal Jordan blocks, where λ a is now specifically the eigenvalue
of |pa ii. (Since the left eigenvectors are the same as the right eigenvectors of the adjoint
operator, the eigenvalue of hhqa | is just λ∗a . The overall spectral decomposition of the operators
ˆ

now use the right eigenvalue specifically.) For non-diagonal Jordan blocks, the expression etL̂
pulls down a factor of tn /n! for each instance of a nonzero superdiagonal entry. Thus, for a
given non-diagonal Jordan block with right eigenvalue λ a and N generalized eigenvectors, if
ˆ

tL̂
we index the generalized eigenvectors by μ, ν ∈ N+
N , we have the decomposition of e | ρin,S ii
for that specific block given by [17,19]:
ˆ

|ρS (t)ii = etL̂ |ρin,S ii =

∑

t(ν − μ)
|pa ii etλa hhqa |ρin,S ii
(ν − μ)!

∑

c a etλa t(ν − μ)
|pa ii.
(ν − μ)!

ν≤μ

=

ν≤μ

(63)

A direct consequence is that the Jordan normal form of the asymptotic state eigenvalue blocks
(i.e., the eigenvalue blocks with pure imaginary eigenvalues) are all diagonal, since the factor
of t(ν − μ) would blow up otherwise.
As mentioned earlier, the factor of etλa in the spectral decompositions (62) or (63) of |pa ii
tells us that the set of pure imaginary eigenvalues correspond to the asymptotic states; we
can denote these as Λ a = Im{λ a }. The corresponding right eigenvectors form a subspace
of B(HS ), called the asymptotic subspace and denoted As(HS ). The asymptotic left and
right eigenvectors are respectively the asymptotic states and the (asymptotic) conserved
quantities of the GKSL system we're examining.32 Indexing these by their value of Λ and
their corresponding degeneracy μ, we'll denote the right and left eigenvectors as sΛμ and
J
respectively. (For clarity, this means that we have L̂ˆ s
= iΛ s
and L̂ˆ ‡ J
=
Λμ

Λμ

Λμ

Λμ

−iΛ JΛμ .)
ˆ

Under the action of etL̂ , all initial states |ρin ii converge to As(HS ) in the t → ∞ limit.
Naturally, the GKSL dynamics maps states outside of As(HS )-the states that don't survive
in the infinite time limit-to some linear combination of states in As(HS ). However, at a finite
ˆ

time t, there's no requirement that if |ρS (t)ii = etL̂ is in As(HS ), then it must stay in that
state for all future times. Indeed, the GKSL dynamics permits the time evolution of a state in
As(HS ) to leave that subspace altogether at some other time, as long as the state returns to
As(HS ) at t → ∞. Two examples of GKSL state evolution are provided in Figure 8.

31

32

Most examinations of GKSL dynamics examine the case of a single asymptotic state, given by the right eigenvector corresponding to λ = 0. The
corresponding left eigenvector is 1. GKSL systems with multiple asymptotic states form a set of measure zero [19] over the set of all possible GKSL
systems. However, we're representing an actual engineered system: we're not interested in the set of all possible GKSL systems, we're interested in the
one that actually represents our system, so this isn't a problem.
These conserved quantities are slightly different from some of the more familiar conserved currents in classical and quantum mechanics; for instance, the
conserved quantity given by the hh1| eigenvector is the trace of ρ∞ .

33 of 68

Figure 8. Two examples of evolution of states under GKSL dynamics to As(HS ) in the t → ∞ limit.
Here, the gray blocks denote further subspaces of As(HS ). |ρin,2 ii starts outside of As(HS ) and settles
into one such subspace of As(HS ) as t → ∞, whereas |ρin,3 ii starts inside one subspace of As(HS ),
leaves it but stays within As(HS ), and then returns to the same subspace as as t → ∞. Many further
dynamics are possible: for instance, a state in one of these subspaces could leave As(HS ) altogether,
and then settle into the same or even a different subspace of As(HS ) as t → ∞; meanwhile, a state
could start in a subspace of As(HS ), leave it but stay within As(HS ) overall, and settle into a different
subspace as t → ∞. There are, indeed, no restrictions on where the initial state can start from, as long
as it's somewhere in the universe and settles to As(HS ) as t → ∞: as with |ρin,2 ii, a state could start
outside of As(HS ) altogether, or a state could alternately start inside As(HS ) but outside one of the
subspaces. These subspaces are defined in the infinite time dynamics; thus, they only have relevance
after the GKSL dynamics has finished.

From sΛμ and JΛμ , we can construct a superoperator projector P̂ˆ ∞ , known as the
asymptotic projection, which projects solely onto As(H):33

P̂ˆ ∞ :=

∑

Λ, μ

sΛμ

JΛμ

1
= lim
T→∞T

∑

ZT

Λ 0

dt e



t L̂ˆ − iΛÎˆ

1
=
2πi

I
C

ˆ

dz etL̂
.
zÎˆ − L̂ˆ

(64)

(Here, C is the contour which encloses only the {λ}s.) Using P̂ˆ ∞ , we can write |ρ∞ ii as:


b
b
(65)
|ρ∞ ii = e−i H∞ s P̂ˆ ∞ |ρin ii ei H∞ s
We can recall from the discussion at the beginning of this section that the Markov dynamics
involves two timescales: the relaxation timescale tre and the asymptotic timescale sAs . Here,
b ∞ is the Hamiltonian that governs the asymptotic dynamics, parametrized by the time
H
parameter s  t; i.e., s solely describes the dynamics of the system after it has already
equilibrated. From this expression, we can directly see that As(HS ) = P̂ˆ ∞ [B(HS )].
The spectral properties of L̂ˆ play a central role in understanding the GKSL dynamics
of the system in question. As such, the projector decomposition of these dynamics which
separates the asymptotic dynamics from the dissipative dynamics serves as an essential tool
to understand the overall structure of GKSL evolution. This is given by the four-corners
decomposition , first developed in [18]. (As before, we follow the presentation in [19].) We

33

ˆ
The last two equalities come from recognizing P̂ˆ ∞ as the projector onto the peripheral spectrum of etL̂ . The second-to-last equality expresses P̂ˆ ∞ as the

 −1
ˆ
ˆ
Cesàro mean of etL̂ , and the last equality expresses P̂ˆ as the Dunford-Taylor integral of etL̂ via the resolvent zÎˆ − L̂ˆ
.
∞

34 of 68

can define the operator PbA ∈ HS as the projector onto the asymptotic states. Explicitly, PbA is
defined in terms of ρ∞ by:
PbA ρ∞ PbA = ρ∞ ;
h i
TrS PbA = max[rank(ρ∞ )].

(66)

ρ∞

(The second expression helps us ensure that PbA is defined so that it only projects onto the
b := 1S − PbA , with
asymptotic states.) Meanwhile, the complement of PbA is given by: Q
b
b
b
Q ρ(t) Q → 0 as t → ∞. Together, PbA and Q provide the four-corners projections of operators
b ∈ B(HS ):
A
b
A
b
A

b := PbA A
bPbA ;
:= P̂ˆ A

b
A

b := Q
bA
bPbA ;
:= P̂ˆ A

b := PbA A
bQ;
b
:= P̂ˆ A

b
A

b := Q
bA
bQ.
b
:= P̂ˆ A
!
b
A
b
A

b=
A

b
A
b
A

(67)

b provide a decomposition of every A
b ∈ B(HS ). (67) also provides a definition
Thus, PbA and Q
n
o
ˆ
ˆ
b as indicated.
of the four corners projection superoperators P̂ , P̂ , P̂ˆ , P̂ˆ
, which act on A
(66) and (67) serve as the foundation for examining the properties of GKSL systems with
multiple asymptotic states, as well as the geometric properties of their quantum state spaces.
These in turn are fundamental for examining the properties of classical (including reversible)
computing operations in GKSL systems. However, a detailed discussion of the properties of
the four-corners decomposition is far beyond the scope of this paper; the interested reader is
highly encouraged to examine [17–19]. For our purposes here, what's relevant is that As(HS )
forms an identifiable subspace, which we can project onto using the four corners projection
superoperators.
As an important note, P̂ˆ does not project onto As(HS ) directly. Rather, the
subspace
contains As(HS ) in its entirety: As(HS ) ⊆
. The difference between these lies in the
b ∞ : As(HS ) describes the states that survive in the
asymptotic dynamics governed by H
infinite-time limit (as given in (64) and (65)). If there are no further dephasing dynamics
within , then As(HS ) = ; conversely, if there are, then As(HS ) ( . This notation also
serves as a visual indication for the framework: each operator in B(HS ) can be subdivided
into four regions, corresponding to these projections. We can freely gather As(HS ) into the
bPbA projects into the top-left corner; i.e., PbA A
bPbA projects into .
top-left corner. Then, PbA A
The subspace is a full Hilbert space in its own right, supporting quantum mechanical
b ∞ in the t → ∞ limit. Thus, it supports any possible dynamics that can
evolution under H
be governed by a Hamiltonian. Indeed, this framework provides a way to describe an
open system extension of any finite-dimensional system that can be governed by the laws
of nonrelativistic quantum mechanics, as long as the open system relaxation is governed
by Markov dynamics.34 Thus, we can directly model a system of computational states as
discussed in §2.1.5.2: each computational state corresponds to a DFS within an overall Hilbert

34

In principle, infinite-dimensional Hilbert spaces, relativistic quantum mechanical systems, and quantum field theories should be describable as well;
however, the details of these descriptions are still in progress.

35 of 68

space. The overall Hilbert space
is then the direct sum of the individual DFS spaces, known
as the von Neumann algebra [58–62]:

=

M

HDFS,i .

(68)

i

The fact that this is identical to (2) (at the level of the vectorized space) shows us that the von
Neumann algebra is a natural framework to represent reversible computing operations. This
representation is discussed in detail in §3.5. The embedding of a von Neumann algebra within
the four corners representation of an operator evolving under GKSL dynamics is given in
Figure 9.

Figure 9. An example of the type of overall operator algebra B(HS ) that can support classical (including
reversible) computing operations. (Note this matrix operates on the space of vectorized density matrices.)
Here, the upper left corner subspace is a von Neumann algebra corresponding to the direct sum
of decoherence-free subspaces, with the gray regions representing the individual decoherence-free
subspaces.

A striking feature of GKSL dynamics with multiple asymptotic states is that the shape
of
corresponds to substantially different expressions for the quantum geometric tensor
(QGT) over . This is a key aspect of GKSL dynamics with multiple asymptotic states, and
will also serve as an essential feature of understanding the properties of RC operations in
open quantum systems. The dependence of the dynamics on the QGT of
is central to the
framework developed in [18], and is discussed in detail there and in [19]. Unsurprisingly,
because the framework of classical reversible computing operations in open quantum systems
relies at its core on GKSL dynamics with multiple asymptotic states, the dependence of GKSL
dynamics on the QGT over
is an indispensable part of classical RC operations in open
quantum systems as well. The quantum geometric properties of RC operations are briefly
mentioned in §3.5. A more detailed analysis of these properties, and conclusions regarding RC
operations, are the central theme of a forthcoming work which follows up on these discussions.
2.3. Existing and Proposed Implementation Technologies
In this section, we briefly survey a number of conceptual examples of concrete physical
mechanisms of operation that may be suitable, to varying degrees, for performing reversible
computations. The detailed performance characteristics for these example technologies (e.g.,
the exact energy dissipation per operation as a function of speed) depend on a great many
design details, so we will not attempt to derive those characteristics here. Rather, this survey
is just to give the reader an idea regarding the range of physical mechanisms for reversible
computing that may be possible. It is likely that many other, much more efficient mechanisms
can be invented with further research.

36 of 68

First, here is a concise list of the technologies we will survey, with abbreviations noted
(some of which are coined here):
1.
2.
3.
4.
5.

Reversible adiabatic CMOS (RA-CMOS).
Reversible quantum flux parametron (RQFP).
Reversible quantum-dot cellular automaton (R-QCA).
Reversible nanomechanical rod logics (RNRL).
Ballistic asynchronous reversible computing in superconductors (BARCS).

These particular examples will be described in a bit more detail in the following subsections. These are not the only physical mechanisms for reversible computing to have been
proposed, but (except for BARCS) are some of the most well-developed implementation
concepts so far.
2.3.1. Reversible Adiabatic CMOS
This class of implementation technologies for reversible computing refers to a logic
design discipline based on ordinary CMOS (complementary metal-oxide-semiconductor)
field-effect transistors [30,63–68]. To approach physical reversibility in these types of circuits
requires several conditions to be met (see Appendix A for some key derivations):
1.

2.

The on/off conductance ratio ron/off = Gon /Goff of the device channel (at the specified
operating points) should diverge, as the technology is improved. The quantity Gon refers
to the typical effective peak source-drain conductance through the channel of a device
(transistor) when it is in the "on" state (with gate voltage set accordingly, e.g., Vg = Vdd =
logic HIGH for an n-type FET). Meanwhile, Goff refers to the maximum conductance
through the device for off-state "leakage" current (including both gate leakage and
subthreshold current) when the device is nominally turned off (e.g., Vg = 0 = logic LOW
for an nFET). Roughly speaking, 1/Gon ends up being proportional to the characteristic
relaxation timescale τr = Ron C of the circuit, while 1/Goff ends up being proportional to
the characteristic equilibration timescale τe = Roff C of the circuit when its non-equilibrium
state is not being actively maintained. One of the classic results of physical reversible
computing theory, the roots of which can be traced back to Feynman's lectures on
computation, delivered in the early 80s [69], is that in general, at least for any classic
"adiabatic" reversible computing technology, the maximum energy recovery efficiency for
a reversible device is √
ultimately limited as a function of the ratio of these two timescales,
e.g., as ηer ≤ 1 − c * τr /τe for τe  τr . (See App. A) That
√ is, the minimum fraction
of signal energy dissipated per operation cycle scales like τr /τe , quite generally. For
CMOS, this means that, to attain high energy efficiency, we want to make the leakage
conductance Goff as small as possible to extend the equilibration timescale τe , and doing
this well in practice requires some combination of various engineering refinements (e.g.,
higher threshold voltages, thicker gate oxides, lower operating temperatures, higher
materials purity). Identifying the most economical manufacturing process to minimize
Goff in practice is not a simple optimization problem by any means. However, there
appears to be no fundamental reason why the ratio ron/off cannot be made as large as
desired with further refinement of the technology over time. Thus, it seems that this
class of circuits can approach ideal reversibility with continued development.
Since in CMOS, the relaxation timescale τr is subject to lower bounds, the transition time
ttr for the adiabatic logic transitions should also diverge. For a given technology, the
minimum dissipation per cycle will be found when the transition time ttr is (within a
√
small constant factor) roughly at the geometric mean τm = τr τe between the relaxation
and equilibration timescales (App. A). But, as long as we can arrange to keep extending

37 of 68

3.

the equilibration timescale τe , the useful transition time ttr ≈ τm can continue increasing
as well.
The effective quality factor Qeff of any external resonant oscillatory element serving as the
clock-power supply driving the adiabatic circuit should also diverge. For our purposes,
2
Qeff can be defined as the ratio between the peak electrostatic energy Eload = 12 Cload Vdd
stored transiently on the logic nodes, and the energy dissipated by the resonant oscillator
per cycle, Qeff = Eload /Eodiss .

In addition to the above, two design rules that must always be obeyed in (conditionally)
reversible adiabatic CMOS circuits in order for them to be able to approach physicallyreversible operation in the above limits are the following:
1.
2.

Never turn on a transistor when there is a nonzero source-drain voltage across it.
Never turn off a transistor when there is a nonzero source-drain current through it.

If either of these rules is ever broken in the design, this can lead to substantial nonadiabatic dissipation, and the physical computational process as a whole no longer qualifies
as being asymptotically physically reversible. This is discussed further in [30,65,70].
A brief description of the overall normal mechanism of reversible operation for these
kinds of circuits is as follows. Periodic voltage waveforms are supplied by a resonant oscillatory circuit that is customized to provide quasi-trapezoidal wave shapes (that is, with roughly
flat waveform tops and bottoms). The flat regions are needed in order to avoid pushing
current through devices while they are being switched on or off. The provided waveforms
exist in several different (mutually-offset) phases. Each phase drives a corresponding section
(subset) of adiabatic logic circuits. The choice of which circuit nodes to charge up in a given
section is determined using series-parallel networks of devices, whose gate (control) electrodes
are connected to the (quiescent) nodes controlled by a neighboring phase. After the supplied
waveforms have finished causing the desired transitions between valid logic voltage levels for
a given section of the circuit, now those circuit nodes can be used to control the adiabatic transitions for the neighboring sections in adjacent clock phases. The correct architectural design
of these kinds of circuits can become somewhat involved, but is conceptually straightforward.
See [30] for an example.
2.3.1.1. Description of RA-CMOS in terms of our general framework.
In reversible adiabatic CMOS technology, a given (time-dependent) computational state
c(τ` ) has a very simple description in terms of physical microstates. Essentially, in a given
computational state, at a given time, each circuit node exhibits a given well-defined, relatively
uniform voltage level, within some tolerances. Of course, there will be local fluctuations about
that average level. Physical states in which voltages depart substantially (over a broad region)
from any of the computationally-meaningful levels can be relegated to the catch-all "invalid"
computational state c⊥ , but during normal operation of a well-engineered circuit, such states
should have an astronomically close to zero probability of arising in any case.
In terms of computational operations, a certain computational operation Ost is carried
out each time one of the supply waveforms executes a voltage-level transition between two
distinct valid logic levels, i.e., from an initial level Vi to a final level Vf 6= Vi , over the time
interval between the two time points s (start time) and t = s + ttr (end time). During this
transition, the voltage levels on the set of circuit nodes that are connected to that particular
supply line themselves undergo (with a slight delay, and modulo voltage offsets due to leakage
and other non-idealities) the same transition between voltage levels. In this process, some
transistors (e.g., ones whose gates are controlled by the transitioning nodes) may be turned on
or turned off, causing the source and drain nodes of those transistors to become connected to
or disconnected from each other. These connection and disconnection events result in the set

38 of 68

of accessible computational states changing over time (since even the number of independent
connected components will be changing, thus, so will the number of available computational
states).
In any case, as long as the two rules of adiabatic design are respected throughout a given
transition, the operation Ost that is performed will be both (conditionally) logically reversible
(under the condition that the rules are respected), as well as asymptotically thermodynamically
reversible, in the limit described above where Goff → 0 and ttr → ∞, while keeping ttr  τe .
Thus, we can allow both ron/off and ttr to continue increasing as the technology develops,
and approach perfect reversibility over time given continued development of this family of
technologies.
The above discussion glosses over the important issue of the effective quality factor Qeff
of the driving power-clock resonator, which will also limit the overall degree of reversibility,
but, as far as we know at present, there is no reason why this quantity cannot diverge as
well, with continued engineering refinements. (The development of high-quality trapezoidal
resonators suitable for driving adiabatic circuits is in the scope of engineering R&D work
being performed at Sandia.)
2.3.2. Reversible Quantum Flux Parametron
The Reversible Quantum Flux Parametron (RQFP) logic family [71–73] is a logically
reversible variant of the well-developed superconducting logic family AQFP (Adiabatic
Quantum Flux Parametron), which has been being developed primarily at Yokohama National
University in Japan. RQFP (and its not-necessarily-reversible generalization AQFP) rely on
adiabatic transformation of the abstract potential energy surface (PES) that obtains within
Josephson-junction-based superconducting circuits. The independent variables for the PES
describe the current distribution in the circuit, and the phase (order parameter) differences
across the junctions. The PES is manipulated in such a way that the occupied potential energy
valley of the system is transformed adiabatically to configurations representing different
computational states.
RQFP circuits are controlled by externally supplied waveforms, similarly to the case
in RA-CMOS, except that the supplies are providing current signals, not voltage signals
(since voltages, except for inductive transients, are normally zero in superconducting circuits).
Except for the fact that the state of the circuit and the driving signals at a given time is
described in terms of currents instead of voltages, and that the physics of superconductivity
dominates the charge transport, the representation of RQFP in terms of computational and
physical states is, roughly speaking, qualitatively similar to the case in RA-CMOS. That is to
say, the higher-level principles of pipelined reversible logic are roughly comparable between
the two technologies.
One advantage, however, of RQFP compared to CMOS is that, due to Meissner-effect
trapping of flux quanta, the natural equilibration timescale τe is extremely large (effectively
infinite) in RQFP, and as a result, scaling to extreme ultra-low levels of dissipation may
ultimately prove far easier to do in RQFP than in adiabatic CMOS. The primary disadvantages
of RQFP, compared to CMOS, are its lower density and accordingly higher manufacturing
cost per-device, together with its requirement for low-temperature operation.
2.3.3. Reversible Quantum-dot Cellular Automaton
The Quantum-dot Cellular Automata (QCA or QDCA) [74–76] family of technologies
operate using single electrons confined to quantum dots, dipole configurations of two such
electrons confined to four such dots in a square layout separated by tunnel barriers (a.k.a. a
"cell"), and linear/branching arrays of such cells interacting through dipole-dipole Coulombic
interactions. As in RA-CMOS and RQFP, externally supplied signals are used to adiabatically

39 of 68

raise and lower potential energy barriers that separate neighboring regions of the physical
state space, in patterns that (in the technology's reversible variant, here dubbed R-QCA)
allow the overall computational state to evolve reversibly-which, as usual, means in a
(conditionally) logically reversible and asymptotically physically reversible way.
An interesting note about QDCA is that it was recently shown [77] that exponential
scaling of adiabaticity with speed (as in Landau-Zener transitions with a missed level crossing)
exists in this system, apparently implying that there is no fundamental lower bound on
dissipation-delay product. In [78], Pidaparthi and Lent investigate this phenomenon in more
detail using a Lindbladian analysis, finding that when there is weak thermal coupling to the
environment, these systems can exhibit substantially suppressed dissipation within a certain
regime of speeds. This is a promising result, and we expect that this type of behavior likely
generalizes to a wider variety of quantum systems.
2.3.4. Reversible Nanomechanical Rod Logics
This is a concept that goes back to K. Eric Drexler's work in the 1980s leading up to
his dissertation on molecular nanotechnology at MIT [79–81]. The original idea was that
logical bits are encoded in the linear displacements of atomically-precise nano-rods that move
within sleeves at the ends of nano-springs. The nods are pushed back and forth (by externally
supplied mechanical signals, following the same kind of quasi-trapezoidal waveforms we've
talked about previously) to adiabatically transform them between computational states, using
nano-scale bumps on the rods to sterically hinder each other's motion in ways that allow them
to perform (conditionally reversible) Boolean logic. The whole scheme is closely analogous to
RA-CMOS, except that it uses mechanical rather than electrical state variables.
Drexler's rod logic concept was updated more recently [82,83] by a group led by Ralph
Merkle (a pioneering cryptographer and early nanotechnologist). The new concept eliminated
the sleeve bearings, whose friction had dominated the dissipation in Drexler's earlier concept.
In the new scheme, the only bearings are rotary bearings implemented by single carbyne bonds,
whose orbitals are circularly symmetrical. Frictional losses in this system were assessed in
simulations [84] to be so low that individual joints (operated reversibly) would dissipate
∼70,000× less than Landauer's kT ln 2 limit even when operating at frequencies as high as
100 MHz. This example illustrates that in principle, dissipation-delay products for reversible
operations can be far smaller than is the case in RA-CMOS. (This particular dissipationdelay value is roughly 106 × improved versus projected end-of-roadmap CMOS-and at room
temperature!)
The main problem with the Drexler-Merkle family of nanomechanical rod logic concepts
for reversible computing is simply that building them would seemingly require a very general,
sophisticated, atomically-precise and fast technology for nano-fabrication and assembly, which
does not yet exist, and may continue to not exist for some decades.
2.3.5. Ballistic Asynchronous Reversible Computing in Superconductors
Ballistic Asynchronous Reversible Computing (BARC, previously called ABRC) [85] is
a fundamentally new physical model of reversible computing in which the computational
degrees of freedom evolve ballistically (i.e., under their own inertia) rather than being dragged
along adiabatically as a side effect of the oscillatory evolution of an external resonator. This
change may provide certain advantages in terms of, e.g., allowing us to avoid having to worry
about accidentally exciting undesired modes of the resonator and of the distribution network
for the driving signal. The BARC model is required to be asynchronous as a means to prevent
the nonlinear interactions between subsystems from chaotically amplifying uncertainties in
the subsystem trajectories.

40 of 68

In a current project at Sandia, we are attempting to implement the BARC model in superconducting electronic circuits [86]. The computational subsystems are individual polarized
flux solitons (or fluxons) propagating near-ballistically along long Josephson junction (LJJ)
transmission lines. In our circuits, fluxons are conserved and interact asynchronously with
stored flux quanta at (stateful) interaction sites or circuit elements, transforming the local digital
state reversibly, in a deterministic sort of elastic "scattering" interaction.
BARC is an extremely novel concept, and has only been developed to a very preliminary
level to date. So far, we have a single (very simple) "working" BARC circuit element (i.e., it
simulates correctly in SPICE) [87]; a test chip for it has been fabricated, and experimental tests
of it are in progress. However, a wider variety of useful elements, leading up to a complete
logic family, still need to be developed and optimized.
We are also collaborating with a group at the University of Maryland which has been
working on a similar ballistic approach which they call Reversible Fluxon Logic (RFL) [88–94].
The original RFL concept envisioned synchronous ballistic logic, but the Maryland group is
also now also developing asynchronous elements which fall into the BARCS paradigm [95].
3. Results
Much work remains to be done, in terms of fleshing out a complete physical theory
of reversible computing informed by NEQT, but in this section, we review some important
preliminary results in this area that can be, or have already been obtained.
First, we view it as important, for resolving some of the long-standing controversies in
the thermodynamics of computation, to distinguish a couple of different results that have
historically been associated with Landauer's Principle:
1.

2.

First is a simple result regarding the interchangeability of entropy between computational and non-computational forms. This one follows directly from the association
of computational states to sets of microstates discussed in §2.1.2. However, it is such
an important result that we call it The Fundamental Theorem of the Thermodynamics of
Computation. We review it in §3.1 below. This result implies that non-computational or
"physical" entropy must be increased when computational ("information") entropy is
reduced, but does not require that total entropy be increased.
Second is a result (§3.2) showing that a strict entropy increase is required whenever
there is a loss of information (which by itself is not surprising, since entropy increase
effectively means that known information is reduced), and furthermore, that an example
of this necessarily occurs when one of two mutually-correlated subsystems is obliviously
erased, meaning that, in isolation, its reduced subsystem entropy is ejected to its local
thermal environment without regards to its existing correlations. To the extent that the
ejected information is then thermalized, with its correlations to the other subsystem
being lost, this then corresponds to a strict increase in total entropy. This result follows
directly from unitarity, information theory, and the definitions in §2.1.

We argue that it is the second result, and not the first one, that is most properly understood
as being Landauer's Principle, because Landauer's Principle is most properly taken to concern
the consequences of information loss in a computer-since that was the original subject of
Landauer's 1961 paper. And, at least in an ordinary, deterministic computer, it is normally the
case that computed bits are correlated-meaning, there is mutual information between them-
since in fact, one can say that it is the generation of specific desired patterns of correlation
between different subsystems that is exactly the whole point of what computation, per se, is all
about.
In particular, we show in §3.2 that, for any deterministically computed bit (or larger
computational subsystem), the amount of new entropy that is generated when that bit is obliviously erased is strictly lower-bounded by the prior reduced subsystem entropy of that bit (or

41 of 68

subsystem).35 Note that, in that statement, we are talking about an absolute increase in the
total entropy of the model universe (including computational and non-computational entropy,
defined below), and not just a transfer of entropy from computational to non-computational
form.
Thus, Landauer's Principle, when it is properly understood in this way, really does
provide a lower bound on new entropy generation, and not simply on entropy transfer, as has
sometimes been claimed.
In addition to the above clarification of Landauer's Principle, we also (in §3.3) review
two fundamental theorems of reversible computing. (These were previously presented in [20],
but we reprise them here.)
1.

2.

The Fundamental Theorem of Traditional Reversible Computing, whose proof is summarized
in §3.3.1 below, states that the only deterministic computational operations that always
avoid ejecting computational entropy to non-computational form (and thus, can avoid
Landauer's lower limit on entropy increase when operating in isolation on computed
bits) are the unconditionally logically reversible operations traditionally studied in reversible
computing theory.
The Fundamental Theorem of Generalized Reversible Computing, whose proof is summarized
in §3.3.2 below, states that, in a statistically contextualized computation, it can suffice (in
a properly designed mechanism) to avoid entropy ejection (and the resultant entropy
increase due to Landauer's limit) if a computational operation is simply reversible on
the subset of initial states having nonzero probability in the given statistical operating
context.

Taking the latter observation (the generalized theorem) into account is essential in order
for theory to adequately encompass the state of the art of the existing best practices in
the engineering of reversible computing hardware. The generalized theorem significantly
expands the class of computational mechanisms that can be seen to be capable of approaching
thermodynamic reversibility when appropriate constraints are met. In particular, all of the
actual implementation technologies for reversible computing described in §2.3 can only be
understood properly in the light of the generalized form of the theorem-in other words, all
of the real reversible computing technologies that have been implemented to date are only
conditionally reversible, and so they rely, for their ability to achieve asymptotic reversibility in
practice, on the fact that their preconditions for reversibility have been met by design, within
the architectures of those machines, and (implicitly) on the Generalized Theorem of RC.
Next, the framework of NEQT provides us with several new perspectives from which to
understand Landauer's principle, and to begin to characterize the properties of RC operations
in open quantum systems. In §3.4, we relate Landauer's principle and the structure of
reversible computing to the CTOs discussed in §2.2.1.2. By examining the difference between
conditional and unconditional Landauer reset using the structure of these CTOs, we find
a general motivation for and rationale for the structure of RC directly from RTQT. Quite
spectacularly, we see that by treating elements of the physical computer system as the "catalyst"
in the CTO sense, we can directly represent repeated cycles of computation and Landauer
reset. In particular, we see that using the structure of CTOs outlined in §2.2.1.2, we can cycle
through the operation of computational systems as long as we wish, with minimal buildup of
QMI. Finally, in 3.5, we begin the foundational work of representing RC operations in terms of
open quantum systems from a first-principles level, using the properties of GKSL dynamics
with multiple asymptotic states. In particular, we note specific properties of computational
and noncomputational operations, and briefly discuss implications in terms of their quantum
geometric signatures.
35

This argument was previously made explicit in the preprint arXiv:1901.10327, but we reprise it here.

42 of 68

Let us now review these results in a bit more detail.
3.1. The Fundamental Theorem of the Thermodynamics of Computation
First, starting from the basic conception of (classical, digital) computational states presented in §2.1.2, we can easily derive what we call The Fundamental Theorem of the Thermodynamics of Computation. This theorem formalizes the relationship between so-called "information
entropy" (that is, entropy of the computational state) and physical entropy.
To start, let φ be a variable representing the (complete, micro-) physical state of the
computer system S, specified by a choice of one of the protocomputational basis vectors
~b ∈ B . Assume that, at a given point in time τ, the probability mass over the different possible
physical states φ is distributed according to a probability distribution p(φ), as given in the
usual way using the Born rule, or equivalently, by the diagonal elements of the system's
instantaneous density matrix ρ(τ ) in the B basis.
We can then derive an implied probability distribution P(c) over the computational states
c j ∈ C, by simply summing p over the various physical states φ = φi ∈ B j , where B j denotes
the specific basis set Bc ⊂ B corresponding to computational state c = c j :
P(c j ) =

∑

p(φi ).

(69)

φi ∈ B j

It is then trivial to show that the system's total (von Neumann/Shannon) entropy S(Φ) (where
Φ is a random variable ranging over values φ) can always be partitioned as:
S ( Φ ) = H ( C ) + S ( Φ | C ),

(70)

where H (C ) (with C a random variable ranging over values c) refers to the computational
entropy or "information entropy," meaning the entropy of the computational state variable C
according to the above-derived probability distribution P(c), and meanwhile S(Φ|C ) refers
to the conditional entropy of the physical state variable Φ if the value of the computational
state variable C is given. If we then define non-computational entropy as Snc = S(Φ|C ), then we
can just say, "total entropy equals computational entropy plus non-computational entropy."
Note that this is true always-no matter how the protocomputational basis B is defined and
partitioned into basis sets corresponding to computational states. See Figure 10. (And for
more details, see ref. [9].)
This fact, together with the Second Law of Thermodynamics (i.e., ∂S/∂t ≥ 0 globally),
implies that one can't ever reduce computational entropy (for example, by merging two
computational states, like in Figure 5(b)) without also increasing non-computational entropy
by (at least) a corresponding amount. Of course, this works both ways-meaning, if you
increase computational entropy (e.g., by splitting a computational state, in a stochastic computational operation, like in Figure 5(c)), you can thereby also reduce non-computational entropy
accordingly. This is done in practice, for example, in paramagnetic cooling [96–98], if we think
of the (relatively stable) randomized magnetic domains that form during the cooling process
as constituting "computational" bits.
A widespread perception is that the theorem corresponding to the above observations
constitutes a form of Landauer's Principle, but we argue that, although it is indeed a very
important basic theorem of the thermodynamics of computation, calling it "Landauer's
Principle" creates confusion, because it entirely misses what we argue is the central, most
important point of Landauer's Principle proper, which has to do more specifically with the
loss of computed, correlated information, such as typically exists within a computer. This
viewpoint is discussed at great length in [9], and more concisely in the following subsection.

43 of 68

Figure 10. Fundamental Theorem of the Thermodynamics of Computing, illustrated using the picture
of Fig. 3. No matter how we choose the protocomputational basis B of the computing system S and
partition it into distinct computational states c ∈ C, we can always express the total physical entropy
S(Φ) of the system as the sum of the information entropy H (C ) of the computational state (state of the
computational subsystem C), and the non-computational entropy Snc (Φ) of S, which is equal to the
conditional entropy S(Φ|C ) of the physical state when the computational state is given.

3.2. Landauer's Principle Proper
Since we wish to argue that Landauer's Principle is, most centrally, a theorem about the
consequences of information loss in computation, specifically, it behooves us to say a little bit
more about what we mean by that.
A quite general picture of computation involves the concept of function evaluation, e.g.,
computing y = f ( x ), given x. In fact, historically, the very first formal model of universal computation, due to Alonzo Church, defined general computations in terms of recursive function
evaluation [99]. And it is of course well-known today that arbitrarily complex computations
can be composed out of simple function evaluations (e.g., Boolean logic operations).
Let us then consider, as an example, two subsystems X, Y of a computational system
C, that exist for purposes of holding the input value x and output value y of some function
f (*) to be evaluated. Let us assume that subsystems X and Y have separable corresponding
computational state spaces C X , C Y , which is to say, the computational states of subsystems
X and Y are independently measurable. There is then a joint computational state space
C XY = C X × C Y . Suppose initially we have some distribution P(CX ) over the initial state of
X. Suppose, then, a deterministic computational OXY is performed on the joint system XY
which leaves CX unchanged, but results in cY = f (cX ), which is to say, the computational
state cY of Y becomes a state representing the value y = f ( x ), where x is the value represented
by the state cX of X. Note that this operation OXY could also be reversible, e.g. if CY contained
a known value initially (e.g., is "cleared memory").
It then follows from the above setup that:
1.

First, the reduced computational entropy of Y, written H (CY ), after performing OXY , is
entirely accounted for by the mutual information between Y and X; that is, H (CY ) =
I (CX ; CY ). In other words, Y contains an exactly zero amount of independent entropy,
relative to X, since H (CY |CX ) = 0. (I.e., Y is completely determined by X.) This just
follows from the fact that, as is typically the case in traditional digital computation,
function evaluation is a deterministic operation.

44 of 68

Figure 11. Landauer's Principle as entropy increase from thermalization of mutual information. Red
shading denotes probability density. (Left) Two perfectly-correlated computational bit-systems X and
Y; their states could have been prepared by computing Y's value y deterministically from x, e.g.,
using y := x. (Middle) When the variable Y (for the computational state of Y) is obliviously erased,
this amounts to merging the two computational states in each column; we can say that now Y = 0
(say) in each merged state. Note that now, there briefly exists a correlation between X and the noncomputational part of the physical state. (Right) Very quickly (over a thermalization timescale), we
lose track of the probabilities of the different physical states making up each computational state, thus
losing this correlation information. This is where the absolute increase of total entropy from Landauer's
Principle necessarily occurs. We cannot, of course, then undo this entropy increase by simply reversing
the first step (un-merging the Y states), because the correlation information between X and Y has already
been irrevocably lost by this point.

2.

3.

Second, now suppose that, next, an irreversible computational operation Oerase is performed locally on Y in complete isolation from X, that is, without any influence from the state
of X, or even any applied knowledge about the state of X (beyond our prior distribution
P(CX )), and suppose, further, that the overall output-state distribution P(CY ) resulting
from Oerase has zero entropy. This resultant distribution P(CY ) is found by computing
a weighted sum of Oerase (cY ) over the set of all input computational states of Y with
probability P(cY ) > 0. For this distribution to have zero entropy implies that all such
states of Y map to the same value, cY = c0 , which is why Oerase can be considered an
"erasure" operation.
If we now simply assume that the non-computational entropy in S will shortly be thermalized-
which is to say, the entropy ejected from Y is not being preserved in a stable or predictable
form elsewhere in the physical state of the system-then it follows that the correlation
previously contained in the mutual information I (CX ; CY ) has now been lost, and
therefore, the total entropy of the model universe U is immediately (i.e., after a thermalization
timescale) increased by (at minimum) the prior value of the reduced entropy H (CY ), just
before the erasure. An example is illustrated in Figure 11.

We argue that the resulting theorem constitutes what is the most appropriate statement of
Landauer's principle: Namely, that to erase any deterministically-computed information in an
isolated computational subsystem obliviously, without regards to its correlations with other
information that may exist, and if this is followed by allowing the reduced subsystem entropy
that was thereby ejected to subsequently thermalize, results in turning that subsystem's
previous mutual information (which was not independent entropy) into true entropy (real,
new uncertainty), and thereby results in a permanent increase in the total entropy of the
universe by the corresponding amount.
Additional details of the argument for this result can be found in the extended postprint
version arXiv:1901.10327 of [9].

45 of 68

3.3. Fundamental Theorems of Reversible Computing
In this section, we review what we call The Fundamental Theorems of Reversible Computing
(RC) [20], which show that, in order for a deterministic computing system to avoid entropy
increases due to Landauer's Principle (when understood properly, as in §3.2 above), logically
reversible computational operations must be utilized. The Fundamental Theorem of RC comes
in two versions: The traditional version, which shows that traditional unconditionally logically
reversible operations are required in order to avoid entropy increase from Landauer's Principle
in all possible input circumstances, and the (less often recognized) generalized version, which
shows that a broader class of conditionally reversible operations suffice, for use in systems that
are properly designed to ensure that the preconditions for reversibility of those operations are
met.
3.3.1. Fundamental Theorem of Traditional Reversible Computing
Before we review the traditional RC theorem, we first present a simple definition, based
on the discussion of §§3.1–3.2 above, which will be helpful for stating it. (The following is
presented in time-independent terms, but can easily be made time-dependent.)
3.3.1.1. Entropy-ejecting operations.
A computational operation O on a computational state set C is called (potentially) entropyejecting if and only if where exists some possible prior distribution P(C ) ∈ P (C) such
that, when the operation O is applied within that context, the increase ∆Snc in the noncomputational entropy required by the Fundamental Theorem of the Thermodynamics of
Computing (§3.1) is greater than zero. If an operation O is not (even potentially) entropyejecting, we call it non-entropy-ejecting.
Note that if an operation is entropy-ejecting, and it is performed in isolation (by which
we implicitly also mean obliviously, without external knowledge of the state being applied)
on a subsystem that contains mutual information with other subsystems (and if we assume
that any non-computational entropy will not be preserved in a predictable form, but will be
thermalized), then this entropy ejection will furthermore result in a global entropy increase, by a
straightforward generalization of Landauer's Principle (in its proper form, stated above in §
3.2).
Fundamental Theorem of Traditional Reversible Computing. If a deterministic
computational operation O is non-entropy-ejecting (by the above definition), then it follows
that O must be unconditionally logically reversible.
The proof of this statement is trivial, but can be found in arXiv:1806.10183, the extended
postprint version of [20].
Note, also, that an immediate corollary of this theorem is that, if we wish to perform
computational operations in isolation (i.e., obliviously) on subsystems that contain any mutual
information with other systems (such as subsystems whose state was computed deterministically from those other systems), then we can only avoid a global entropy increase from
Landauer's Principle in the general case (i.e., for any distribution P(C ) over initial computational states, and when the non-computational state doesn't preserve information in a
predictable form) if those operations are unconditionally logically reversible.
3.3.2. Fundamental Theorem of Generalized Reversible Computing
The traditional theorem, above, is in essence about how we can avoid Landauer losses
in the worst case-that is, when we assume that we have no control over what the initial
computational state cI ∈ C may be, and thus, any statistical mixture of initial states is possible.
But, in a real computer, the initial state prior to a given computational operation may be (and

46 of 68

usually is) a resultant state from a previous operation. Thus, it is frequently the case that we
can, by design in a computer, restrict the set of possible initial states to a proper subset A ⊂ C
of allowed states. This then makes it possible to design computing mechanisms that avoid
Landauer losses by transforming just the subset A of allowed states reversibly. This is, in fact,
how typical real engineered technologies for reversible computing (including those described
in §2.3 above) work-since it turns out, in general, to be much easier, in practice, to design
mechanisms that only transform restricted subsets of computational states reversibly, rather
than the full set of all potentially describable states. But to show why doing this is sufficient,
we need a more general version of the fundamental theorem of RC, one that properly models
the case where the set of initial states is restricted.
To do this, we also need to extend the concept of an entropy-ejecting operation from §
3.3.1 as follows:
3.3.2.1. Entropy-ejecting computations.
For purposes of the below theorem, let a (statistically contextualized) computation C =
C(O, P) refer to the concept of performing a computational operation O over its computational
state space C, given a particular initial probability distribution P = P(C ), where C is a random
variable ranging over computational states c ∈ C. (The quantum contextualized computation
concept of §2.1.5 is just a straightforward generalization of this concept to a quantum context.)
We say that a (deterministic) computation C is (specifically) entropy-ejecting if and only if the
increase ∆Snc in the non-computational entropy required by the Fundamental Theorem of
the Thermodynamics of Computation (i.e., due to a reduction in computational entropy
H (C )) is greater than zero. If the computation C is not specifically entropy-ejecting, we call it
non-entropy-ejecting.
As before, this then allows us to immediately state the corresponding theorem:
Fundamental Theorem of Generalized Reversible Computing. A deterministic
computation C(O, P) is non-entropy-ejecting if and only if at least one of its preconditions for
reversibility is satisfied with probability 1 under the initial probability distribution P.
As with the traditional theorem, the proof of this is easy, but may be found in arXiv:1806.10183.
Like with the traditional theorem, the generalized theorem has an immediate corollary,
which is that if we wish to perform the computation C(O, P) in isolation (obliviously) on
a subsystem bearing mutual information with other systems (such as a subsystem whose
computational state was deterministically computed from those outside systems), then we can
only avoid a global entropy increase from Landauer's Principle for that specific computation
(assuming, as usual, that the non-computational state doesn't preserve information in a
predictable form) if the operation O is conditionally reversible, under (at least) the precondition
that c ∈ A, where A = { ci ∈ C | Pi > 0 }.
The significance of the two RC theorems together is that, in order to avoid the otherwisenecessary entropy increase resulting from Landauer's Principle when performing isolated
computational operations on subsystems in the context of larger deterministic computations,
one must confine oneself to the above two cases (unconditionally reversible operations, and/or
conditionally reversible operations that have a satisfied condition for reversibility).
The significance of the generalized reversible computing theorem, as opposed to the
traditional one, is to observe that it is a sufficient logical-level requirement, to avoid requiring
an entropy increase from Landauer's Principle, if simply those initial states having nonzero
probability in the given statistical operating context P(C ) are mapped one-to-one onto final
states.
Of course, in any event, even when these conditions for reversibility are satisfied, to avoid
entropy increase in reality also requires that the physical mechanisms implementing the given
computation must be designed to approach thermodynamic reversibility in practice-but, the

47 of 68

import of the RC theorems is to say that, when the conditions of either theorem are satisfied,
Landauer's Principle, at least, does not preclude doing this.
Additional discussion of these two theorems can be found in [20], with detailed proofs
available in the associated postprint arXiv:1806.10183. We should note that, although the
particular proofs of these theorems presented there did not yet explicitly utilize the quantum
generalization of the concept of a statistical operating context that we presented in §2.1.5
above, all of the constructions in §2.1.5 were specifically designed to guarantee that the exact
same proofs will go through essentially unmodified in the quantum version of the theory
(given our assumptions about rapid decoherence of final states). Thus, the above theorems
remain valid within the quantum framework of the present paper.
3.4. Representations of Reversible Computing by Catalytic Thermal Operations
The results above follow from a static analysis just based on the overall starting and
ending states of a given computational process; however, obtaining more detailed results
(e.g., about minimum energy dissipation as a function of speed) will require more detailed
attention to the dynamics of computational transitions. This then requires engaging more
detailed theoretical methods, such as the resource-theoretic tools we reviewed in 2.2.1. In this
section, we discuss how to think about reversible computational operations in terms of those
more detailed methods.
3.4.1. Reconsidering the Notion of a Catalyst
The nonequilibrium Landauer results in §§2.2.2.1–2.2.2.2 emphasize how essential it
is to have a map as close to unital as possible in order to minimize the energy cost of the
operation (i.e., the importance of a map that minimizes the entropy difference between ρin,S
and Λt [ρin,S ]). Ideally, we'd like to connect these to the theory of thermal operations, so that
we can begin to identify the thermal processes that are relevant for reversible computing.
As discussed in §2.2.2.1, the bound is zero when the Landauer reset protocol applied to the
subsystem bearing computational degrees of freedom is conditioned on the state of that
subsystem and when the von Neumann entropies of the subsystem state before and after reset
are equal. Although achieving this in practice is a nontrivial engineering challenge, there is
no fundamental (quantum mechnical)
barrier to this constraint, so we can consider this case

specifically (i.e., that S(ρi ) = S ρ j = S(ρr ) where ρi and ρ j can be any possible computational
state).
In order to select the right TO, we again return to the Landauer reset protocols. These
were described earlier as the process of resetting a state bearing some computational degrees of
information, either with a conditioned or unconditioned potential. Without loss of generality,
we can consider the system carrying these degrees of freedom as part of a larger system.
Then, we can label the larger system S and the subsystem carrying these degrees of freedom
Q, as shown in Figure 12. In terms of Q, the Landauer reset protocol is the process of
transforming the state ρ`,Q to the reset state ρr,Q . Until now, we've been content to consider
the Hamiltonians acting on all of the systems and subsystems as background Hamiltonians.
Ordinarily, this wouldn't pose any issues, and indeed helps us keep the properties of the
system as general as possible.
br,Q can be conditioned on ρ`,Q plays
However, as we saw in §2.2.2.1, whether or not V
a vital role in calculating the free energy bound on the reset process, and in particular on
the information contribution to the bound. Thus, by contrast to the other contributions to
bQ as an ambient background potential we in fact lose a
the overall Hamiltonian, by having V
vital piece of context of the overall process. This context is relevant when trying to identify
bQ as not
the correct TO we want to use to examine the process. Thus, we need to think of V
an ambient potential that acts on Q, but rather a potential that acts on Q from a different

48 of 68

Figure 12. (a) The embedding of a system Q carrying computational degrees of freedom inside a larger
system S, which also contains a subsystem P used to induce state transformations on Q. (b) An example

of the process discussed in §2.2.2.1, in terms of this embedding. Q is in one of the N states ρ`,Q . A

bQ is applied to ρ`,Q to transform it into the reset state ρr,Q . Crucially, since V
bQ is part of the
potential V
system, it must be contained in S (i.e., it must not be part of the environment); meanwhile, it also must
bQ onto Q to
be outside of all of Q. We can without loss of generality consider the subsystem that applies V
be part of (or all of) P. (c) The application of this potential transforms the local state of Q as ρ`,Q 7→ ρr,Q .
Assuming that the dynamics can be described by a CTO of the form (10), the transformation must also
induce some state transformation ω1,P 7→ ω2,P , to preserve unitarity of the overall dynamics on PQ.
bQ by P upon Q also gives
(The sole exception to this is the identity transformation.) The application of V
rise to a correleation between Q and P, given by the QMI (14). (d) The correlated states ρr,Q and ω2,P




correspond to a single state ξ PQ over PQ as a while, with TrP ξ PQ = ρr,Q and TrQ ξ PQ = ω2,P .

subsystem P of the overall system S. If we require that the local state of P (i.e., the state of P
when we trace out every other subsystem) be the same to within some value e ∈ R+ under
the trace distance, then we can treat P as a catalyst which is necessary to induce the local state
transformation ρ`,Q 7→ ρr,Q . In this framework, the natural TO to examine this interaction is
the general CTO given by (10). Indeed, we can recognize the ∆Ier term in the unconditional
Landauer bound (34) as precisely the same as the QMI (14) built up between the transforming
subsystem and the catalyst.
Thus, in terms of TOs, the correlation-preserving generalized CTOs discussed in
§2.2.1.2 are precisely the conditioned Landauer reset protocols discussed in §2.2.2.1. By
contrast, the requirement in (15) that the final state of the catalyst remain uncorrelated with
the final state of the transforming subsystem is identical to applying a single unconditioned
potential for the Landauer reset. As was the case when comparing the most general CTO (10)
and the more traditional CTO (15), the correlated information ∆Ier = I (Q : P) is ejected from
the overall system S = QP after the unconditional protocol. Alternately, and equivalently,
the unconditional Landauer reset protocol (resp., the more traditional CTO) can be realized by
performing the conditional Landauer reset protocol (resp., the general CTO) and then ejecting
the correlated information afterwards.

49 of 68

Thus far, we've used the general CTO to describe the process of a subsystem being
transformed with the help of a catalyst, and to obtain the quantum thermodynamic restrictions
on this process. However, the word "catalyst" is simply a convention based on our modelling;
mathematically, the catalyst is simply another subsystem which (within an e ∈ R+ ) returns
locally to the same state before and after the overall state transformation on S. Nothing a
priori tells us that the subsystem K in (10) must be a catalyst; as far as the mathematics is
concerned, this is simply a statement about a specific type of transformation on the system
S = TK, where T and K are subsystems and K has the additional requirement (11) that the
state before and after the transformation is locally the same up to an infinitesimal e. This offers
an interesting extension of the discussion above regarding the reset of Q due to a subsystem P:
what happens if we allow P to change its state before and after the transition, but we require
that the subsystem Q bearing computational degrees of freedom must return to the same
state? A priori this seems like it would make no sense: how can we meaningfully talk about
computation if the subsystem with computational degrees of freedom is left unchanged?
To answer this, we'll consider the decomposition of the transition ρQ ⊗ ωP 7→ ξ QP into
two distinct (non-catalytic) TOs over the subsystems Q and P. Here, we enforce TrPE [ξ QP ] =
ρQ and kTrQE [ξ QP ] − Ξ(ωP )k1 < e for some infinitesimal e ∈ R+ . In other words, the overall
transition ρQ ⊗ ωP 7→ ξ QP is an operation where now the state over Q starts and ends in the
same state. In this decomposition, one of these transformations locally takes the state of Q
away from σQ , and the other returns the state of Q to σQ . Overall, then, we consider the pair
of transformations:
ρQ ⊗ ωin,P 7→ χQP 7→ ξ QP .
(71)
In addition to the properties for TrPE [ξ QP ] and TrQE [ξ QP ] stated above, we have TrPE [χQP ] =
γQ for some γQ 6= ρQ .
The composed transition ρQ ⊗ ωP 7→ ξ QP is the CTO ρQ ⊗ ωP 7→ ξ QP discussed above,
where now it is the state ρQ of Q that starts and ends in the same state under the composition.
Thus, the composed transition must correspond to the constraints in §2.2.1.2. This has a direct
interpretation in terms of computing if we think of σQ as a reset state. The reset state is
conventionally the state we use as our starting point to perform a computation on Q, which
is why it's chosen as the reset state in the first place. Then, the process (71) corresponds to
starting with the standard reset state ρQ , using a different subsystem P to manipulate the state
of Q (i.e., perform a computation on Q), and then using P once more to perform a conditional
Landauer reset on Q to return it to the reset state. Remarkably, since these compose to yield
an overall CTO of the form (10), this process can be achieved with an infinitesimal build-up of
mutual information: I (Q : P) < δ1 + δ2 for δ1 , δ2 ∈ R+ .
By contrast, we can also consider unconditional Landauer reset as a type of CTO, of the
form (15). In this case, we can consider the transformation over QP given by:
ρQ ⊗ ωin,P 7→ χQP 7→ σQ ⊗ ρf,P .

(72)

Here, Q and P are uncorrelated at the end of the transformation. As before, we can think
of σQ as the reset state. We can think of this pair of transformations corresponding to a
decomposition of a CTO of the form (15), and, simultaneously, the unconditional Landauer
protocol in (28). As discussed in §2.2.1.2 and §2.2.1.4, the fact that the final states of Q and P
are uncorrelated corresponds to an intrinsic asymmetry between the work of formation F∞
and the extractable work F0 ; this loss of energy represents the energy lost as a result of the
expulsion of the QMI between Q and P into the environment.

50 of 68

3.4.2. Transformations on Computational States and Catalytic Thermal Operations
For the sake of clarity, we explicitly restate this way of viewing computational operations,
now referencing the computational subspace C and a control subspace K, combining the
framework of §2.2.1.2 and the current section with the notation and viewpoint of §2.2.2.1.
As discussed in §2.2.2.1, for a subspace C bearing computational degrees of freedom, we
define the reset state ρr,C as a standard, known reference state upon which operations can be
performed. These operations correspond to known computations, which transform the state
of the system from the reset state to one of N known final computational states ρ`,C . Then, in
the Landauer protocol, we reset the final state back to the reset state, either conditioning the
reset protocol on the final state or not conditioning the reset protocol on the final state. These
correspond to the conditional and unconditional Landauer protocols, respectively, with the
lower bound on the energy cost of each given in §§2.2.2.1–2.2.2.2. Specifically, we saw that
the conditional Landauer protocol was bounded below by zero, whereas the unconditional
Landauer protocol was bounded below by the amount of correlated information between the
computational state and the subsystem applying the reset potential onto the computational
state.
We can understand the process of repeatedly resetting the computational subspace C to
ρr,C , evolving the state of C to a final computational state ρ`,C , again resetting, again evolving
to a final computational state ρm,C (which may be the same or different), and continuing in
this fashion as a sequence of CTOs as discussed earlier in §3.4.1. In particular, since the local
state of C is constantly reset, evolved, and then reset and evolved again and again all under
the influence of a secondary operator K; we can consider C as the catalyst subsystem in the
sense of the discussion earlier in this section. A series of computational operations, performed
by a subsystem K of S that's distinct from C but contained entirely within S, transforms
the state of C from ρr,C to some ρ`,C , which corresponds to our computational operation. K
then performs the Landauer reset ρ`,C 7→ ρr,C of C, following either the conditional Landauer
protocol (23) or the unconditional Landauer protocol (27), with the corresponding energy
costs given by (26) and (34) respectively.
A priori, it may not be clear why we insist that K must be the same subsystem that performs the local transformation ρr,C 7→ ρ`,C and the Landauer reset ρr,C 7→ ρ`,C . Indeed, these
transitions may well be performed by different machines within S. However, without loss of
generality, we can lump the set of all machines which perform operations on C collectively
into a single subspace K, and subsequently examine the set of operations that K in its entirety
performs on C. In particular, from the decomposition of S and E given in §2.1.1, we note that
all of these individual machines, as well as their combined collection K, must correspond to a
subspace of S.
We can use the techniques of CTOs to examine these transformations, in particular using
the argument in §3.4.1 to examine the conditional Landauer bound. We start with C in a reset
state, have K perform some operations to transform it into a final computational state, and
then reset C to the reset state once again. As in §3.4.1, this chain of operations permits us
to think of C as the "catalyst" in a CTO, despite C being the actual computational system of
interest. Then, the means by which we transform from ρr,C to ρ`,C and then back to ρr,C tells us
whether we have a CTO of the form (10) or of the form (15); equivalently, the means by which
this pair of transformations takes place tells us whether we have a conditional Landauer reset
protocol (21) or an unconditional Landauer reset protocol (28).
In the case of the unconditional Landauer reset protocol, we have the pair of transformations ρr,C ⊗ σin,K 7→ χCK 7→ ρr,C ⊗ σ f ,K with TrK [χCK ] = ρ`,C . This is of the exact same form
as the transformation (72). As such, the same conclusion applies: in this case, this transformation corresponds to the CTO described in (15). The final correlation between C and K is
ejected into the environment, yielding the irreversible energy difference F∞ − F0 . Conversely,

51 of 68

Figure 13. A representation of a computational operation cycle in terms of a CTO, with conditional
Landauer reset. (a) The computational system C starts in a standard reset state ρr,C . An auxiliary system
K starting in the state σK performs a series of operations on ρr,C , causing CK to jointly evolve into a
state χCK , with TrK [χCK ] = ρ`,C as one of the possible known final computational states. (The series of
operations that K performs on C corresponds to computation.) Then, K performs a Landauer reset of C,
returning it locally to the standard reset state. In the case of the conditional Landauer reset, pictured
here, the reset protocol corresponds to CK jointly evolving into the final state ξ CK , with TrK [ξ CK ] = ρr,C .
The composition of operations ρr,C ⊗ σK 7→ χCK 7→ ξ CK is a composition of the form (71), and thus
corresponds to a CTO of the form (10) (shown as the gray arrow). (b) Locally in Q, the state of χPQ is



N
given by one of the N final computational states ρ`,Q ` = 1 ; i.e., we have TrP χPQ = ρ`,Q . (c) Locally


in Q, the state of ξ PQ is once again given by the reset state ρr,Q ; i.e., we have TrP ξ PQ = ρr,Q .

in the case of the conditional Landauer reset protocol, we have the pair of transformations
ρr,C ⊗ σin,K 7→ χCK 7→ ξ CK with TrK [χCK ] = ρ`,C and TrK [ξ CK ] = ρr,C . Here, we permit
the QMI (14) between C and K to build up in both transformations. As before, the QMI in
each transformation can be made as small as possible, but cannot in general be zero. The
representation of the conditional Landauer reset protocol as a CTO in which the computational
subsystem C is thought of as the "catalyst" (inasmuch as it returns to the starting state) after
two successive operations is given in Figure 13.
3.5. Subspace Representations of Computational and Noncomputational Operations
In §2.2.3.2, we discussed some of the basic properties of open quantum systems with
multiple asymptotic states evolving under the GKSL approximation. A key aspect of the
asymptotic subspace As(HS ) is that the evolution after GKSL relaxation supports the full
dynamics available to closed quantum systems. In other words, As(HS ) supports any dynamics that can be expressed by a Hilbert space of states evolving under a Hamiltonian; in this
b ∞ governs the dynamics of As(HS ) after the GKSL relaxation. This
case, the Hamiltonian H
provides an extremely powerful framework to represent reversible computing operations:
if we can represent RC operations for closed system dynamics, we can automatically get a
representation for RC operations in GKSL dynamics. As we saw in §2.1.2.3, the most general

52 of 68

framework for representing a computational subsystem is with the DFS sum HS = i HDFS,i ,
where each DFS HDFS,i represents a computational basis element ci .
When examining the dynamics on HS , this immediately gives us a way of distinguishing
computational and noncomputational operations. In particular, we note that since each DFS
corresponds to a specific computational basis element, a computational operation must transfer
states from one subspace to another. Conversely, a noncomputational operation cannot transfer
states from one subspace to another; therefore, it must only be able at most to rearrange states
within each subspace. A direct consequence of this is that noncomputational operations
must commute with the DFS structure of the computational system, whereas computational
operations in general have no such restrictions and permit coherences between different
computational subspaces during the immediate period of computational operation. A visual
representation of these two different kinds of operations is provided in Figure 14.
L

(a)

(b)

Figure 14. The representation of computational and noncomputational operations in a Hilbert space,
such as As(HS ). (a) Computational operations (blue arrows), which transfer between different computational states (blue circles). As discussed in §2.1.2.2, each computational state corresponds to a distinct,
orthogonal DFS (gray), with the overall Hilbert space corresponding to the direct sum of these. (b)
Noncomputational operations (yellow arrows), which cannot transfer between different computational
states and thus can only transfer protocomputational states within the same DFS. Note that a direct
consequence of this is that noncomputational operations must commute with the DFS structure.

Our interest here is in classical computing, rather than quantum computing. As a result,
we expect no quantum coherences to develop between different computational subspaces;
quantum coherences may only exist within a DFS representing a single computational state.
However, computational operations of the type shown in Figure 14(a) necessarily induce coherences; these are, indeed, characteristic of the transfer between one subspace and another. As a
result, immediately after a computational operation, As(HS ) will appear as a single space.
For our computer to remain a classical computer, then, we require that this space dephase
into the DFS sum we expect faster than the computer's ability to resolve distinct times; this is
showing in Figure 15. This provides us with a dephasing timescale, which can in fact offer
a way to distinguish between classical, quantum, and "approximately classical" computing
representations as we tune the dephasing timescale. (Here, by "approximately classical",
we mean those operations where the dephasing timescale is on the same order as the computer resolution timescale.) The relative strength of the dephasing and computer resolution
timescales, and the consequences of tuning this relative strength, will be of significant interest
for future work.
It's an almost trivial statement to note that any matrix can be represented as the sum of
two other matrices. However, the distinction between computational and noncomputational
operations discussed above, and the point that a computational operation necessarily mixes

53 of 68

Figure 15. The dephasing of As(HS ) from a single subspace to a DFS direct sum. For classical reversible
operations, this dephasing must occur faster than the computer's ability to resolve distinct times (i.e.,
on a timescale faster than the computer can see). Classical and quantum computing operations can be
distinguished by the relation between this timescale and the computer resolution timescale.

the different computational DFSs to temporarily make a single large space, provides us with
an interesting decomposition of such operations. In particular, we note that a computational
operation which appears as an operator mixing all of the states in As(HS ) can be decomposed
into a 'noncomputational part', which commutes with the DFS structure, and a 'pure computational part', which contains all of the information involving transfer of states between DFS
blocks (and thus, all of the information regarding the actual computational content of the operation); this decomposition is shown in Figure 16. A central property of GKSL dynamics with
multiple asymptotic states, derived in [18] and discussed there and in [19], is the nontrivial
quantum geometric tensor over As(HS ) that emerges, and the dependence that the dynamics
exhibits on the QGT. Notably, different shapes of the asymptotic subspace exhibit different
geometric signatures; thus, computational operations which mix different DFS states will have
a different quantum geometric signature than noncomputational operations. In light of the
decomposition of computational operations into noncomputational and pure computational
operations, this also means that each of these parts will exhibit distinct quantum geometric
signatures which can identify the computational and noncomputational part. As an added
benefit, we expect this decomposition to provide additional intuition for the distinction mentioned above between Landauer's Principle and the Fundamental Theorem. The discussion of
this will be provided in much greater detail in the forthcoming work examining the quantum
geometric properties of RC operations in general.
Beyond simply distinguishing between computational and noncomputational operations,
the discussion in §2.1.3 highlights how essential it is to distinguish between the different types
of computational operations – deterministic irreversible, deterministic reversible, stochastic
irreversible, and stochastic reversible. As further discussed in §2.1.4, these types of operations
are themselves comprised of a set of primitive computational state transitions; namely the
bijections, merges, and splits as discussed in Figure 5. As such, in order to understand the
representations of the different types of reversible (and, indeed, irreversible) classical operations, we must first find a representation of these different types of operations. Although the
nature of bijections and merges is somewhat self-evident, the case of splits must be handled
with slightly more care, since they can be generally expected to result in temporary coherences (which will, typically, quickly decohere). As with the decomposition of computational
operations, these will in all likelihood exhibit distinct quantum geometric signatures in lieu
of the quantum geometric signatures of different asymptotic subspaces discussed in [18,19].
Along with the previously-mentioned issues regarding quantum geometric signatures of RC
operations, the discussion of this will be addressed in the forthcoming work centering on the
quantum geometric properties of reversible computing operations more broadly.

54 of 68

Figure 16. Decomposition of a computational operation (left) into a noncomputational part (middle), which commutes with
the DFS structure that distinguishes different computational states, and a pure computational part (right), which contains all
of the information regarding the transfer of states between different DFS blocks, and thus all of the information regarding
the computational part of the operation. Notably, because the quantum geometric tensor of As(HS ) as a single space has a
different shape than that of As(HS ) as a DFS sum, the QGT of each of these will naturally be distinct as well. As such, the
noncomputational part of a computational operation will have a different, measurable quantum geometric signature to the pure
computational part of a computational operation.

4. Discussion
4.1. Essential Consistency of the Classic RC Formulation with NEQT
An important high-level conclusion supported by this paper is that there is no inconsistency between the simple, classic formulation of Landauer's Principle and reversible computing that we reviewed in §§3.2–3.3 and a more detailed treatment based on NEQT. Indeed, no
such inconsistency is possible, since, as we showed, the classic formulation can be presented
in a form that makes no equilibrium assumptions whatsoever. The only assumptions we
made there were the fundamental unitarity of the underlying quantum evolution, which is
also assumed by all of quantum thermodynamics, and the treatment of the environment as
immediately thermalizing all ejected information, which is equivalent to the Markov assumption underlying GKSL dynamics as discussed in §3.5. Therefore, the more detailed NEQT
formulations cannot negate the basic results of §§3.2–3.3, and indeed, we showed how to draw
explicit correspondences between a more detailed treatment of classical reversible computing
based on generalized CTOs and multiple asymptotic states in GKSL, and the simpler model
of §2.1 on which the basic results of §§3.2–3.3 can be based. We next discuss a few specific
aspects of this correspondence in more detail.
4.2. CTO Representations of Reversible Computing and System Boundaries
In §3.4, we discussed the representation of quantum mechanical models of reversible
computing in terms of the general CTO (10). Specifically, we identified the Landauer reset
b`r,Q applied to a subsystem Q as coming from the interaction between Q and a
potential(s) V
distinct separate subsystem P, where Q and P are both subsystems of the overall system S
we're examining in our TO. This analysis reinforces the importance of properly drawing the
system boundaries, as discussed in [40].
The specifics of where we choose to draw the boundaries between each subsystem, or
between the overall system and the environment, plays a vital role in being able to properly
identify the reset protocol of a system bearing computational degrees of freedom. Properly
drawing the boundaries makes the distinction as to whether a given reset protocol is a Landauer
reset protocol per se or not. In [40], we have the example of the reset of a system P coupled to a
copy / referent subsystem Q which stores the same computational state as P before reset. The
set of transformations on S in this case are given by {ρin,P ⊗ σin,Q }iN= 1 7→ {ρr,P ⊗ σi,Q }iN= 1 .
Comparing these to expressions (21), (22), and (28), we see that identifying P as the reset

55 of 68

system is commensurate with the Landauer reset definitions, whereas identifying PQ as the
reset system doesn't count as Landauer reset. (Specifically, identifying P as the reset system,
this corresponds to conditional Landauer reset.)
In precisely the same way, identifying the system boundaries is essential to representing
reset processes as CTOs. The CTO expression (10) requires a specific shape for the starting
and ending states (namely, that the overall system S be subdivided into a subsystem P which
locally undergoes the state transformation ρin,P 7→ ρf,P and a subsystem Q which locally
returns to the same state). Thus, properly identifying the system boundaries plays a vital role
in identifying the effect of the global universal CPTP map as a catalytic thermal operation, or
some other kind of operation. This dependence on system boundaries is, indeed, a general
feature of resource theories [27]. Thus, when applying the results of RTQT to analyzing
Landauer reset protocols and formulating bounds on quantities of interest, it is vital to specify
the subsystem boundaries properly: these boundaries affect whether or not we can properly
classify a reset as a Landauer reset, whether or not we can properly classify a CPTP map as a
CTO, and whether or not we can properly relate these two. (Incidentally, we saw a specific
example of this earlier: in §3.4, this dependence is what constrained the reset potential(s) to be
implemented by a separate cataylst subsystem within S as a whole.)
4.3. Applicability of the Markov Approximation to Reversible Computing
The Markov approximation has substantial consequences for the kinds of dynamics we
consider over all of U, which are worth comparing to our quantum mechanical model of
computing systems. In doing so, we explicitly preclude the possibility of fluctuations that
can take information from S to E during an intermediate time period and then have that
information return to S at time t + dt. Instead, this assumption is equivalent to saying that
any information that is ejected from the system to the environment cannot be returned to the
system. We might be concerned that this might represent an "artificial" type of information
loss in our model that comes from imposing a limitation on the types of processes we consider,
which does not reflect computational systems in the real world. In fact, the opposite is true:
this assumption matches perfectly with our understanding of the thermalization of ejected
correlated information from S.
In §3.2 and [9], we saw that the entropy increase due to Landauer reset was a consequence
of the thermalization of mutual information ejected into the environment. In particular, the
thermalization of entropy ejected into the environment occurs at a time frame much faster than
our ability to capture the dynamics of the system. Thus, in our model, the role of fluctuations
between S and E originating from S is suppressed: the effect of perturbative fluctuations
looks identical to the effect of environment perturbations. This is exactly the kind of behavior
we expect for a system S bearing computational degrees of freedom in a larger open system
evolution: the system has no practical way of tracking mutual information that is transferred
to the environment at a given time and then is transferred from the environment back to the
system at a later time. Any perturbations arising from information that originated from S at
an earlier time appears to S as indistinguishable from perturbations due to E. This is also true
for models of computation where the computational degrees of freedom reside in a subsystem
P being acted on by one or more orthogonal subsystems Qi of S: a crucial part of the model
is that neither P nor any of the Qi s are able to track information after it has been ejected
into E; and, indeed, this is a completely physically realistic framework. Thus, the Markov
assumption, in addition to being a vital calculational tool to retrieve closed form expressions,
also represents the real-world dynamics of the system.

56 of 68

4.4. Relationship to the Stochastic Thermodynamics of Computation
The stochastic thermodynamics of computation [8,100] is a framework for examining the
entropy cost of classical computational systems that has gained substantial prominence in
recent years. As such, an important question is the relationship between this framework and
the NEQT framework and results given in §§2.2.1.2–2.2.2.2, which we discuss here.
In the stochastic thermodynamics of information, the thermodynamic properties of
classical computational systems are examined [8] from the point of view of purely classical
information theory, relying on the properties of the continuous probability distributions
of classical random variables that arise therein. In this approach, classical computation is
represented as a continuous-time Markov chain (CTMC), represented by a directed acyclic
graph (DAG) which in turn represents a set of functions over a given Boolean string s ∈ {0, 1}n
of length n. Then, in the stochastic thermodynamics of information framework, the entropy
cost of transitions is calculated by examining the difference in the classical relative entropies
(i.e., the Kullback-Leibler divergences) of the CTMC distribution relative to an arbitrary
distribution before and after a single set of state evolutions along the graph. This framework
explicitly does not consider the perspective from quantum information theory,36 in contrast
with the representation of classical computation in terms of quantum channels (e.g., as in
[1–7,101–104]). Instead, the thermodynamic properties of computation are derived solely from
examining the entropy production and entropy flow rates of probability distributions which
evolve under this CTMC representation.
Despite avoiding the quantum information representation for classical computation
(and indeed for nonequilibrium dynamics), we would expect no differences whatsoever
in the conclusions we get from this framework compared to the framework focusing on
quantum information theory. At its core, the technique of correlation engineering [9,12] relies
on performing operations on correlated systems in such a way as to minimize the mutual
information build-up and to make the Helmholtz free energy cost of the transition arbitrarily
small, as discussed in §2.2.1. Although [9,12] and the discussion in §2.2.1 have focused on
quantities such as the quantum mutual information, the principles of correlation engineering
are in fact completely oblivious to whether the correlations and mutual information quantities
are classical or quantum in nature. Indeed, since the examination in these works of the
effect of correlations on overall entropic cost do not rely on whether or not the system state
commutes with the thermal reference state or the Hamiltonian, we can freely substitute
classical information quantities (such as the Kullback-Leibler divergence) and retrieve valid
statements for correlation engineering of classical thermodynamic systems.37
For individual systems in isolation, this is precisely what we find: the stochastic thermodynamics of computation is completely able to reproduce the results regarding the distinctions
between logical and thermodynamic reversibility found earlier in [2,3,13]. Specifically, the
now-famous result in those works that logically irreversible operations (such as erasure of
a single, isolated bit or computational system) can be nevertheless thermodynamically reversible has also been reproduced in [8,100]. This reflects our exact point about the proper
interpretation of Landauer's principle that we elaborated upon in §3.2, which is that erasing
bits in isolation when they contain mutual information with other bits results in thermodynamic irreversibility, and an amount of entropy increase corresponding to the loss of mutual
information.
Nevertheless, the subject of extending the framework of the stochastic thermodynamics
of computation to correlated systems appears to remain a matter of controversy. In particular,
36
37

In the words of [8] directly, "[this paper] will not consider the thermodynamics of quantum mechanical information processing, or indeed any aspect of
quantum computation."
Indeed, this precise property is the insight underlying the β-ordering and thermomajorization curve technique in [29].

57 of 68

the example of the thermodynamic reversibility of erasure of a single bit in isolation has
been used to argue that a correlated system cannot realize operations that are both logically
and thermodynamically reversible to within a mutual information difference of δ ∈ R+ , as
given in (14). Here, it appears that the misunderstanding has persisted due to confusing
the matter of isolated versus correlated systems: the example in [2,3,13] and reproduced in
[8,100] continues to focus on the case of an isolated system, whereas [9,10,12,40] highlight that
correlation engineering relies entirely on reducing the correlation buildup between systems
and applying operations in a way that does not increase the net entropy flow from the overall
system.38
It must be emphasized again, there is no fundamental disagreement between the results
calculated in [9,10,12,40]. Indeed, there cannot be, since all of these paths start with precisely
the same set of fundamental assumptions about the underlying dynamics of the system; i.e.,
that the dynamics are described by some CPTP map which we can express in terms of a larger
subspace as per the Stinespring dilation theorem. Thus, although some of the conclusions in
[8,100] seem to disagree with the consensus of [9,10,12,16,40], this is only a matter of mistaken
identity: [8,100] has erroneously drawn conclusions about correlated systems from a valid
calculation about the thermodynamic reversibility of a logically irreversible process applied
to an isolated system. Furthermore, although some of the conclusions of [8,100] may be drawn
from a mistaken conflation between the properties of isolated and correlated systems, it is
worth re-emphasizing that the underlying techniques in these works remain completely valid.
Indeed, the stochastic thermodynamics of computation may nevertheless serve as a useful
additional tool to examine correlation engineering of correlated systems.39
4.5. Thermodynamically Reversible Transformations of Extended Systems
An appropriate caveat to Landauer's principle could be to mention that even a correlated
state in a computer could in principle be erased in a thermodynamically reversible way if,
rather than erasing bits in isolation, we instead considered the full space of all possible thermodynamic transformations. But what, in detail, would a concrete protocol for accomplishing
such a transformation look like? One such protocol would be to simply unwind the correlations
by running, in reverse, a reversible computation that could have computed those correlations
in the first place, thereby leaving us, potentially, with an array of independently random input
bits, that could then each be thermodynamically reversibly erased in isolation from each other.
But, note that the existence of protocols such as this one doesn't refute the need for reversible
computing, since the protocol itself uses reversible computing to begin with.
Fundamentally, if we wish to be able to construct complex computational processes by
composing them out of local primitive transformations, which operate locally on part of the
full computational state, then by definition, those primitives cannot operate monolithically
on the state of the entire extended system, and thus they must be logically reversible if we
wish to avoid entropy increase in the face of the kind of non-local correlations which naturally
arise, as a matter of course, in typical large computations. This is not to say that some
radically different alternative basis for computation that was not based on local computational
primitives at all would necessarily be impossible to develop, but until that has been done,
reversible computing remains the most promising and well-developed available avenue
towards performing general digital computing in a thermodynamically efficient way.

38

39

Somewhat more confusingly, §IX-B in [8] appears to use this example to claim that correlated systems cannot realize such operations; however, Example
6 in §V-B in [8] appears to use a general argument to verify that logically irreversible operations on correlated systems cannot be made thermodynamically
reversible when each irreversible operation is at the subsystem level. This is precisely the same principle used in [9,10,12,40]. The source of the internal
disagreement in [8] remains unclear.
This further reinforces how delicate the issue of system boundaries is, as discussed in [40].

58 of 68

That being said, exploration of alternative protocols for thermodynamically efficient
computing may someday also be worthwhile. One conceptual example of such an alternative is
illustrated by [105], in which a chaotic dynamical system whose strange attractor is engineered
to encode the state of an extended Boolean circuit is monolithically transformed adiabatically
from an old state to a new state of the entire circuit all at once. This example illustrates that
thermodynamically efficient alternatives to performing computations via a sequence of local
logically reversible transformations do in fact exist. This example even still preserves a kind
of compositionality, albeit at a different level, in the sense that the structure of the extended
system is still composed out of local interaction Hamiltonians representing Boolean logical
constraints, even though the transformation of the system is monolithic.
So, the existence of the example of [105] could be cited as partial vindication of assertions
that reversible computing via local transformations is not necessarily the only way to accomplish
digital computation in a thermodynamically efficient way. However, the results of [105] appear
to suggest that the penalty for non-local operation of digital machines is to incur an exponential
increase in time complexity-which, in retrospect, is not surprising, since otherwise, one could
use methods based on [105] to solve NP-complete problems using only polynomial resources.
So, it may still be the case that reversible computing remains the only physically possible way
to achieve thermodynamically efficient digital computation with only modest (i.e., polynomial)
resource overheads.
We should also note in passing that, apart from [105], many other, more "analog" approaches to physical computing with dynamical systems also exist; see §4.2 of [106] for a
survey. As with [105], the evolution of other, more analog kinds of conservative dynamical
systems that may be useful for computing could also conceivably be engineered to approach
thermodynamic reversibility, although most existing analog computing schemes have not
been specifically designed to do so.
4.6. Future Directions
Although providing a valuable framework both theoretically and for our purposes in
modeling reversible computation, the structure of GKSL systems with multiple asymptotic
states [17–19] leaves several questions remaining. These questions are of great interest to
the theory of open quantum systems generally, and also offer substantial insights for open
quantum systems models of reversible computing. One important question is the question of
energy dissipation for generic nonequilibrium protocols. The notion of thermodynamic length
has been developed [107] for GKSL systems with single asymptotic states. Minimization of
this length provides a characterization of the minimal dissipation of the time evolution of a
Hamiltonian in an open quantum system. Meanwhile, general thermodynamic uncertainty
relations have also been developed [108] for single asymptotic states. These provide a general
set of uncertainty relations between the currents of a system in an asymptotic state and the
entropy production rate of the system, in terms of the information geometric metric (i.e., the
Fisher information) on nonequilibrium asymptotic states. Extending these notions to multiple
asymptotic states can help us develop expressions of energy dissipation for time evolving
systems for multiple asymptotic states. In order to characterize the efficiency of reversible
information processing operations, we're interested in the dissipation as a function of delay,
D (d). For reversible computing in an open quantum system, multiple asymptotic state
framework, we want to be able to characterize the minimal dissipation for any Hamiltonian
we might want to write that can represent the model we're using for a reversible computer.
Fundamentally, both the dissipation and delay will depend quite fundamentally and
intrinsically on the underlying geometry of the asymptotic states. From the derivation of an
adiabatic (i.e., Berry-like) curvature on the space induced by asymptotic states [18,19], we
can immediately anticipate that the expression for thermodynamic length in open quantum

59 of 68

systems will depend intricately on this induced curvature. Given that quantum speeds for
GKSL systems are expressed through a suitable metric on the information geometry of states
[109], we can expect that the delay can be derived similarly.40 By relating the information
geometry metric tensor with the QGT, we can derive expressions for the delay and in turn the
dissipation in terms of the QGT. This can then provide us with dissipation as a function of
delay.
The development of D (d) will involve as intermediate steps several quantities which
will be of interest to the open quantum systems community as a whole, such as the thermodynamic length and the thermodynamic uncertainty relations for GKSL systems with multiple
asymptotic states. These will be essential for understanding properties of open quantum
systems which have direct bearing on classical reversible computing operations. The bearing
that these properties will have on RC operations per se also depends on the particulars of how
RC operations are represented in open quantum systems. We have here provided some of
the initial groundwork for these representations, but several specific details which are vital
for understanding RC operations and the application of open quantum system properties to
RC remain to be developed in full. Here, we have identified several key remaining details –
specifically, the quantum geometric signature that different RC operations will have, the representations of merges and splits in the framework of GKSL dynamics with multiple asymptotic
states, and the specific timescale under which the result of a computational operation dephases
to retrieve the DFS sum structure characteristic of classical RC operations. These details are
currently being developed in a forthcoming work, but they are likely not an exhaustive list of
the specific characteristics of open quantum systems representations of RC operations.
5. Conclusions
At this time, much work remains to complete the task of fully fleshing out a useful
physical theory of classical reversible computing based on the tools of modern quantum
thermodynamics and quantum information. Our goal, in this article, was to lay some key
conceptual foundations for that effort, point the way towards further progress that can be
made, and review some important preliminary results.
Our primary conclusion thus far, from this line of work, is that the core insights from
the classic theory of the thermodynamics of computing which originally motivated the field
of reversible computing, rather than being contradicted by the modern non-equilibrium
quantum thermodynamics perspective, are, to the contrary, supported by it. We argued
that the most appropriate understanding of Landauer's Principle is as a statement about
the absolute increase in total entropy that is required when correlated information is lost,
and reviewed the theorems showing that only computational operations that are (fully or
conditionally) logically reversible can avoid such increases, when applied to subsystems that
exhibit correlations to other subsystems, as is normal for subsystems that contain computed
information. In addition, we provided a complementary way of seeing conditional and
unconditional Landauer reset in terms of catalytic thermal operations, which helps shed
some light on the underlying nonequilibrium quantum thermodynamic principles at play
distinguishing the reset processes.
Even in its early stages of development, the GKSL dynamical perspective on computational operations in open quantum systems is already showing quite surprising implications,
of interest both on a purely theoretical level as well as for applications to reversible computing
models. In particular, we see that the quantum geometric properties of the space supporting
RC operations play a central role in governing these operations and the dynamics of systems
40

To elaborate slightly, note that the delay is not necessarily directly bounded by the quantum speed limit, which is defined in terms of dynamical energy
invested, not energy dissipated; however, we can expect that the derivation of the delay will still involve considerations of the speed limit, to the extent that
dissipation can be bounded as a fraction of the dynamical energy.

60 of 68

supporting reversible computation. This offers a tantalizing glimpse into the rich geometrical
structure which underpins and can help support RC operations, and suggests that the discovery of these signatures generally can support reversible computational operations in exotic
structures. Much more work remains to be done in teasing out the geometric structure of RC
operations, with implications of substantial interest both to reversible computing engineering
and the theory of open quantum systems generally.
In conclusion, we see that there is a potentially enormous long-term practical value to
be gained through seriously studying the limits and potentialities of physical mechanisms
designed to efficiently implement reversible computational processes, with an eye towards
making technologies for general digital computing far more efficient. In this article, we have
reviewed a number of key theoretical tools from modern non-equilibrium quantum thermodynamics which we believe will be useful for continuing this line of work and investigating
the physics of reversible computing in more depth. We intend to continue this effort in future
papers, and we invite other interested researchers to join us.
Author Contributions: Conceptualization, Michael Frank and Karpur Shukla; Formal analysis, Michael
Frank and Karpur Shukla; Funding acquisition, Michael Frank and Karpur Shukla; Investigation, Michael
Frank and Karpur Shukla; Methodology, Michael Frank and Karpur Shukla; Project administration,
Michael Frank; Supervision, Michael Frank; Visualization, Michael Frank and Karpur Shukla; Writing –
original draft, Michael Frank and Karpur Shukla; Writing – review & editing, Michael Frank and Karpur
Shukla.
Funding: This research was funded in part by the Laboratory Directed Research and Development
(LDRD) and Advanced Simulation and Computing (ASC) programs at Sandia National Laboratories, a
multimission laboratory managed and operation by National Technology and Engineering Solutions
of Sandia, LLC., a wholly owned subsidiary of Honeywell International, Inc., for the U.S. Department
of Energy's National Nuclear Security Administration under contract DE-NA-0003525. It was also
supported in part by the U.S. Army Research Office (ARO) under cooperative agreement W911NF-14-20075 and BAA W911NF-19-S-0007, and in part by the U.S. Air Force Office of Scientific Research (AFOSR)
under grant number FA9550-19-1-0355. This document describes objective technical results and analysis.
Any subjective views or opinions that might be expressed in this document do not necessarily represent
the views of the U.S. Department of Energy or the United States Government. Approved for public
release, SAND2021-5340 O.
Acknowledgments: The authors would like to thank Victor Albert, Neal Anderson, Gavin Crooks,
Ed Fredkin, John Goold, Giacomo Guarnieri, David Guéry-Odelin, Norm Margolus, Markus Müller,
Kevin Osborn, Subhash Pidaparthi, Greg Snider, David Wolpert, and Noboyuki Yoshikawa for helpful
discussions, and Jimmy Xu for his support. M.F. would also like to thank Rudro Biswas, Robert
Brocato, Erik DeBenedictis, Rupert Lewis, Nancy Missert, and Brian Tierney for their contributions to
the reversible computer engineering efforts at Sandia, and Gladys Eden for her love and encouragement.
K.S. would also like to thank Hannah Watson for her boundless love and emotional support.
Conflicts of Interest: The authors declare no conflict of interest. The funders had no role in the design
of the study; in the collection, analyses, or interpretation of data; in the writing of the manuscript, or in
the decision to publish the results.

61 of 68

Abbreviations
The following abbreviations are used in this manuscript:
AQFP
ASIC
BARC(S)
CMOS
CTMC
CPTP
CTO
DAG
DPI
FET
GKSL
LvN
NEQT
nFET
PES
QC
QCA
QRD
QRT
QGT
RA-CMOS
RC
RNRL
R-QCA
RRE
RTQT
RQFP
SPICE
TO

Adiabatic quantum flux parametron
Application-specific integrated circuit
Ballistic asynchronous reversible computing (in superconductors)
Complementary metal-oxide-semiconductor (circuit/technology)
Continuous-time Markov chain
Completely positive trace-preserving (map/channel)
Catalytic thermal operation(s)
Directed acyclic graph
Data processing inequality
Field-effect transistor
Gorini-Kossakowski-Sudarshan-Lindblad (operator/theory)
Liouville-von Neumann (equation)
Non-equilibrium quantum thermodynamics
n-type FET
Potential energy surface
Quantum computation
Quantum-dot cellular automaton
Quantumr relative divergence
Quantum resource theory
Quantum geometric tensor
Reversible adiabatic CMOS
Reversible computing
Reversible nanomechanical rod logic
Reversible QCA
Relative Rényi entropy
Resource theory of quantum thermodynamics
Reversible quantum flux parametron
Simulation Program with Integrated Circuit Emphasis
Thermal operation(s)

Appendix A. Minimum-Energy Scaling for Classical Adiabatic Technologies
In this appendix, we briefly present the derivation for the scaling of minimum energy
dissipation for reversible technologies such as RA-CMOS (§2.3.1) that obey classic adiabatic
scaling and that can be characterized in terms of relaxation and equilibration timescales.41
First, we assume (as is the case for "perfectly adiabatic" technologies such as [30]) that
the total energy dissipation per clock cycle Ediss in a reversible circuit can be expressed as a
sum of switching losses and leakage losses,
Ediss = Esw + Elk ,

(A1)

and further, that switching and leakage losses depend on the signal energy Esig and transition
time ttr approximately as follows:
τr
,
ttr
ttr
Elk ' Esig * clk * ,
τe

Esw ' Esig * csw *

41

(A2)
(A3)

Note that this particular scaling analysis does not extend to families of technologies that may potentially offer some approximation to a Landau-Zener
type of exponential quantum adiabatic scaling, such as R-QCA (see §2.3.3).

62 of 68

where τr , τe are the relaxation and equilibration timescales, respectively, and csw , clk are small
dimensionless constants characteristic of a particular reversible circuit in a specific family of
technologies, such as [30]. In practice, although these specific formulas are only approximate,
they approach exactness in the regime τr  ttr  τe .
Then, now treating (A2),(A3) as exact, we can write:


1
c
Ediss = Esig csw τr *
+ lk * ttr .
(A4)
ttr
τe
We can collect the constants, absorbing them into adjusted timescales τr0 = csw τr and τe0 =
τe /clk , so


1
0 1
Ediss = Esig τr *
+ 0 * ttr .
(A5)
ttr
τe
Setting the derivative of (A5) with respect to ttr equal to zero, we find that Ediss is minimized
when
1
1
τr0 2 = 0 ,
(A6)
τ
ttr
e
or in other words, when
ttr =

p

τr0 τe0 ,

(A7)

at which point Esw and Elk are equal. The minimum energy dissipation per cycle is then
s
Ediss = 2Esig

τr0
.
τe0

(A8)

Thus, for any given reversible circuit design in a family of technologies with given values
of the constants csw , clk , in order for Ediss to approach 0 as the technology develops, we must
have that the ratio of equilibration/relaxation timescales τe /τr → ∞, and, if the relaxation
timescale τr is fixed, this implies that also the (minimum-energy) value of the transition time
ttr → ∞. These requirements were mentioned in §2.3.1.
More specifically, in order to increase the peak energy efficiency of a reversible circuit
by a factor of N ×, in a given family of technologies obeying classic adiabatic scaling, this
requires that the timescale ratio τe /τr must be increased by N 2 ×, and (assuming τr is fixed)
the transition time ttr for minimum energy will increase by N ×.
Appendix B. Vectorization of the Operator Algebra on Quantum States
In ordinary quantum mechanics, expressions such as (52), (56)), and (60) can be easily
solved using operator algebra techniques. This same principle holds for operators which
operate on other operators (e.g., L̂ˆ operates on density matrices ρ ∈ D(HS )), known as
superoperators. Since the space of L2 -bounded operators
D B(H
ES ) forms
h aiHilbert space in
b
b† B
b
b , the exact same
its own right under the Hilbert-Schmidt inner product A, B := Tr A
operator algebra techniques can be applied to examining superoperators.
A simple way of explicitly writing down these techniques for the L2 -bounded operators
is using the process of vectorization, which we very briefly discuss here following the excellent
presentation in [19]. Succinctly, vectorization is the process of rewriting matrices in Fm × n
as vectors in Fmn via the mapping |vihw| 7→ |vi ⊗ |wi. (Here, F is the field (R or C) that
the matrices live over.) In terms of a basis {|bi i}iN= 1 of HS , the vectorization of an operator
b ∈ B(HS ) appears as:
A
O
b = ∑ ci |bi i 7→ | Aii :=
A
c i | bi i .
(A9)
i

i

63 of 68

As a concrete example, the vectorization of a 2 × 2 matrix appears as:


a
c

b
d



 
a
c

7→ 
 b .
d

The "double-ket" notation for vectorized matrices acts largely the same as the familiar Dirac
notation:42
h iEE
EE
b .
b = O A
b as Ôˆ A
• Superoperators Ôˆ act on operators A
EE‡ DD
EE
b
b .
b is A
= A
• The Hermitian adjoint of A
DD h i
EE DD
EE
b .
b = A
b Ôˆ ‡ = Ôˆ ‡ A
b is given by Ôˆ A
• The Hermitian adjoint of Ôˆ A
EE
h
i
DD
b† B
b B
b := Tr A
b .
• The Hilbert-Schmidt inner product is given by A
DD
EE
b is given by 1 A
b .
– Thus, the trace of A
• The basis {|bi i}iN= 1 of B(HS ) gives a corresponding basis of B(HS ): bij

= | bi i b j .

– From this structure, changing the basis of HS changes the basis of B(HS ), and thus, the
EE
b ∈ B(HS ) and the superoperaexplicit decompositions of the vectorized operators A
tors Ôˆ .
However, the basis change in HS directly reflects a basis change in B(HS ): transforming
|bi i 7→ |ci i directly corresponds to the transformation bij = |bi i b j 7→ cij = |ci i c j .
Thus, we don't need any "extra" information in the transformation: everything can be
expressed entirely in terms of what lives in B(HS ), without needing to further reference
HS .
• An additional complication that doesn't appear with ordinary Hilbert spaces is the operator
algebra structure B(HS ) × B(HS ) → B(HS ); thus, we need to describe the vectorized
b B,
b
version of matrix
Explicitly, the vectorized product of the operators A,
EE multiplication.

 EE
>
b is A
bB
b = C
b ⊗B
b .
bC
b A
and C
In vectorized form, the GKSL equation (56) appears as:
"

L̂ˆ |ρS ii = −i

L̂ˆ ‡



1 ⊗ HbS −

>
bS
H

⊗1



1
+
2

∑


κ ab

∗
2 Fbab

⊗ Fbab − 1 ⊗

† b
Fbab
Fab

−



† b
Fbab
Fab

>

⊗1

#

|ρS ii.

(10)

a, b > 0

Meanwhile, the vectorized form of the adjoint GKSL equation (58)) is given by:
"

# EE
EE

 1

>
>
∗
† b
† b
b
b .
b
b
b
b
b
b
A = i 1 ⊗ HS − HS ⊗ 1 +
κ ab 2 Fab ⊗ Fab − 1 ⊗ Fab Fab − Fab Fab
⊗1
A
2 a, ∑
b>0

(11)

64 of 68

Weh can also derive
to the adjoint evolution equation by examining
i DDthe formal solution
EE
†
†
b (0) ρS ( t ) = A
b (0) ρS ( t ) :
Tr A

h
i DD
EE 
ˆ
b† (0) ρS (t) = A
b† (0) ρS (t) = A
b† (0) etL̂ ρS (t)
Tr A


=

e

tL̂ˆ ‡

(12)



b†

A (0) ρS ( t )

=

DD

b†

EE

A ( t ) ρS ( t ) .

DD
DD
EE
EE
EE
b† (t) = A
b† (0) etL̂ˆ and etL̂ˆ A
b(0) = A
b(t) , we have A
b(t)
Here, since we have A
satisfying the differential equation:
EE
b(t)
EE
d A
b(t)
(13)
= L̂ˆ A
dt
Finally, the vectorized solutions to the differential equation (56) for time-dependent and
time-independent GKSL superoperators are, respectively:


Zt


dt0 L̂ˆ t0
(14a)
|ρS (t)ii = T exp
|ρ (t )ii

 S 0
t0

ˆ

|ρS (t)ii = etL̂ |ρS (t0 )ii.

(14b)
ˆ

These expressions are the same as (52) and ρ(t) = etL̂ ρ(t0 ), but crucially they now allow us to
examine the spectral decomposition of (and analytic functions of) L̂ˆ .
References
1.
2.
3.
4.
5.
6.
7.
8.
9.

10.
11.
12.

42

Landauer, R. Irreversibility and Heat Generation in the Computing Process. IBM J. Res. Dev. 5, 3, 183–191. Jul. 1961.
doi:10.1147/rd.53.0183.
Bennett, C.H. Logical Reversibility of Computation. IBM J. Res. Dev. 17, 6, 525–532. Nov. 1973. doi:10.1147/rd.176.0525.
Bennett, C.H. The Thermodynamics of Computation-a Review. Int. J. Theor. Phys. 21, 12, 905–940. Dec. 1982. doi:10.1007/BF02084158.
Bennett, C.H.; Landauer, R. The Fundamental Physical Limits of Computation. Sci. Am. 253, 1, 48–57. Jul. 1985.
Landauer, R. Computation: A Fundamental Physical View. Physica Scripta 35, 1, 88–95. 1987. doi:10.1088/0031-8949/35/1/021.
Bennett, C.H. Notes on the History of Reversible Computation. IBM J. Res. Dev. 32, 1, 16–23. Jan. 1988. doi:10.1147/rd.321.0016.
Nielsen, M.A.; Chuang, I.L. Quantum Computation and Quantum Information; Cambridge University Press: Cambridge, Cambridgeshire,
UK, 2000.
Wolpert, D.H. The Stochastic Thermodynamics of Computation. J. Phys. A.: Math. Theor. 52, 19, 193001. Apr. 2019. doi:10.1088/17518121/ab0850.
Frank, M.P. Physical Foundations of Landauer's Principle. In RC 2018: Reversible Computation, Proc. 10th Int'l Conf., Leicester, UK, Sep.
12–14, 2018; Kari, J., Ulidowski, I., Eds.; Lecture Notes in Computer Science 11106; Springer: Cham, Zug, Switzerland, 2018, pp. 3–33.
doi:10.1007/978-3-319-99498-7_1. (See also the extended postprint at arXiv:1901.10327.)
Goold, J.; Paternostro, M.; Modi, K. Nonequilibrium Quantum Landauer Principle. Phys. Rev. Lett. 114, 060602. Feb. 2015.
doi:10.1103/PhysRevLett.114.060602.
Guarnieri, G.; Campbell, S.; Goold, J.; Pigeon, S.; Vacchini, B.; Paternostro, M. Full Counting Statistics Approach to the Quantum
Non-Equilibrium Landauer Bound. New J. Phys. 19, 103038. Oct. 2017. doi:10.1088/1367-2630/aa8cf1.
Müller, M. Correlating Thermal Machines and the Second Law at the Nanoscale. Phys. Rev. X 8, 041051. Dec. 2018.
doi:10.1103/PhysRevX.8.041051.
Although our intuitions from Dirac notation directly carry over to the "double-ket" notation, translating back and forth from the vectorized expressions
to the operator expressions can be somewhat nontrivial. Care must be taken when doing so, although discussing these difficulties is beyond the scope of
this paper.

65 of 68

13.
14.
15.

16.

17.
18.
19.
20.

21.
22.
23.
24.
25.

26.
27.
28.
29.
30.
31.
32.
33.
34.
35.
36.
37.
38.
39.
40.

Sagawa, T. Thermodynamics of Information Processing in Small Systems. Ph.D. Thesis, University of Tokyo, Tokyo, Japan, Mar. 2012.
Springer Theses; Springer Nature: Tokyo, 2013. doi:10.1007/978-4-431-54168-4
Parrondo, J.M.R.; Horowitz, J.M.; Sagawa, T. Thermodynamics of Information. Nat. Phys. 11, 131–139. Feb. 2015. doi:10.1038/nphys3230.
Funo, K.; Ueda, M.; Sagawa, T. Quantum Fluctuation Theorems. In Thermodynamics in the Quantum Regime; Binder, F.; Correa, L.A.;
Gogolin, C.; Anders, J.; Adesso, G., Eds.; Fundamental Theories of Physics 195; Springer Nature: Cham, Zug, Switzerland, 2018;
pp. 249–273. doi:10.1007/978-3-319-99046-0_10.
Sagawa, T. Second Law, Entropy Production, and Reversibility in Thermodynamics of Information. In Energy Limits in Computation;
Lent, C.S.; Orlov, A.O.; Porod, W.; Snider, G., Eds.; Springer Nature: Cham, Zug, Switzerland, 2019; pp. 101–139. doi:10.1007/978-3319-93458-7_3.
Albert, V.V.; M.; Jiang, L. Symmetries and Conserved Quantities in Lindblad Master Equations. Phys. Rev. A 89, 022118. Feb. 2014.
doi:10.1103/PhysRevA.89.022118.
Albert, V.V.; Bradlyn, B.; Fraas, M.; Jiang, L. Geometry and Response of Lindbladians. Phys. Rev. X 6, 041031. Nov. 2016.
doi:10.1103/PhysRevX.6.041031.
Albert, V.V. Lindbladians with Multiple Steady States. Ph.D. Thesis, Yale University, New Haven, Connecticut, USA, Jan. 2018.
Available at arXiv:1802.00010.
Frank, M.P. Foundations of Generalized Reversible Computing. In RC 2017: Reversible Computation, Proc. 9th Int'l Conf., Kolkata, India,
Jul. 6–7, 2017; Phillips, I., Rahaman, H., Eds.; Lecture Notes in Computer Science 10301; Springer: Cham, Zug, Switzerland, 2017,
pp. 19–34. doi:10.1007/978-3-319-59936-6_2. (See also the extended postprint at arXiv:1806.10183.)
Zurek, W.H. Decoherence, Einselection, and the Quantum Origins of the Classical. Rev. Mod. Phys. 73, 3. May 2003.
doi:10.1103/RevModPhys.75.715.
Bekenstein, J.D.. Holographic Bound from Second Law of Thermodynamics. Phys. Lett. B 481, 2–4, 339–345. May 2000.
doi:10.1016/S0370-2693(00)00450-0.
Stinespring, W.F. Positive Functions on C ∗ Algebras. Proc. Am. Math. Soc. 6, 211. 1955. doi:10.1090/S0002-9939-1955-0069403-4.
Pechukas, P. Reduced Dynamics Need Not Be Completely Positive. Phys. Rev. Lett. 73, 1060. Aug. 1994.
doi:10.1103/PhysRevLett.73.1060.
Ng, N.H.Y.; Woods, M. Resource Theory of Quantum Thermodynamics: Thermal Operations and Second Laws. In Thermodynamics in
the Quantum Regime; Binder, F.; Correa, L.A.; Gogolin, C.; Anders, J.; Adesso, G., Eds.; Fundamental Theories of Physics 195; Springer
Nature: Cham, Zug, Switzerland, 2018; pp. 625–650. doi:10.1007/978-3-319-99046-0_26.
Lostalgio, M. An Introductory Review of the Resource Theory Approach to Thermodynamics. Rep. Prog. Phys. 82, 11, 114001. Oct.
2019. doi:10.1088/1361-6633/ab46e5.
Chitambar, E.; Gour, G. Quantum Resource Theories. Rev. Mod. Phys. 91, 025001. Apr. 2019. doi:10.1103/RevModPhys.91.025001.
Brandão, F.; Horodecki, M.; Ng, N.H.Y.; Oppenheim, J.; Woods, S. The Second Laws of Quantum Thermodynamics. Proc. Nat. Acad.
Sci. 112, 11, 3275-3279. Jan. 2015. doi:10.1073/pnas.1411728112.
Horodecki, M.; Oppenheim, J. Fundamental Limitations for Quantum and Nanoscale Thermodynamics. Nat. Comm. 4, 2059. Jun.
2013. doi:10.1038/ncomms3059.
Frank, M.P.; Brocato, R.W.; Tierney, B.D.; Missert, N.A.; Hsia, A. Reversible Computing with Fast, Fully Static, Fully Adiabatic CMOS.
In 2020 Int'l Conf. on Rebooting Computing (ICRC), Atlanta, Georgia, USA, Dec. 1–3, 2020; IEEE. doi:10.1109/ICRC2020.2020.00014.
Renithasamy, S.; Wilde, M.M. Relative Entropy and Catalytic Relative Majorization. Phys. Rev. Res. 2, 033455. Sep. 2020.
doi:10.1103/PhysRevResearch.2.033455.
Müller-Lennert, M.; Dupuis, F.; Szehr, O.; Fehr, S.; and Tomamichel, M. On Quantum Rényi Entropies: A New Generalization and
Some Properties. J. Math. Phys. 54, 122203. Dec. 2013. doi:10.1063/1.4838856.
van Erven, T.; Harremos, P. Rényi Divergence and Kullback-Leibler Divergence. IEEE Trans. Info. Theory 60, 7, 3797–3820. Jun. 2014.
doi:10.1109/TIT.2014.2320500.
Rényi, A. On Measures of Dependence. Acta Math. Acad. Sci. Hung. 10, 441–451. Sep. 1955. doi:10.1214/12-STS405.
Audenaert, K.M.R.; Datta, N. α-z-Rényi Relative Entropies. J. Math. Phys. 56, 022202. Feb. 2015. doi:10.1063/1.4906367.
Klimesh, M. Entropy Measures and Catalysis of Bipartite Quantum State Transformations. In 2004 Int'l Sympos. on Information Theory
(ISIT), Chicago, Illinois, USA, Jun. 27–Jul. 2 2004; IEEE. doi:10.1109/ISIT.2004.1365394.
Klimesh, M. Inequalities that Collectively Completely Characterize the Catalytic Majorization Relation. arXiv, 2007; arXiv:0709.3680.
Turgut, S. Catalytic Transformations for Bipartite Pure States. J. Phys. A: Math. Theor. 40, 12185. Sep. 2007.
doi:10.1088/1751-8113/40/40/012.
Wilming, H.; Gallego, R.; Eisert, J. Axiomatic Characterization of the Quantum Relative Entropy and Free Energy. Entropy 19, 241.
May 2017. doi:10.3390/e19060241.
Anderson, N. Conditional Erasure and the Landauer Limit. In Energy Limits in Computation; Lent, C.S.; Orlov, A.O.; Porod, W.; Snider,
G., Eds.; Springer Nature: Cham, Zug, Switzerland, 2019; pp. 65–100. doi:10.1007/978-3-319-93458-7_2.

66 of 68

41.
42.
43.
44.
45.
46.
47.
48.
49.
50.
51.
52.
53.
54.
55.
56.
57.
58.
59.
60.
61.
62.
63.

64.
65.
66.

67.

Perarnau-Llobet, M.; Riera, A.; Gallego, R.; Wilming, H.; Eisert, J. Work and Entropy Production in Generalised Gibbs Ensembles.
New J. Phys. 18, 123035. Dec. 2016. doi:10.1088/1367-2630/aa4fa6.
Kraus, K. General State Changes in Quantum Theory. Ann. Phys. 64, 2, 311–335. Jun. 1971. doi:10.1016/0003-4916(71)90108-4.
Esposito, M.; Harbola, U.; Mukamel, S. Nonequilibrium Fluctuations, Fluctuation Theorems, and Counting Statistics in Quantum
Systems. Rev. Mod. Phys. 81, 1665. Dec. 2009. doi:RevModPhys.81.1665.
Talkner, P.; Lutz, E.; Hänggi, P. Fluctuation Theorems: Work is Not an Observable. Phys. Rev. E 75, 050102(R). May 2007.
doi:10.1103/PhysRevE.75.050102.
Reeb, D.; Wolf, M.M. An Improved Landauer Principle with Finite-Size Corrections. New J. Phys. 16, 103011. Oct. 2014.
doi:10.1088/1367-2630/16/10/103011.
Breuer, H.-P.; Petruccione, F. The Theory of Open Quantum Systems; Oxford University Press: Oxford, Oxfordshire, UK, 2007.
Breuer, H.-P; Burgarth, D.; Petruccione, F. Non-Markovian Dynamics in a Spin Star System: Exact Solution and Approximation
Techniques. Phys. Rev. B 70, 045323. Jul. 2004. doi:PhysRevB.70.045323.
Breuer, H.-P; Gemmer, J.; Michel, M. Non-Markovian Quantum Dynamics: Correlated Projection Superoperators and Hilbert Space
Averaging. Phys. Rev. E 73, 016139. Jan. 2006. doi:PhysRevE.73.016139.
Ivanov, A; Breuer, H.-P. Extension of the Nakajima-Zwanzig Approach to Multitime Correlation Functions of Open Systems. Phys.
Rev. A 92, 032113. Sep. 2015. doi:PhysRevA.92.032113.
Lindblad, G. On the Generators of Quantum Dynamical Semigroups. Commun. Math Phys. 48, 2, 119–130. Jun. 1976.
doi:0.1007/BF01608499.
Gorini, V; Kossakowski, A.; and Sudarshan, E.C.G. Completely Positive Dynamical Semigroups of N-Level Systems. J. Math. Phys. 17,
821. May 1976. doi:10.1063/1.522979.
Kossakowski, A. On Quantum Statistical Mechanics of Non-Hamiltonian Systems. Rep. Math. Phys. 3, 4, 247–274, Dec. 1972.
doi:10.1016/0034-4877(72)90010-9.
Wolf, M.M.; Cirac, J.I. Dividing Quantum Channels. Commun. Math. Phys. 279, 147–168, Feb. 2008. doi:10.1007/s00220-008-0411-y.
Wolf, M.M.; Eisert, J.; Cubitt, T.S.; Cirac, J.I. Assessing Non-Markovian Quantum Dynamics. Phys. Rev. Lett. 101, 150402, Oct. 2008.
doi:10.1103/PhysRevLett.101.150402.
Ingarden, R.S.; Kossakowski, A. On the Connection of Nonequilibrium Information Thermodynamics with Non-Hamiltonian
Quantum Mechanics of Open Systems. Ann. Phys. 89, 2, 451–485, Feb. 1975. doi:10.1016/0003-4916(75)90190-6.
Alicki, R.; Lendi, K. Quantum Dynamical Semigroups and Applications; Lecture Notes in Physics 717; Springer-Verlag: Berlin, Germany,
2007. doi:10.1007/3-540-70861-8.
Woit, P. Quantum Theory, Groups, and Representations ; Springer International Publishing: New York, New York, USA, 2017.
doi:10.1007/978-3-319-64612-1.
Baumgartner, B.; Narnhofer, H. Analysis of Quantum Semigroups with GKS-Lindblad Generators: II. General. J. Phys. A: Math. Theor.
41, 39, 395303, Sep. 2008. doi:10.1088/1751-8113/41/39/395303.
Ticozzi, F.; Viola, L. Quantum Markovian Subsystems: Invariance, Attractivity, and Control. IEEE Trans. Aut. Control 53, 9, 2048–2063,
Oct. 2008. doi:10.1109/TAC.2008.929399.
Blume-Kohout, R.; Ng, H.K.; Poulin, D.; Viola, L. Information-Preserving Structures: A General Framework for Quantum Zero-Error
Information. Phys. Rev. A 82, 062306, Dec. 2010. doi:10.1103/PhysRevA.82.062306.
Deschamps, J.; Fagnola, F.; Sasso, E.; Unamità, V. Structure of Uniformly Continuous Quantum Markov Semigroups. Rev. Math. Phys.
28, 01, 1650003, Mar. 2016. doi:10.1142/S0129055X16500033.
Pastawski, F.; Preskill, P. Code Properties from Holographic Geometries. Phys. Rev. X 7, 021022, Mar. 2017.
doi:10.1103/PhysRevX.7.021022.
Younis, S.G.; Knight, Jr., T.F. Practical Implementation of Charge Recovering Asymptotically Zero Power CMOS. In Research on
Integrated Systems: Proc. 1993 Symp., Seattle, WA, Feb. 1993; Ebeling, C., Borriello, G., Eds.; MIT Press: Cambridge, 1993, pp. 234–250.
Available at ftp://publications.ai.mit.edu/ai-publications/pdf/AITR-1500.pdf.
Younis, S.G. Asymptotically Zero Energy Computing Using Split-Level Charge Recovery Logic. Ph.D. Thesis, Massachusetts Institute
of Technology, Cambridge, Massachusetts, USA, June 1994. Available at http://hdl.handle.net/1721.1/11620.
Frank, M.P. Reversibility for Efficient Computing. Ph.D. Thesis, Massachusetts Institute of Technology, Cambridge, Massachusetts,
USA, June 1999. Available at http://hdl.handle.net/1721.1/9464.
Venkiteswaran, A.; He, M.; Natarajan, K.; Xie, H.; Frank, M.P. Driving Fully-Adiabatic Logic Circuits Using Custom HighQ MEMS Resonators. In Proc. Int'l Conf. on Embedded Systems and Applications, ESA '04 and Proc. Int'l Conf. on VLSI, VLSI '04
(ESA/VLSI 2004), Las Vegas, Nevada, USA; Arabnia, H.R., Guo, M., Yang, L.T., Eds.; CSREA Press, 2004, pp. 5–11. Available at
http://revcomp.info/legacy/revcomp/AdiaMEMS/MLPD-04.pdf.
Zulehner, A.; Frank, M.P.; Wille, R. Design Automation for Adiabatic Circuits. In ASPDAC '19: Proc. 24th Asia and South Pacific Design
Automation Conference, Tokyo, Japan, Jan. 2019; ACM; pp. 669–674. doi:10.1145/3287624.3287673.

67 of 68

68.

69.
70.

71.
72.
73.
74.
75.
76.
77.
78.
79.
80.
81.
82.
83.
84.
85.
86.
87.

88.
89.

90.
91.
92.
93.

Frank, M.P.; Brocato, R.W.; Conte, T.M.; Hsia, A.; Jain, A.; Missert, N.A.; Shukla, K.; Tierney, B.D. Special Session: Exploring the
Ultimate Limits of Adiabatic Circuits. In 2020 IEEE 38th Int'l Conf. on Computer Design (ICCD), Hartford, Connecticut, USA, Oct. 18–21,
2020; IEEE. doi:10.1109/ICCD50377.2020.00018.
Feynman, R.P. Feynman Lectures on Computation; CRC Press: Boca Raton, Florida, USA, 2000.
Frank, M.P. Common Mistakes in Adiabatic Logic Design and How to Avoid Them. In Proc. Int'l Conf. on Embedded Systems and
Applications, ESA '03, Las Vegas, Nevada, USA, June 23–26, 2003; Arabnia, H.R., Yang, L.T., Eds.; CSREA Press, pp. 216–222. Available
at http://revcomp.info/legacy/revcomp/MLPD03-Mistakes-paper.pdf.
Takeuchi, N.; Yamanashi, Y.; Yoshikawa, N. Reversible Logic Gate Using Adiabatic Superconducting Devices. Scientific Reports 4, 6354,
Sep. 2014. doi:10.1038/srep06354
Takeuchi, N.; Yamanashi, Y.; Yoshikawa, N. Recent Progress on Reversible Quantum-Flux-Parametron for Superconductor Reversible
Computing. IEICE Trans. Electronics E101-C, 5, 352–358, 2018. doi:10.1587/transele.E101.C.352.
Yamae, T.; Takeuchi, N.; Yoshikawa, N. A Reversible Full Adder using Adiabatic Superconductor Logic. Superconductor Sci. and Tech.
32, 3, art. 035005, Jan. 2019. doi:10.1088/1361-6668/aaf8c9.
Lent, C.S.; Tougaw, P.D.; Porod, W.; Bernstein, G.H. Quantum Cellular Automata. Nanotechnology 4, 1, 49–57, Jan. 1993.
doi:10.1088/0957-4484/4/1/004.
Amlani, I.; Orlov, A.O.; Toth, G.; Bernstein, G.H.; Lent, C.S.; Snider, G.L. Digital Logic Gate Using Quantum-Dot Cellular Automata.
Science 284, 5412, 289–291, Apr. 1999. doi:10.1126/science.284.5412.289.
Lent, C.S.; Isaken, B. Clocked Molecular Quantum-Dot Cellular Automata. IEEE Trans. Electron Devices 50, 9, 1890–1896, Aug. 2003.
doi:10.1109/TED.2003.815857.
Pidaparthi, S.S.; Lent, C.S. Exponentially Adiabatic Switching in Quantum-Dot Cellular Automata. J. Low Power Electronics &
Applications 8, 3, 30, Sep. 2018. doi:10.3390/jlpea8030030.
Pidaparthi, S.S.; Lent, C.S. Energy Dissipation During Two-State Switching for Quantum-Dot Cellular Automata. J. Appl. Phys. 129, 2,
art. 024304, Jan. 2021. doi:10.1063/5.0033633.
Drexler, K.E. Molecular Engineering: An Approach to the Development of General Capabilities for Molecular Manipulation. Proc.
Nat'l Acad. Sci. 78, 9, 5275–5278, Sep. 1981. doi:10.1073/pnas.78.9.5275.
Drexler, K.E. Molecular Machinery and Manufacturing with Applications to Computation, Ph.D. Thesis, Massachusetts Institute of
Technology, Cambridge, Massachusetts, USA, 1991. Available at http://hdl.handle.net/1721.1/27999.
Drexler, K.E. Nanosystems; John Wiley & Sons: Hoboken, New Jersey, USA, 1992.
Merkle, R.C.; Freitas, Jr., R.A.; Hogg, T.; Moore, T.E.; Moses, M.S.; Ryley, J. Molecular Mechanical Computing Systems. Institute for
Molecular Manufacturing, tech. report #046, 2016. Available at http://www.imm.org/Reports/rep046.pdf.
Merkle, R.C.; Freitas, Jr., R.A.; Hogg, T.; Moore, T.E.; Moses, M.S.; Ryley, J. Mechanical Computing Systems Using Only Links and
Rotary Joints.J. Mechanisms Robotics 10, 6, art. 061006, Sep. 2018. doi:10.1115/1.4041209.
Hogg, T.; Moses, M.S.; Allis, D.G. Evaluating the Friction of Rotary Joints in Molecular Machines. Mol. Sys. Des. & Eng. 2, 3, 235–252,
2017. doi:10.1039/C7ME00021A.
Frank, M.P. Asynchronous Ballistic Reversible Computing. In 2017 IEEE International Conference on Rebooting Computing (ICRC),
Washington, District of Columbia, USA, 2017; IEEE. doi:10.1109/ICRC.2017.8123659.
Frank, M.P.; Lewis, R.M.; Missert, N.A.; Wolak, M.A.; Henry, M.D. Asynchronous Ballistic Reversible Fluxon Logic. IEEE Trans. Appl.
Supercond. 29, 5, Mar. 2019. doi:10.1109/TASC.2019.2904962.
Frank, M.P.; Lewis, R.M.; Missert, N.A.; Henry, M.D.; Wolak, M.A.; DeBenedictis, E.P. Semi-Automated Design of Functional Elements
for a New Approach to Digital Superconducting Electronics: Methodology and Preliminary Results. In 2019 IEEE Int'l Superconductive
Electronics Conf. (ISEC), Riverside, California, Jul. 28–Aug. 1, 2019. doi:10.1109/ISEC46533.2019.8990900.
Wustmann, W.; Osborn, K.D.; Osborn Team. Autonomous Reversible Fluxon Logic Gates. APS March Meeting 2017 abstract.
2017APS..MARC46006W.
Osborn, K.D.; Wustmann, W. Ballistic Reversible Gates Matched to Bit Storage: Plans for an Efficient CNOT Gate Using Fluxons. In
RC 2018: Reversible Computation, Proc. 10th Int'l Conf., Leicester, UK, Sep. 12–14, 2018; Kari, J., Ulidowski, I., Eds.; Lecture Notes in
Computer Science 11106; Springer: Cham, Zug, Switzerland, 2018, pp. 189–204. doi:10.1007/978-3-319-99498-7_13
Wustmann, W.; Osborn, K.D. Reversible Fluxon Logic: Topological Particles Enable Gates Beyond the Standard Adiabatic Limit. APS
March Meeting 2018 abstract. 2018APS..MARK15004W
Yu, L.; Wustmann, W.; Osborn, K.D. Experimental Designs of Ballistic Reversible Logic Gates Using Fluxons. In 2019 IEEE Int'l
Superconductive Electronics Conf. (ISEC), Riverside, California, Jul. 28–Aug. 1, 2019. doi:10.1109/ISEC46533.2019.8990914.
Osborn, K.D.; Wustmann, W. Reversible Fluxon Logic for Future Computing. In 2019 IEEE Int'l Superconductive Electronics Conf.
(ISEC), Riverside, California, Jul. 28–Aug. 1, 2019. doi:ISEC46533.2019.8990955.
Osborn, K.D.; Wustmann, W. Reversible Fluxon Logic With Optimized CNOT Gate Components. IEEE Trans. Appl. Supercond. 31, 2,
1–13, Mar. 2021, art. 1300213. doi:10.1109/TASC.2020.3035344

68 of 68

94.
95.
96.
97.
98.
99.
100.

101.
102.
103.
104.
105.

106.
107.
108.
109.

Wustmann, W.; Osborn, K.D. Reversible fluxon logic: Topological particles allow ballistic gates along one-dimensional paths. Phys.
Rev. B 101, 1, art. 014516, Jan. 2020. doi:10.1103/PhysRevB.101.014516
Wustmann, W.; Osborn, K.D. Reversible Fluxon Logic with shift registers. APS March Meeting 2020 abstract. Available at
https://meetings.aps.org/Meeting/MAR20/Session/A36.3.
De Haas, W.J.; Wiersma, E.C.; Kramers, H.A. Experiments on adiabatic cooling of paramagnetic salts in magnetic fields. Physica 1, 1-6,
1–13, 1934. doi:10.1016/S0031-8914(34)90002-141.
Kunzler, J.E.; Walker, L.R.; Galt, J.K. Adiabatic demagnetization and specific heat in ferrimagnets. Physical Review 119, 5, 1609, 1960.
doi:10.1103/PhysRev.119.160942.
Pecharsky, V.K.; Gschneidner, K.A., Jr. Magnetocaloric effect and magnetic refrigeration. Journal of Magnetism and Magnetic Materials
200, 1–3, 44–56, 1999. doi:10.1016/S0304-8853(99)00397.
Church, A. An Unsolvable Problem of Elementary Number Theory. Am. J. Math. 58, 2, 345–363, Apr. 1936. doi:10.2307/2371045.
Wolpert, D. Overview of Information Theory, Computer Science Theory, and Stochastic Thermodynamics for Thermodynamics of
Computation. In The Energetics of Computation in Life and Machines; Wolpert, D.; Kempes C.; Stadler, P.; Grochow, J., Eds.; Santa Fe
Institute Press: Santa Fe, New Mexico, USA, 2019; pp. 1–36. Available at arXiv:1901.00386.
Nakahara, M.; Rahimi, R.; SaiToh, A. Mathematical Aspects of Quantum Computing 2007; Kinki University Series on Quantum
Computing 1; World Scientific: Singapore, 2007.
Wolf, M.M. Quantum Channels and Operations Guided Tour (unpublished). Available at
https://www-m5.ma.tum.de/foswiki/pub/M5/Allgemeines/MichaelWolf/QChannelLecture.pdf.
Attal, S. Lectures in Quantum Noise Theory (unpublished). Available at http://math.univ-lyon1.fr/ attal/chapters.html.
Wilde, M.M. Quantum Information Theory, 2nd Edition; Cambridge University Press: Cambridge, Cambridgeshire, UK, 2017. Prepublication copy available at arXiv:1106.1445.
Frank, M.P.; DeBenedictis, E.P. A Novel Operational Paradigm for Thermodynamically Reversible Logic: Adiabatic Transformation
of Chaotic Nonlinear Dynamical Circuits. In 2016 Int'l Conf. on Rebooting Computing (ICRC), San Diego, California, USA, Oct. 2016;
pp. 1–8. doi:10.1109/ICRC.2016.7738679. (Note: See also the presentation notes available at https://tinyurl.com/Frank-DeBenedictis16 for key results not included in the paper.)
IEEE. Beyond CMOS chapter, International Roadmap for Devices and Systems, 2020 ed.; IEEE, 2020. Available at https://irds.ieee.org/editions/2
cmos.
Scandi, M.; Perarnau-Llobet, M. Thermodynamic Length in Open Quantum Systems. Quantum 3, 197, Oct. 2019.
doi:10.22331/q-2019-10-24-197.
Guarnieri, G.; Landi, G.T.; Clark, S.R.; Goold, J. Thermodynamics of Precision in Quantum Nonequilibrium Steady States. Phys. Rev.
Res. 1, 033021, Oct. 2019. doi:10.1103/PhysRevResearch.1.033021.
Deffner, S.; Campbell, S. Quantum Speed Limits: From Heisenberg's Uncertainty Principle to Optimal Quantum Control. J. Phys. Rev.
A: Math. Theor. 50, 453001, Oct. 2017. doi:10.1088/1751-8121/aa86c6.

