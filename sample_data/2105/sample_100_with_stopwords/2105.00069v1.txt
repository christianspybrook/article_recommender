unbiased deterministic total ordering of parallel simulations with simultaneous events neil mcglohon christopher d carothers rensselaer polytechnic institute troy new york usa mcglon2rpiedu rensselaer polytechnic institute troy new york usa chriscarothersgmailcom arxiv210500069v1 csdc 30 apr 2021 abstract in the area of discrete event simulation des event simultaneity occurs when any two events are scheduled to happen at the same point in simulated time simulation determinism is the expectation that the same semantically configured simulation will be guaranteed to repeatedly reproduce identical results since events in des are the sole mechanism for state change ensuring consistent realtime event processing order is crucial to maintaining determinism this is synonymous with finding a consistent total ordering of events in this work we extend the concept of virtual time to utilize an arbitrarylength series of tiebreaking values to preserve determinism in parallel optimistically executed simulations without imposing additional bias influencing the ordering of otherwise incomparable events furthermore by changing the core pseudorandom number generator seed at initialization different orderings of events incomparable by standard virtual time can be observed allowing for fair probing of other potential simulation outcomes we implement and evaluate this extended definition of virtual time in the rensselaer optimistic simulation system ross with three simulation models and discuss the importance of deterministic event ordering given the existence of event ties ccs concepts  computing methodologies discreteevent simulation simulation evaluation mathematics of computing probabilistic algorithms keywords parallel discrete event simulation determinism event simultaneity order theory introduction discrete event simulation des is an effective method for simulating a wide variety of phenomena it quantifies any occurrence in the simulation as being an event that occurs on a simulation entity this event alters the state according to some encoded context and occurs at a temporal coordinate in the simulation defined by an offset from its current definition of time because simulation state only changes when an event happens the outcome of a simulation is entirely dependent on the initial state and the set of ordered events that alters it it is expected that two identically configured simulations will produce identical results simulations with this property are referred to as deterministic and it is a common expectation for models developed in des maintaining determinism in a simulation can help confirm that there is not additional errant undefined behavior occurring the defined rules of a deterministic simulation given a singular input result in a singular answer from a highlevel view maintaining determinism appears to be a simple task process events in the order in which they are scheduled to occur however there are complications that can add complexity to this objective in a parallel processing environment a simulation is partitioned across multiple processors with events occurring between entities that may not exist on the same processor because of this the nature of interprocessor clock drift and individual processing delays ensuring a deterministic ordering of event execution requires additional synchronization overhead fortunately this is generally a solved problem in parallel discrete event simulation pdes with various synchronization methods for conservative parallel and optimistic parallel execution one complication however is event simultaneity events that occur at the same coordinate in virtual time given two simultaneous events that each result in different noncommutative state changes on the occurring entity final simulation results will naturally depend on the ordering of these two events in a parallel environment an interprocessor event may arrive at the receiving processor after an earlier timestamped event had been processed violating the virtual timeguaranteed happensbefore relation of the two events correction methods like reversecomputation or checkpoints can be used to revert the simulation to the last known safe state and ensure that a consistent and valid causal ordering is maintained despite this phenomenon however there could be a problem when two events are to occur at the same coordinates in virtual spacetime given the encoded standard virtual timestamps alone there is not a clear way to define which event happensbefore the other which results in a loss of determinism to regain assured determinism a set of rules can be defined dictating the expected ordering of two simultaneous events given a strictly increasing event counter on each processor that increments with every new event then in the case of simultaneous events we can give priority based on the sending processor id if that too is identical then we can give priority based on the event id encoded from the event counter determinism was regained but with one major caveat the resulting ordering is influenced by the bias of the chosen of ruleset because of this bias imparted by the ruleset it is difficult to know for certain if the resulting simulation behavior is exemplary of the simulated models behavior as a whole or a special case determined by said rulesets influence on event ordering in this work we extend the definition of virtual time to include a set of tiebreaking values and devise a mechanism for unbiased arbitration of simultaneous neil mcglohon and christopher d carothers events in a parallel discrete event simulator with optimistic execution this is accomplished by utilizing a rollbacksafe tiebreaking uniform random number generator we develop this mechanism into the rensselaer optimistic simulation system ross and exhibit its effects on simulation performance and model behavior because ross even in optimistic execution utilizes fully deterministic pseudorandom number generators prngs different rng initialization seed values will yield different but deterministic event orderings even in the presence of simultaneous events allowing for deeper statistical analysis of simulated models in this work we propose and argue three new mechanisms for finding a deterministic total ordering of events in a parallel discrete event simulation with simultaneous events 1 unbiased random total ordering of otherwise incomparable simultaneous events 2 biased random total ordering of otherwise incomparable simultaneous events including events created with zerodelayoffset 3 unbiased random total ordering of otherwise incomparable simultaneous events including events created with zerodelayoffset problem definition for this work we specifically utilize the rensselaer optimistic simulation system ross pdes engine 3 4 which implements the time warp protocol 810 in conjunction with virtual time 11 in a ross simulation entities or agents are represented as logical processes lps these lps are mapped to the various processing elements pes that may exist typically there is one pe per physical mpi process that is participating in the actual execution of the simulation ross is capable of being run in three main modes of synchronization when the simulation is to be executed on a single process it is executed in sequential mode maintaining determinism in this mode is trivial the challenge of determinism comes when additional pes are added to the simulation with additional pes comes the advent of remote events those whose destination is on a different pe than its source all propositions in this work are based on the following assumptions and definitions assumption 1 in a parallel environment arrival order of interprocessor messages is not guaranteed to be consistent across executions of a simulation this is due to natural differences of local clockspeed even the smallest perturbation can lead to enough clock drift to change the order in which any two events from different processors may arrive at a third processor if this is not accounted for it can lead to drastically different final results fortunately this is addressed by time warps virtual time approach to parallel event processing assumption 2 every event in the simulation is encoded with a standard virtual timestamp specifying when in simulation time the event occurs without virtual time a receiving process will have no ability to determine when in the future the event should occur given this encoded virtual time it is possible for the receiving process to deduce a partial ordering of this received event and others that the process is aware of assumption 3 each processing element in a pdes system has a priority queue maintaining a proper order of arrived events to be processed because different lps across pes may be scheduling events at various times in the future we cannot assume that events will arrive in the exact order that they are to be executed and by assumption 1 can not be guaranteed even if one tried to make it so thus each pe should manage a queue maintaining a proper order in which events should be processed this is almost certain to exist in any parallel simulator that implements virtual time in an optimistically executed simulation events that arrive at an lp after its current definition of now are referred to as straggler events 6 to address this optimistic simulations can be rolled back after rolling back the simulation to a known safe state the undone events can be correctly ordered in the priority queue and reprocessed none of this can be accomplished without some ordered queue assumption 4 no lp can create events at a virtual time in the past relative to its own definition of virtual time this is a safe assumption as the entirety of discrete event simulation relies on the basis of maintaining causalorder causal ordering can be formally stated as definition 1 from 11 event a causes b a b if there exists any sequence of events a e 0 e 1 en b such that for each pair ei and ei1 of adjacent events either a ei and ei1 are both in the same process and the virtual time of ei ei1 or b event ei sends a message to be received at event ei1 because in virtual time simulations the virtual spacetime coordinates of an event define the happensbefore and causal relations of events the only instance where two events are considered incomparable is when they have identical virtual timestamps ie simultaneous events or an event tie definition 2 two events are considered comparable if a consistent happensbefore relation can be inferred between the two if no happensbefore relation can be inferred then they are considered incomparable definition 3 an event created with zero virtualtime delay between its encoded timestamp and the creating lps definition of now timestamp of the causal event is referred to as a zerooffset event assumption 5 every lp has at least one rollbacksafe pseudorandom number generator stream solely dedicated to generating uniform random values to encode into events that it creates to achieve the goal of creating an unbiased ordering of simultaneous events via a pseudorandom number generator it is imperative that this stream be completely independent from other streams accessed in the model and deterministically rolled back for reasons which will be explained in detail in section 32 it is also critical that this prng can be deterministically rolled back to a previous state should the events it generated values for be cancelled or rolled back unbiased deterministic total ordering of parallel simulations with simultaneous events with the above assumptions and definitions we posit the following problem problem statement 1 given an optimistically or conservatively executed parallel discrete event simulation with the above assumptions consisting of a partially ordered set of virtualtime encoded events e which may or may not contain event ties find a mechanism which ensures unbiased total ordering of e such that any subsequent executions of the simulation are deterministic event simultaneity another way to phrase problem 1 is given a simulation of events find a mechanism to randomly establish the partial ordering found by a parallel simulation in a way that is deterministic and identical to the total ordered version found by a sequential execution of the same simulation if all events in a partially ordered simulation are comparable to each other then the partially ordered events are also considered totally ordered as briefly mentioned in section 1 deterministic ordering of simultaneous events can be achieved by establishing a ruleset that is enforced by each pe dictating which event happensbefore another if this ruleset is precise enough to render every possible event in the simulation comparable to every other event then a deterministic total ordering can be established from its partial counterpart in figure 1 events a b c and d all occur simultaneously in the simulation how this ruleset is defined will specify how these events are ordered to occur in the simulation the orderings of c and d are specifically of consequence due to them each operating on the same lp ordering bias this ruleset would in effect turn incomparable simultaneous events into comparable events that occur simultaneously yet infinitesimally before or after one another an example ruleset would be as follows in decreasing order of importance cascading down to break any subsequent value ties figure 1 in this lpevent diagram all events a b c and d occur at each of their respective lps simultaneously determining how these events c and d in particular should be ordered in a final total ordering may have an effect on final simulation results ruleset 2 ordering without bias given 2way event ties give priority to 1 events with lower virtual timestamp 2 events that win a coin flip with this rulset given two tied events a and b there is a 50 chance of being ordered as ab and a 50 chance of being ordered as ba if we can randomly generate the values necessary for this coin flip to occur then we can without bias order all events in a simulation with at most 2way event ties this can easily be extended to nway ties instead of a coinflip encode an iid uniform random ur value into an event when it is created and implement the following ruleset ruleset 3 ordering without bias given nway event ties give priority to 1 events with lower virtual timestamp 2 events with lower tiebreaking value ruleset 1 ordering with explicit bias give priority to 1 events with lower virtual timestamp 2 events with lower pe id 3 events with lower lp id 4 events with lower per pe event id this however will result in a single final result with likely few options that would allow users to explore alternate orderings perhaps with greater consequence is the amount of bias that this ruleset instills into the simulation in the case of a timestamp tie it will always give priority to whatever event came from a lower numbered processor this means that lps mapped to lower numbered processors for instance will always take precedence should they tie and that the same simulation but with different numbers of pes or a different mapping will likely generate different final results given the possibility of a twoway event tie it is possible to relinquish the simulated model from the influences of our bias by instead relying on a fair coin flip given an nway tie each event having its own independently generated uniform random value any specific ordering of these events constitutes a single possibility occurring with probability 1n out of all possible permutations of these tied events furthermore the probability of any two tied events being ordered a specific way with respect to each other is 50 this method is equivalent to what is described and proven in 5 as permutebysorting yielding the following lemma lemma 1 from 5 given a list of length n with n distinct iid uniform random values a uniform random permutation can be found by assigning one value to each item in the list and sorting according to these values if the probability of tiebreaker collision is negligible then it is possible to generate a uniform or unbiased random permutation by sorting based on the uniform randomly generated key it follows that by using ruleset 3 we can extract an unbiased random ordering of an nway event tie neil mcglohon and christopher d carothers one may question whether any random ordering of these events is safe the most important thing in ordering simultaneous events is to uphold event causality no event caused by another can happen before the other event lemma 2 if there are no zerooffset events in a simulation then no events participating in a tie caused any other events in said tie proof given the contrapositive if events participating in the tie did cause other events in the tie then there are zerooffset events suppose an event participating in the tie caused another event in the tie because both events are participating in the tie the virtual time difference between the two would be zero by definition the caused event was scheduled with zerooffset thus by contrapositive proof if zerooffset events are not allowed then no events in an event tie caused any other events in the same tie a consequence of this lemma is that if there are no zerooffset events in a simulation then because there is no causal linking between any events participating in the tie no two events in the tie are ordinarily comparable if they were comparable by their virtual timestamps then they would not be in this tie in the first place because events that are not causally related to each other and incomparable could be processed in any order without violating causality then a random permutation of these events constitutes a valid ordering proposition 1 providing in addition to the standard virtual timestamp a secondary uniform random value and comparing tied events based on that will yield an unbiased ordering of events without violating causality given no zerooffset events proof lemma 2 assures that no events in any event tie will have a causal relationship with any others in the same tie because these events given their standard virtual timestamp are thus incomparable any possible permutation of these events is causally safe and by lemma 1 an implementation of ruleset 3 will allow these events to be comparable and yield an unbiased ordering of events for clarification we define the combination of a virtual timestamp and any secondary values determining event priority as a virtual time signature events created in accordance to proposition 1 that are incomparable by their virtual timestamps are comparable by their virtual time signature it is important to note however that lemma 1 relies on distinct values from its uniform random number generator by the nature of prngs this is not possible for the purposes of our work though we utilize sufficiently precise prngs with very large periods and thus we assume the probability of generating nondistinct values is negligible should this probability still be considered too high additional tiebreaking values can be generated and encoded via supplementary independent prng streams by applying permutebysorting recursively to sublists containing prng value collisions this effectively increases the bit precision of the primary tiebreaking value making overall collision even less likely while maintaining the expected lack of bias determinism with randomness we have now established that given a good choice of ruleset we can create an unbiased ordering of events in a simulation but this alone does not grant determinism the ross simulator guarantees assumption 5 allocating an independent prng stream on every lp with the sole duty of generating the tiebreaker values encoded into each event that that lp creates one valuable property of prngs is that given a specific seed the sequence of values generated from it is deterministic in a sequentially or conservative parallel executed simulation this allows for pseudorandomness without sacrificing determinism in neither of these execution modes is there ever a rollback to a previous simulation state when executing a parallel simulation optimistically however rollbacks are expected if the state of a prng stream indicating the position of the next value in the sequence is not also rolled back when necessary then a different set of numbers will be generated for events when the simulation is resumed as a result lp state changes and decisions based on that prng stream will differ from an execution where said rollbacks did not occur a loss of determinism corollary 1 using a rollbacksafe tiebreaking uniform random value in execution of proposition 1 will yield a deterministic unbiased ordering of events without violating causality given no zerooffset events any extra identifier that enables the comparison of two events that would otherwise be incomparable must be implemented into all parts of a system that compares two events if for instance a pdes system is configured to process events in a specific order but care is not taken to recognize any stragglermessage based on virtual time signatures and correct it then there will no longer be any guarantee of determinism any events irrevocably committed to the simulation history must be in agreement with the new extended definition of virtual time zerooffset event simultaneity proposition 1 makes certain assumptions about the nature of the problem and the simulation environment it operates in specifically it does not allow for zerooffset events to exist in the simulation while this may seem rather inconsequential from a realworld perspective we are quite used to imposed speed limits in traversing spacetime this is not necessarily a guaranteed assumption for every possible simulated model to allow for zerooffset events in a simulation there are some finer details that must be established to ensure that a deterministic valid unbiased total ordering of events can be found part of what makes this difficult is that the act of creating zerooffset events by definition creates event ties as a result an event that generates a new event with a zerooffset is creating a new event that in virtual time occurs at the same time as the event that created it in this instance the order in which these two events are committed to simulation history is very important its also important to note that while assumption 4 is standard for virtual timestamps the same must also be held true for any happensbefore relations inferred from an extended definition of unbiased deterministic total ordering of parallel simulations with simultaneous events virtual time furthermore the virtual time signature of any event must be strictly greater than the time signature of its causal parent challenge of zerooffset events we have shown with proposition 1 that an unbiased total ordering of simultaneous events can be found with a uniform random value acting as a tiebreaker this works by establishing an unbiased hard rule of how any two events should be ordered in the simulation proposition 1 worked because any arbitrary ordering of otherwise incomparable events will result in a valid simulation this becomes tricky once zerooffset events are introduced because a parent event and its zerooffset child have the same virtual timestamps but one event definitely caused the other the ordering in which these two events should be ordered in the final simulation history cannot be arbitrary in a solution using proposition 1 to create an unbiased random ordering of events an absolute comparison of iid random tiebreaking values is utilized given an event e that generates a child event e with zerooffset it is entirely possible that the uniform random tiebreaking value of e could be less than that of event e by our extended definition of virtual time this would imply that event e happened before event e which is impossible since event e directly caused e this contradiction caused by a zerooffset event is exactly the same as what would happen if a timetravelling negativeoffset event were created this establishes the following lemma 3 no event can be created in a way that would classify it as happening before any events that caused or happenedbefore it without the tiebreaker value enforcing the final ordering of these events this will execute and complete fine but at the risk of nondeterminism if there are other eventties but with the tiebreaking mechanism the pdes engine will enter an endless loop of rollbacks and replays as it tries fruitlessly to reconcile this situation and adhere to the deterministic tiebreaking order if all we consider was their standard virtual timestamps the two events are incomparable but they are comparable by the ordered chain of causality definition 1 does not account for zerooffset events if we are to have a stable simulation with zerooffset events we need to extend our definition of virtual time to ensure that the virtual time signature of e e and so on for any descendants of event e definition 4 an event which shares a standard virtual timestamp with another but has a lower tiebreaking value is defined to happen infinitesimally before the other the converse implies that the other event happens infinitesimally after the first definition 5 a zerooffset event sharing the virtual timestamp with that of its parent is considered to happen infinitesimally after its parent the converse implies that the parent happens infinitesimally before its children to demonstrate the challenge of utilizing the tiebreaking mechanism we have established in proposition 1 let us assume that we have some ability to ensure that lemma 3 is maintained while using the same tiebreaking mechanism as before then we have nothing to prevent the possibility of generating events with virtual time signatures to happen infinitesimally before others that have already been processed table 1 events and their virtual times and tiebreaking values for the example shown in figure 2 event time tiebreaker 1 01 1 015 1 040 1 030 1 020 figure 2 diagram showing event processing queue state while processing previously given simultaneous events t represents the time in the simulation after a given event has been processed event a is created by a but according to its tiebreaker value should happen before b which has already been processed as designated by a slash consider a sequential simulation there is no ability to rollback events should a new one be generated that happens before one previously processed if a mechanism cannot be used for generating a valid ordering in sequential then it is unlikely to consistently work for parallel executions either as an example two events a and b each generate a zerooffset child event a and b a generates a single zerooffset child a the events are each scheduled to occur at the same point in virtual time but have uniform random generated tiebreaking values to determine the order of events not directly caused by each other the virtual time and tiebreaker values for these events are shown in table 1 in this sequential simulation we would start by processing events a and then b this would schedule two new zerooffset events a and b we could process these two in order according to their tiebreaker values without issue b first however after processing a another child event is created with a tiebreaker value that is lower than b the simulation processing queue state for this example can be observed in figure 2 the result of this is an irreparable error in the simulation in a sequential execution an effective negativetime event was received breaking lemma 3 in an optimistic execution we will enter an infinite rollback scenario and cause instability in sequential this is exactly the challenge of creating a fair deterministic ordering of zerooffset events it is not possible for the simulator to know if a zerooffset event will create another zerooffset event until after its processed thus how can a fair random ordering of zerooffset tie events be determined neil mcglohon and christopher d carothers figure 3 lpevent diagram depicting events all simultaneously occurring with the same virtual timestamp but depicted with varying legal tiebreaking values encoded using the additive scheme described in section 42 the final ordering in the simulation for these tied events is a b b a a biased random causal ordering it is now clear that a single pair of randomly defined tiebreaking values is insufficient for ordering two events given the existence of zerooffset events it is always possible to violate causality and that should never be possible any scheme to determine ordering two events must guarantee causality is maintained we know however that a simulator that utilizes standard virtual time can generate a deterministic total ordering of events if no ties exist because all events have a unique time and the final ordering should just be monotonically increasing by their timestamp this is possible because when new events are created they are encoded with an offset an additive time from now value so long as that value is not negative it guarantees causality is maintained as long as the value is positive it guarantees determinism what if when generating a zerooffset event instead of using a random tiebreaking value from 01 we generate that random value but add it to the random tiebreaking value of the parent event the new tiebreaking value will be strictly greater than the parent assuring that any comparison of the two will always order the parent first a lpevent diagram using the same generated values in the previous example using table 1 but adding consecutively generated tiebreaking values when creating child events is shown in figure 3 proposition 2 providing in addition to the standard virtual timestamp a secondary value defined by summing deterministic uniform random values generated by causally related zerooffset events and comparing tied events based on that will yield a randomizedbutbiased deterministic ordering of events including zerooffset events without violating causality proof given four simultaneous events a b c and d where a b and a c d and b c d are zerooffset from a with additive tiebreaker values assume that an event d is an event that violates lemma 3 in conflict with a previously processed event b the tiebreaker value of d is strictly greater than that of its parent c the only way for d to be created so that it happens before b is if c also happened before b if c happened before b then no ordering of b and d would violate lemma 3 thus by contradiction additive tiebreaking values will safely allow for zerooffset event tiebreaking without violating causality established from lemma 3 this does allow for randomness to be introduced in the ordering of events but it introduces some potentially unintended bias into the comparison of tiebreaking values for example given two events scheduled for the same time a and b event a creates a zero offset child a who creates a zero offset child a the four events are each scheduled for the same virtual time if the tiebreaker value for descendants is additively generated then the probability that event a comes before event b is not 50 it is possible that based on the tiebreaking value that a happens before b but it is far more likely that b happens before a because the expectation for its tiebreaker value is lower than that of a this is because the tiebreaking value encoded into events a and a are no longer a uniform random value from 01 but is instead sampled from an irwinhall distribution 12 the expected value of an irwinhall value is proportional to the number of uniform random values added to generate it and thus the more zerooffset descendants recursively created the less likely they are to happen before another independent event in a way this may seem natural but it is important to remember that these events are all scheduled by the model to happen at the same time this method will assuredly result in a deterministic ordering and this ordering will be somewhat randomized based on the simulations input seed is there however a fairer way to break ties within zerooffset events unbiased random causal ordering when trying to find a fair way to order simultaneous events something to consider is whether it even makes sense for other events to interject between an event and its zerooffset child the two related events are supposed to occur simultaneously with the exception of one being causally dependent by the other the child happens infintesimally afterward by that logic it makes sense that they should be consecutive in the final ordering previously in section 42 we observed that the only way for an events child to precede another independent simultaneous event if the original event also preceded the other what made the additive tiebreaker value successful was that it guaranteed that a zerooffset child event will have a value strictly greater than its parent but it also established a unique timestamp that will not should there be more descendants violate some established order of other already processed events we can devise another mechanism that will ensure that any subsequent zerooffset children of a parent event be processed before other independent events with a greater tiebreaking value than said parent consider ordering two sequences of numbers there are numerous ways to pick some relation and choose which should be considered first in an ordering of the two sets one common way is through lexicographical ordering just as one would find where to place new words into the oxford dictionary of english 21 we start by comparing the first items in the two sets should those two match we recursively compare each of the subsequent items in the sequences until we find a pair that are different determining which of the two is less than the other lexicographically is then based on that final comparison for example let us consider two sequences s 1 5 3 9 3 and s 2 5 3 4 6 lexicographically s 2 s 1 because in the third unbiased deterministic total ordering of parallel simulations with simultaneous events componentwise comparison 4 9 we also observe that it does not matter how long the sequence of s 2 is as long as those first three numbers remain in each sequence then s 2 s 1 always we can extend our definition of virtual time again to include not a single tiebreaking value but a sequence of tiebreaking values the sequence is comprised of the tiebreaking values of historical zerooffset parental events whenever a new event is created a new tiebreaking value is generated and appended to the back of this running list when a regularoffset event is created the sequence is discarded and then the newly generated tiebreaking value for the current event is added as the sole value when comparing two tiebreaking sequences of different lengths but all n components of the shorter one match the first n components of the longer sequence priority is given to the shorter one as this can only happen if the event owning the shorter sequence caused the other referring back to the english dictionary analogy the singleletter word a comes before aardvark but aardvark comes before apple 21 the result of this extension allows for us to make every single event in the simulation comparable to one another via the new virtual time signature in this case the virtual time signature is defined as the sequence of the virtual timestamp followed by the regularoffset tiebreaker and all consecutively generated zerooffset tiebreakers because of the benefits of lexicographical ordering causality is guaranteed as any zerooffset descendants time signature will be strictly greater than its parent grandparent etc the happensbefore comparison of any two tied events that are unrelated will as in proposition 1 be based on a comparison of two uniformrandom values additionally the comparison of any two tied events that are related will also be based on a comparison of twouniform random values unless they are causally locked to a single relative ordering because one is a descendant of the other yielding proposition 3 providing in addition to the standard virtual timestamp a secondary sequence of values defined by deterministic uniform random values generated by causally related zerooffset events and comparing tied events lexicographically based on that will yield an unbiased random deterministic ordering of events including zerooffset events without violating causality proof the exact same logic as demonstrated in the proof of proposition 2 can be applied here to guarantee determinism as lexicographical ordering provides the same strict lessthangreaterthan relation between two events using the same events from that example however we can observe that should c happen before b then d assuredly happens before b as it happens infinitesimally after c the determination of the ordering of d and b still falls down to a fair comparison of two uniform random values the two generated for b and c the probability of d happening before b is effectively randomly determined by a fair coin flip and is unbiased experimental models we evaluate our proposed solution with various methods to observe its capability as well as the performance impact of the solutions overhead we first analyze its performance impact on a standard pdes benchmarking model phold with a strongscaling study in this model event ties are infrequent and there are no zerooffset events none of the results generated from running phold however will tell us about whether the ordering of events was consistent from run to run to do that we developed a new pdes model which intentionally creates as many event ties as possible with and without zerooffset events and the final lp state is dependent on the ordering of these events we show the performance impact in a strong scaling study using this new model we also stress test the simulation with an exceedingly high number of event ties in a worstcase type scenario and observe the performance impact in a third strongscaling study based on a variation of that second model all experiments presented below were performed on the ross pdes engine with and without the unbiased tiebreaking mechanism described in section 43 phold model we utilize the phold benchmarking model included with ross it is a generally well known tool for analyzing the performance of pdes systems 2 6 it generates a lot of events that are sent between an lps self and other lps based on a configurable probability parameter because of the sheer volume of events that this model can generate at large scales this model is not immune to the possibility of event ties but is not exceedingly likely because new events are scheduled at some point strictly in the future at a time that is the result of an exponentially random number valued offset eventties model given any implemented solution for the problems discussed in this work it is difficult to know for certain that the determinism observed in a couple small scale experiments is true determinism or coincidence this is especially the case if event ties are relatively infrequent procedure 1 eventties behavior of lp p on receipt of event e given r preset threshold for desired remote events l preset length of zerooffset event chain pmeanval meanpmeanval eval create new event n nval random integer 0100 if randomunif r then destrandom nonself lp else destself end if if e is the l th zerooffset event then send n to arrive at dest at time pnow1 regularoffset else send n to arrive at dest at time pnow zerooffset end if neil mcglohon and christopher d carothers to validate that our solution accomplishes its core goal we developed a ross model specifically designed to create a scenario where exact event ordering is absolutely critical to deterministic final results a model that utilizes a running sequence of mathematical computations with strict ordering or noncommutative operations operating on local lp state will make nondeterminism evident two identically configured simulations with even slightly different event ordering will yield a different final mathematical result for our model we leverage the noncommutative property of the mean of means procedure 2 eventtiesstress behavior of lp p on receipt of event e given r preset threshold for desired remote events h preset height of zerooffset event tree c preset number of zerooffset children generated per event pmeanval meanpmeanval eval for i 0 c do create new event n nval random integer 0100 if randomunif r then destrandom nonself lp else destself end if ndescendantsum i send n to arrive at dest at time pnow zerooffset end for if e is in the h th level of the tree edescendantsum is 0 then ndescendantsum 0 send n to arrive at dest at time pnow1 regularoffset end if meanmeana b c meanmeana c b to utilize this property when an event is received by an lp its state is updated to be the mean of its current state and the encoded state of the event if two events are received by an lp at a simultaneous point in virtual time and a deterministic rule for simultaneous event ordering is not implemented then because of assumption 1 and the above property simulation determinism is not guaranteed the core behavior of the model is described in procedure 1 when a new event is received the recursive mean value in lp state is updated and a new event with a new random integer is created where this event is destined is based on a probability challenge so that the number of remote simulation events can be controlled when this event is to be scheduled is determined by where in the zerooffset chain this event is if some configured number l 1 samevirtualtime events causally preceded this one then send the new event with an offset of one thereby breaking the zerooffset chain if this event is not the l th event in the zerooffset chain then create another zerooffset event eventtiesstress model in section 52 we showcased an example model that would generate a large number of tied events with and without zerooffset timings but we can make this even harder to showcase the capabilities of our tiebreaking mechanism wherein procedure 1 creates simultaneous chains of zerooffset events we can instead generate simultaneous trees of zerooffset events shown in procedure 2 the difficulty of this model can be scaled by adjusting the height and degree of each generated zerooffset tree the lexicographical ordering operating on the tiebreaking sequences is particularly useful in this case as it is able to quickly determine which event happens before another regardless of if one event is a zerooffset offspring sibling cousin nephewniece or unrelated to the other furthermore we have shown in section 43 that the probability of any two events being ordered a specific way in the simulation is 50 unless one is a zerooffset descendant child grandchild etc of the other in that case there is a single possible relative ordering also shown in procedure 2 is a mechanism to make sure that only one event from a zerooffset tree creates a new zerooffset tree without this there would be exponential growth of events as the simulation proceeds making it progressively more difficult to complete results all simulations performed in this work were executed using at most 4 nodes of the aimos supercomputer at rensselaer polytechnic institutes center for computational innovations 1 each node contains two ibm power 9 processors each with 20 cores with 315ghz clocks and 512gib ram for simplicity of scaling experiments we utilized a maximum of 32 processors per node internode communication is facilitated by an infiniband edr fat tree communication network binaries were compiled using ibms xlcr compiler and spectrum mpi phold strongscaling we wanted to benchmark the performance of this extension of ross in direct comparison with the old version of ross without the deterministic tiebreaker the phold model is commonly used to benchmark ross and other pdes systems and is included in the simulators codebase 2 7 these simulations were configured to each have 2 million lps with a target of 10 remote events generating a total of 13 billion net events what we observe in figure 4 is that the deterministic tiebreaker version runs a bit slower at lower numbers of ranks but catches up as more ranks a re added the overhead of implementing the tiebreaker does not significantly impact parallel performance especially with larger numbers of ranks and because there are so few event ties the benefit may not be obvious based on runtime alone eventties strongscaling using the eventties model we create a situation with as many event ties as possible all event timestamps are either zerooffset or integer incremented 65536 lps were simulated each creating a single regularoffset event which causes a single zerooffset event in total this created 39 million unbiased deterministic total ordering of parallel simulations with simultaneous events phold strong scaling 5000 eventties strong scaling w deterministic tiebreaker wo deterministic tiebreaker simulation runtime s simulation runtime s 6000 4000 3000 2000 1000 820 810 800 790 780 770 000 w deterministic tiebreaker wo deterministic tiebreaker number of ranks 128 figure 4 phold strong scaling study with and without a deterministic tiebreaking mechanism events no event was created that was not tied with another event in the simulation we wanted to be able to show in a plot the capabilities of the deterministic tiebreaker version of ross in contrast to that of the old version the deterministic tiebreaker version excels when faced with many zerooffset events but the old version will give the appearance of stalling as it struggles to make progress the reason for this behavior is that when original ross instigates a rollback it rolls back all events with the same timestamp as the target event it has no way to make two events with the same timestamp comparable this means that if a single straggler event arrives which it most likely will then any progress since the last regular offset event must be rolled back because of this limitation the only way we were able to show these two ross versions in a single plot with this model was to only create zerooffset chains of length two and to instead increase the target remote events to 50 in figure 5 we can see the result of this behavior the old ross version appears to do well to a point and then as more and more ranks are added the probability of a rollback increases and eventually it takes considerable amounts of time for the simulation to complete eventtiesstress strongscaling this model created zerooffset event trees instead of chains as with the standard eventties model this creates more zerooffset siblingsthat where the tiebreaker sequence must be fully utilized to establish a deterministic ordering this model was tested with 131072 lps each generating a 3ary zerooffset tree of depth 5 at every integer timestep in the simulation this created 39 billion total events all with an extreme degree of ties with other events and a target remote percentage of 10 the small increase in runtime for the k 2 ranks run is because for this particular simulation model and configuration the benefit of the additional processing power is not yet able to outweigh the cost of rollbacks which are not observed in the sequential execution 00 1 202 04 8 1606 32 number of ranks 0864 12810 figure 5 eventties strong scaling study with and without a deterministic tiebreaking mechanism note that the yaxis is split to account for the last data point the case for determinism all simulations in this work utilizing the deterministic tiebreaking feature were verified to exhibit the expected determinism in contrast simulations executed without utilizing the tiebreaking mechanism did not consistently generate a reproducible result by looking at the results of the phold scaling one might argue that the overhead and performance impact is too great to warrant utilizing the feature phold lp state does not change throughout the simulation and the generation of future events does not depend on the contents of events received thus even though event ties do occasionally occur in the simulated model their ordering does not affect how many net events there are in the final simulation the same cannot be said for models sensitive to simultaneous event ordering table 2 shows extracted results from a few runs from the eventties scaling results featured in figure 5 we observe small differences in the final results of lp state when there is no arbitration of simultaneous events a lack of determinism with the deterministic tiebreaker functionality enabled however determinism is restored and the parallel executions are identical to their sequential counterpart the difference between the sequential runs with and without the tiebreaker is to be expected and is because the rules dictating order in the tiebreaker simulations also affect the order of events in the sequential version table 2 subset of final results of the sequential k 1 optimistic k 32 and k 128 runs for the eventties model with and without the deterministic tiebreaker tb simulation wo tb k 1 wo tb k 32 wo tb k 128 w tb k 1 w tb k 32 w tb k 128 net events 39190528 39190528 39190528 39190528 39190528 39190528 lp1 final value 350814 344111 344010 347264 347264 347264 neil mcglohon and christopher d carothers eventtiesstress strong scaling simulation runtime s 3000 w deterministic tiebreaker 2500 2000 1500 1000 500 number of ranks 128 figure 6 eventtiesstress strong scaling study with deterministic tiebreaking mechanism the old version of ross did not tolerate this model well and could not make noticeable progress in any execution mode but sequential with the eventties model and any model whose generated events depend on lp state at time of processing however event ordering explicitly affects the final result in the example shown in table 2 it may appear that the executions without the tiebreaker were close enough but this is a product of the simplicity of the model and not indicative of what one could expect with other more complicated models table 2 also shows that simply looking at the number of net events alone is not sufficient for identifying determinism in a simulated model if instead we couple the remote destination decision in procedure 1 to be dependent on its current lp state value then drastically different results are observed it makes sense that should lp state play a role in how events are created if they are created in the first place then that model will be particularly sensitive to the ordering of simultaneous events it is important to keep in mind then given a standard virtual time simulation the level of performance observed in a model with simultaneous events may simply be borrowed with determinism offered as collateral the goal of parallel discrete event simulation is to recreate a semantically identical sequential simulation but distributed across different processing elements if determinism in the parallel execution is not assured then one has by definition failed in this objective related work the topic of event simultaneity and ordering in parallel simulations has been discussed in various contexts over the span of decades 13 19 22 in 14 the topic of distributed logical and physical clocks causal ordering conditions and happensbefore relations is discussed but notes that the included theory makes no requirement about the ordering of incomparable or simultaneous events the clocks discussed base their perception of time based on the perceived happensbefore relations to other events virtual time 11 takes a slightly different approach by inferring happensbefore relations from the encoded timestamps giving a simulated model the power to define when events happen in relation to each other in 20 the authors also extend ross definition of virtual time to encode lower order bits to break event ties much of this paper was inspired by the work performed in 22 the author makes arguments that given a simulation with n simultaneous events then the correct final result is the mean of all n possible event orderings without some mechanism to effectively explore various possible orderings a correct final result is not achievable in our work we provide a method that allows for random sampling of the possible event orderings that same year the authors of 13 proposed an event ordering mechanism for simultaneous events which also employed an extension to the basic timestamp for encoding event priority this mechanism provided identical results between a sequential and parallel executed simulation and is similar in practice to our definition of biased random causal ordering the authors of 19 establish methods for breaking ties based on a logical clock interpretation of event causality or user defined priorities they also briefly argue how different permutations of otherwise incomparable events should be considered and will inherently affect the outcomes of future events but do not elaborate on a solution to effectively explore this space similarly in 15 17 the authors note the importance of discovering other potential outcomes of simultaneous event orderings and propose a pdes branching mechanism tool that facilitates this conclusion in summary we have proposed three solutions to the problem of maintaining a deterministic ordering of events in a parallel conservative or optimistically executed discrete event simulation given the possibility of nway simultaneous events with and without zerooffset events this solution leverages a deterministic pseudorandom number generator to encode values for use in breaking these nway event ties into a specific executionconsistent ordering this ordering can be unbiased and varied by changing the initial seed of the simulations random number generators which allows for further statistical analysis of execution results we evaluated the performance impact of the proposed solution and observed a marginal impact in a standard pdes benchmarking model in the near worstcase stresstest benchmark models the performance of the simulation without the tiebreaking functionality was weakened if it was able to make effective progress at all furthermore a simulation without a tiebreaking feature cannot guarantee that it will deterministically produce an optimistic execution that is semantically identical to the sequential counterpart developers and modelers should always be concerned if a program they wrote generates different results in repeated executions did they make a mistake somewhere is there a race condition they had not accounted for we believe that determinism in parallel discrete event simulation is an important tenet and should not be cast aside in the aim of faster performance as any amount of nondeterminism is by definition unexpected behavior unbiased deterministic total ordering of parallel simulations with simultaneous events references 1 2020 artificial intelligence multiprocessing optimized system aimos center for computational innovations httpsccirpieduaimos 2 peter d barnes christopher d carothers david r jefferson and justin m lapre 2013 warp speed executing time warp on 1966080 cores sigsimpads 2013  proceedings of the 2013 acm sigsim principles of advanced discrete simulation 327336 httpsdoiorg10114524860922486134 3 christopher d carothers david bauer and shawn pearce 2000 ross a highperformance lowmemory modular time warp system proceedings of the workshop on parallel and distributed simulation pads httpsdoiorg101109 pads2000847144 4 christopher d carothers david bauer and shawn pearce 2002 ross a highperformance lowmemory modular time warp system j parallel and distrib comput 62 2002 issue 11 httpsdoiorg101016s0743731502000047 5 thomas h cormen charles e leiserson and ronald l rivest 2001 introduction to algorithms second edition vol 7 issue 9 httpsdoiorg1023072583667 6 richard m fujimoto 1990 parallel discrete event simulation commun acm 33 1 1990 3053 issue 10 httpsdoiorg1011458453784545 7 richard m fujimoto 1990 performance of time warp under synthetic workloads in proceedings of the scs multiconference on distributed simulations 1990 vol 22 2328 8 david jefferson brian beckman fred wieland leo blume and mike di loreto 1987 time warp operating system acm sigops operating systems review 21 1987 issue 5 httpsdoiorg1011453749937508 9 david jefferson brian beckman fred wieland leo blume mike di loreto phil hontalas pierre laroche kathy sturdevant jack tupman van warren john wedel herb younger and steve bellenot 1987 distributed simulation and the time warp operating system proceedings of the 11th acm symposium on operating systems principles sosp 1987 httpsdoiorg1011454145737508 10 david jefferson and henry sowizral 1985 fast concurrent simulation using the time warp mechanism simulation series 15 issue 2 11 david r jefferson 1985 virtual time acm transactions on programming languages and systems toplas 7 1985 issue 3 httpsdoiorg1011453916 3988 12 norman l johnson samuel kotz and narayanaswamy balakrishnan 1995 continuous univariate distributions volume 2 vol 289 john wiley sons 13 ki hyung kim yeong rak seong tag gon kim and kyu ho park 1997 ordering of simultaneous events in distributed devs simulation simulation practice and theory 5 3 1997 253268 issue 3 httpsdoiorg101016s0928486996000092 14 leslie lamport 1978 time clocks and the ordering of events in a distributed system commun acm 21 1978 issue 7 httpsdoiorg101145359545359563 15 patrick peschlow and peter martini 2006 towards an efficient branching mechanism for simultaneous events in distributed simulation proceedings workshop on principles of advanced and distributed simulation pads 2006 133 httpsdoiorg101109pads200636 16 patrick peschlow and peter martini 2007 a discreteevent simulation tool for the analysis of simultaneous events 2007 17 patrick peschlow and peter martini 2007 efficient analysis of simultaneous events in distributed simulation proceedings ieee international symposium on distributed simulation and realtime applications dsrt httpsdoiorg10 1109dsrt200724 18 hassan rajaei 1993 design issues in parallel simulation languages ieee design and test of computers 10 1993 5263 issue 4 httpsdoiorg10110954245963 19 robert ronngren and michael liljenstam 1999 on event ordering in parallel discrete event simulation proceedings of the workshop on parallel and distributed simulation pads 1999 3845 httpsdoiorg101109pads1999766159 20 markus schordan tomas oppelstrup michael kirkedal thomsen and robert glck 2020 reversible languages and incremental state saving in optimistic parallel discrete event simulation in international conference on reversible computation springer cham 187207 21 angus stevenson 2010 oxford dictionary of english oxford university press usa 22 frederick wieland 1995 the threshold of event simultaneity proceedings 11th workshop on parallel and distributed simulation 5659 httpsdoiorg101109 pads1997594586 