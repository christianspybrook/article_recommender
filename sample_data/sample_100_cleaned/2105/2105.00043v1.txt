s ubmodular m utual nformation targeted datas ubset s electionp reprintarxiv210500043v1 cslg 30 apr 2021suraj kothawadesurajkothawadeutdallasedujeff bilmesbilmesuweduvishal kaushalvkaushalcseiitbacinganesh ramakrishnanganeshcseiitbacinrishabh iyerrishabhiyerutdallasedu4 2021bstractrapid growth data increasingly difficult train improve deep learningmodels right subset data problem effectively solvedadditional labeling cost targeted data subset selection tss subset unlabeleddata points similar auxiliary set added training data richclass submodular mutual information smi functions demonstrate effectivenessimage classification cifar10 mnist datasets lastly compare performancesmi functions tss stateoftheart methods closely related problems like activelearning smi functions observe 2030 gain models performanceretraining added targeted subset 12 methodsintroductionrecent times seen unprecedented growth data modalities text images videosnaturally given rise techniques finding effective smaller subsets data variety endtasks exampledata subset selection efficient andor costeffective training machine learning models needselect samples informative training model training smaller subsets dataentails significant speedups reduction labeling timecost sacrificing accuracy killamsetty et al2021 kaushal et al 2019 wei et al 2015 flavor targeted data subset selection focusesimproving existing model performing poorly specific cases improving dataset imbalancedcertain attributes endtasks want able select subsets align certaintarget settargeted data subset selectionrealworld settings training data biased examples biases include distribution shift imbalanceclasses presence rare classes rare slices distribution examples unlabeled datasetcases models performance improved given additional labeling cost augmenting training datainformative samples matching target distribution called targeted subset large poolunlabeled data way achieving assuming access clean validation set matching target setdistribution target example target set critical slice data indoorimages people dark images specific classes user care want improvemodels performance target sacrificing overall accuracy minimum additional labeling costsdepartment science university texas dallasdepartment science engineering indian institute technology bombaydepartment electrical engineering university washington seattlepreprint m ay 4 2021fig 1 case user aware certain rare slice class datasetexample images labeled set heldout test set rare slice paperstudy problem targeted subset selection sample unlabeled data pointspreliminariessubmodular functions let v denote groundset n data points v 1 2 3 n set functionf 2vfunction f submodular fujishige2005 satisfies diminishing marginal returnsf jx f jy x y v jfacility location set cover log determinantsexamples iyer 2015 close connectionssubmodularity entropy submodular functions viewed information functions zhangyeung 1998 submodularity ensures greedyalgorithm achieves bounded approximation factormaximized nemhauser et al 1978labelled training dataaugment taugmentedtraining datatargetsretrain modeltargeteddata subsetselectiontargeted subset tsubmodular mutual information mi given setitems b v submodular mutual informationmi gupta levin 2020 iyer et al 2020 definedb f f b f b intuitivelymeasures similarity b referb query setunlabelled datasetfigure 1 motivating example targeted data subset selection tss night images target underrepresentedtraining data tss mines night images augmentstraining data improve performance finalmodelkaushal et al 2020 extend mi handle case target come auxiliary set v 0 differentground set v targeted data subset selection v source set data instances target subset datapoints validation set specific set examples let v v 0 define set function f 2f defined discrete optimization problem defined subsets voptimal subset given query set q v 0 define gq q v maximizeexamples smi functionsuse mi functions recently introduced iyer et al 2020 gupta levin 2020 extensions introducedkaushal et al 2020 data points v j q let sij denote similaritygraph cut mipthe psubmodular mutual information smi instantiation graphcut gcmi definedigc q 2 ia jq sij maximizing gcmi maximizes joint pairwise sum query setlead summary similar query set q fact specific instantiations gcmi intuitivelyqueryfocused summarization videos vasudevan et al 2017 documents lin 2012 li et al 2012facility location mip v1 variant fl set d v smi instantiation fl1mi definedl1 q iv minmaxja sij maxjq sij term min fl1mi models diversitysecond term models query relevance increase value causes resulting summaryrelevant queryfacility location mip v2 v2 variantp set d v q smi instantiation fl2mi definedl2 q iq maxja sij ia maxjq sij fl2mi intuitive query relevancemeasures representation data points relevant query set vice versathought bidirectional representation scorelog determinant mi smi instantiation logdetmi defined ilogdet q log detsa1 tlog detsa 2 saq sqsaq saq denotes crosssimilarity matrix items sets qsimilarity matrix constructed way crosssimilarity q multiplied controltradeoff queryrelevance diversityframework targeted data subset selectionapply smi functions setting targeted data subset selection improving models accuracytarget classesinstances given additional labeling cost k instances compromising overall accuracylet e initial training set labeled instances t set examples user cares desirespreprint m ay 4 2021better performance let u large unlabeled dataset appropriate feature representation instancescompute kernels similarities elements u t u t instantiate mi functiont maximize compute optimal subset u size k given t target query setaugment e labeled l retrain model achieve desired improvement instantiatingrich class mi functions including gcmi fl1mi fl2mi com logdetmi tss offers rich treatmenttargeted subset selection framework allows adding explicit diversity term ga weightg set function modeling diversity total pairwise distance helpful casesmodel diversity gcmi algorithm summarized algorithm 1 following ash et al 2020 killamsettyet al 2021 use gradients feature representation compute similarity kernels gradients computedmodels inference u t similarity computed cosine similarityalgorithm 1 tssrequire initial labeled set examples e large unlabeled dataset u target subsetslice wantimprove accuracy t loss function l learning1 train model loss l labeled set e obtain parameters e2 compute gradients e lxi yi u e lxi yi t3 gradients compute similarity kernels define submodular function f diversity function g4 maxau ak t ga5 obtain labels elements l6 train model combined labeled set e leffectiveness smi tssdataset baselines implementation details demonstrate effectiveness tss obtaining targetedsubset improving image classification accuracy target classes cifar10 mnist datasetssimulate realworld setting split available train set train validate data lake train setlabeled instances poorly represents randomly picked classes target ii data lake large setlabels use resembling large pool unlabeled data realworld poorly represented classesperform validation set hold clue picking target performance measuredtest set respective datasets apply tss algorithm 1 comparing mi functions existingapproaches specifically mi functions use logdetmi gcmi fl1mi fl2mi gcmi diversity equivalentintuitive approach minimizing average gradient difference target existing approaches compareactive learning baselines uncertainty sampling badge g lister active glister runningsetting select unlabeled subset active learning baselinesexplicitly information target set strengthen compare variantstargetaware targeted uncertainty sampling tus product uncertaintysimilarity target identify subset second g lister tss target setbilevel optimization finally compare pure diversityrepresentation functions facility location flgraph cut gc log determinant logdet disparitysum dsum random sampling train modelresnet18 et al 2016 cifar10 lenet lecun et al 1989 mnist crossentropy loss sgdoptimizer training accuracy exceeds 99 base model augmenting train set labeled versionselected subset retraining model report average gain accuracy target classes overallgain accuracy classes test set averaged 10 runs randomly picking classes targetrun tss different budgets study effect budget performance applicableinternal parameters default values 1results table 1 report results budget 400 cifar10 70 mnist settingrealistic possible set target set smaller budget 10 budget 10cifar10 6 mnist report effect budget gain accuracy target classes fig 2datasets mi functions yield best improvement accuracy target classes 2030 gainmodels performance retraining added targeted subset 12 methodssimultaneously increasing overall accuracy 26 consistently outperform badge g lister tsstus budgets smi functions logdetmi fl2mi gcmidiv model queryrelevancediversity perform better functions tend prefer relevance gcmi tus b functionstend prefer diversityrepresentation badge fl gc dsum logdet observe differentbudgets mi functions outperform methods greater margins target class accuracy fig 2expected methods effective considering targetpreprint m ay 4 2021figure 2 comparison different methods targeted subset selection different budgets cifar10 mnistxaxis budgets yaxis gain model accuracy target classes test set mi based approaches lines redsignificantly outperform subset sizes section 4methodcifar10mnisttargetoverall targetoverallbase1124225276868random2751431080032badge ash et al 2020724523867 1659glister killamsetty et al 20211212271456227glistertss165178 22895405settles 2009395203756 1182tus1045299621 1611logdet11851329189153263 15025241159179 10935116dsum106519 20515392logdetmi265221 28035526fl2mi2023436514fl1mi1712282121383gcmi176148 29375521gcmidiv1823743128421table 1 comparison tss mi functions methods budget 400 cifar10 70 mnistnumbers gain accuracy target classes target classes overall base modelretraining model text highest blue 2nd 3rd highest red green respectivelyconclusiondemonstrate effectiveness smi functions improving models performance augmenting trainingdata samples match target distribution targeted data subset selection experiments cifar10mnist datasets empirically verify superiority smi functions existing methodsreferencesjordan t ash chicheng zhang akshay krishnamurthy john langford alekh agarwal deep batch active learningdiverse uncertain gradient lower bounds iclr 2020preprint m ay 4 2021satoru fujishige submodular functions optimization elsevier 2005anupam gupta roie levin online submodular cover problem acmsiam symposium discretealgorithms 2020kaiming xiangyu zhang shaoqing ren jian sun deep residual learning image recognition proceedingsieee conference vision pattern recognition pages 770778 2016rishabh iyer ninad khargoankar jeff bilmes himanshu asnani submodular combinatorial information measuresapplications machine learning arxiv preprint arxiv200615412 2020rishabh krishnan iyer submodular optimization machine learning theoretical results unifying scalablealgorithms applications phd thesis 2015vishal kaushal rishabh iyer suraj kothawade rohan mahadev khoshrav doctor ganesh ramakrishnanlearning data unified data subset selection active learning framework vision 2019ieee winter conference applications vision wacv pages 12891299 ieee 2019vishal kaushal suraj kothawade ganesh ramakrishnan jeff bilmes himanshu asnani rishabh iyer unifiedframework generic queryfocused privacy preserving update summarization submodular informationmeasures arxiv preprint arxiv201005631 2020krishnateja killamsetty durga sivasubramanian ganesh ramakrishnan rishabh iyer glister generalizationbased data subset selection efficient robust learning aaai 2021yann lecun bernhard boser john s denker donnie henderson richard e howard wayne hubbard lawrence djackel backpropagation applied handwritten zip code recognition neural computation 14541551 1989jingxuan li lei li tao li multidocument summarization submodularity applied intelligence 373420430 2012hui lin submodularity natural language processing algorithms applications phd thesis 2012george l nemhauser laurence wolsey marshall l fisher analysis approximations maximizingsubmodular set functionsi mathematical programming 141265294 1978burr settles active learning literature survey technical report university wisconsinmadison departmentsciences 2009arun balajee vasudevan michael gygli anna volokitin luc van gool queryadaptive video summarizationqualityaware relevance estimation proceedings 25th acm international conference multimedia pages582590 2017kai wei rishabh iyer jeff bilmes submodularity data subset selection active learning internationalconference machine learning pages 19541963 pmlr 2015zhen zhang raymond w yeung characterization entropy function information inequalities informationtheory ieee transactions 44414401452 1998