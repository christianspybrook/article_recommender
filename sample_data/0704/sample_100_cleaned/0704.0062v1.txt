online viterbi algorithm relationship random walksrastislav rmek1 broa brejov2 tom vina2arxiv07040062v1 csds 31 mar 2007department science comenius university842 48 bratislava slovakia email rastokspskdepartment biological statistics computational biology cornell universityithaca ny 14853 usa email bb248tv35cornelleduabstract paper introduce online viterbi algorithm decoding hidden markovmodels hmms smaller linear space analysis twostate hmms suggestsexpected maximum memory decode sequence length n mstate hmm lowm log n significant slowdown compared classical viterbi algorithm classicalviterbi algorithm requires omn space impractical analysis long dna sequencescomplete human genome chromosomes continuous data streams experimentallydemonstrate performance online viterbi algorithm simple hmm gene findingsimulated real dna sequenceskeywords hidden markov models online algorithms viterbi algorithm gene findingintroductionhidden markov models hmms generative probabilistic models succesfulyannotation sequence data dna protein sequences natural langauge textssequences observations measurements numerous applications include gene finding1 protein secondary structure prediction 2 speech recognition 3 lineartime viterbialgorithm 4 commonly algorithm tasks unfortunately space requiredviterbi algorithm grows linearly length sequence high constant factormakes unsuitable analysis continuous long sequences example dnasequence single chromosome hundreds megabases long paper addressproblem proposing online viterbi algorithm average requires memoryannotate continuous streams data online reading complete input sequencehmm composed states transitions probabilistic model generates sequencesgiven alphabet step generative process current state generates symbolsequence according emission probabilities associated state outgoingtransition randomly chosen according transition probability table transitionfollowed new state process repeated sequence generatedstates hmm represent distinct features observed sequences proteincoding noncoding sequences genome emission probabilities state representstatistical properties features hmm defines joint probability prx spossible sequences x state paths s hmm generate sequencesannotate given sequence x want recover state path s maximizes jointprobability example hmm state proteincoding sequences statenoncoding sequences probable state path marks symbol input sequencex protein coding noncodingcompute probable state path use viterbi dynamic programming algorithm4 prefix x1 xi given sequence x state j computeprobable state path generating prefix ending state j store probability pathtable p j second state table bi j values computed leftright recurrence p j maxk p 1 k tk j ej xi tk j transitionprobability state k state j ej xi emission probability ith symbolx state j pointer bi j value k maximizes p j computingvalues recover probable state path s s1 sn setting statesn arg maxk p n k following pointers bi j right leftsi bi 1 si1 hmm m states sequence x length n running timeviterbi algorithm nm2 space nmalgorithm suited sequences models moderate size annotate250 million symbols human chromosome 1 gene finding hmm consistingstates require 25 gb memory store pointers bi j clearlyimpractical computational platformssolutions practice overcome problem example practicalgene finding programs process sequences limited size long input sequence splitshorter sequences processed separately results mergedconflicts resolved heuristically approach leads suboptimal solutions especiallygenes looking cross boundaries splitgrice et al 5 proposed practical checkpointing algorithm trades running time spacedivide input sequence k blocks l symbols forward passcolumn block obtain probable state path recomputeblock l columns use pointers recover l states probable pathstate previous block information staterecompute probable state path previous block way processrepeated blocks value p j computed twice means twofoldslowdown compared viterbi algorithm set k l n algorithmrequires nm memory checkpointing generalized trade lfold slowdownmemory l nm 6 7paper propose analyze online viterbi algorithm use fixedmemory given sequence instead memory varies dependingproperties hmm input sequence worst case algorithm requiresnm memory practice requirements lower prove demonstratinganalogy random walks results theory extreme values simple casesexpected space sequence length n low m log n experimentallydemonstrate memory requirements low complex hmmsonline viterbi algorithmalgorithm represent pointer matrix b viterbi algorithm tree structure4 node j sequence position state j parent node jnode 1 bi j data structure probable state path path leafnode n j highest probability p n j root tree figure 1tree built viterbi algorithm progresses left right processing sequenceposition edges lie paths ending level node removedstatessequence positionsfig 1 example pointer tree structure dashed lines mark edgesprobable state path square node marks coalescence point remaining pathsedges probable path 8 remaining m paths representpossible initial segments probable state path paths necessarily edgedisjoint fact paths share prefix node called coalescence pointfigure 1left coalescence point single candidate initial segmentprobable state path output segment remove edges nodestree coalescence point forney 4 describes algorithm processing d symbolsinput sequence checks coalescence point reached case initialsegment probable state path outputted coalescence point reachedpotential initial segment chosen heuristicaly studies 9 10 suggest choose dlimit expected error caused heuristic steps context convolution codesdetect existence coalescence point dynamically introducingsignificant overhead computation maintain compressed versionpointer tree omit internal nodes children path consistingnodes contracted single edge compressed tree m leavesm 1 internal nodes node stores number children pointer parent nodelinked list nodes compressed tree ordered sequence positionfinally list pointers leavesprocessing kth sequence position viterbi algorithm update compressedtree follows create new leaf node position link parentleaves insert linked list new leaves created removeleaves children recursively ancestorschildrenfinally need compress new tree examine nodes linked list orderdecreasing sequence position node zero child current leafsimply delete leaf node children follow parent linksancestor children link current nodedirectly ancestor node l j ancestor childrencoalescence point new root output probable state pathsequence positions l remove results computation positionsmemoryrunning time update om sequence position representationcompressed tree takes om space asymptotic running time viterbi algorithmincreased maintanance compressed tree implementedstandard viterbi algorithm new online extension time measurements suggestoverhead required compressed tree updates 5worstcase space required algorithm onm rarely caserealistic data required space changes dynamically depending input sectionsimple hmms expected maximum space required processing sequencelength n m log n better checkpointing requires space m nsignificant increase running time conjecture trend extends complexcases present experimental results gene finding hmm real dna sequences showingonline viterbi algorithm leads significant savings memoryadvantage algorithm construct initial segments probablestate path input sequence read feature makes ideal online processingsignal streams sensor readingsmemory requirements online viterbi algorithmsection analyze memory requirements online viterbi algorithm memoryalgorithm variable execution algorithm specialasymptotic bounds expected maximum memory algorithmdecoding sequence length nuse analogy random walks results extreme value theory argue symmetric twostate hmms expected maximum memory m log n conduct experimentshmm gene finding real simulated dna sequencessymmetric twostate hmmsconsider twostate hmm binary alphabet shown figure 2a simplicity assumet 12 e 12 pointers sequence positions 1 formconfigurations iiii shown figure 2b denote pa log p pb log p bp j table probabilities viterbi algorithm recurrence viterbialgorithm implies configuration occurs log tlog1t pa pb log1tlog tconfiguration ii occurs pa pb log1tlog t configuration iii occurs pa pblog t log1 t configuration iv happens t 12note twostate hmm coalescence point occurs configurationsii iii occur memory hmm proportional length continuoussequence configurations sequence configurations runanalyze length distribution runs assumption input sequencex sequence uniform iid binary random variables case represent runpa pbsymmetric random walk corresponding random variable x log1eloge log t log1 tlog1tlogtvariable interval 0 k k 2 log1elogeconfigurationoccurs quantity pa pb updated log1elog e symbol correspondingsequence position 0 log e log1 e symbol 1 shifts correspond updatingvalue x 1 1x reaches 0 coalescence point configuration iii pa pb initializedlog t log1 t log e log 1 e means initialization x 1configurationconfiguration iiconfiguration iiiconfiguration iv0 e1 1e0 1e1 efig 2 symmetric twostate hmm parameters e emission probabilities t transitionsprobabilities b possible backpointer configurations twostate hmmcoalescence point depending symbol corresponding sequence position casex reaches k coalescence point configuration ii symmetricapply classical results theory random walks 11 ch143145analyze expected length runslemma 1 assuming input sequence uniformly iid expected length runsymmetrical twostate hmm k 1larger k memory required decode hmm worst caseachieved e approaches 12 case states indistinguishable stateequivalent state b theory random walks characterizedistribution length runslemma 2 let rl event length run symmetrical twostate hmm2l 1 2l 2 assuming input sequence uniformly iid constantsb c 0b cos2lprrl c cos2lproof symmetric random walk interval 0 k absorbing barriers startingpoint z probability event wzn random walk ends point 0 n steps zeron z odd following quantity n z 11 ch145prwzncosn10vk2sinsinsymmetry note probability random walk ending n steps barrierk probability wkzn k odd stateprrl prw12l1 prwk12l1cos2lsin1v1 sinsink 0vk20vk2cos2lv oddsin2k4 terms sum bounded cos2l vupper lower bounds prrl term sumfollowssin2cos2lprrl cos2lsimilarly k stateprrl prw12l1 prwk12l2sin2cos2l1 1v1 cosk 0vk2similar boundsin21 coscos2lprrl 2 cos2lprevious lemma characterizes length distribution single run analyzememory requirements sequence length n need consider maximum runstotal length n similar problem studied runs heads sequence n cointosses 12 13 coin tosses length distribution runs geometric caseruns bounded geometricaly decaying functions prove expectedlength longest run grows logarithmically length sequence casecoin tosseslemma 3 let x1 x2 sequence iid random variables drawn geometricallydecaying distribution positive integers exist constants b c 0 1 0 b cintegers k 1 bak prxi k caklet nn largest index i1nn xi n let yn maxx1 x2 xnn np nni1 xieyn log1a n olog nproof let zn maxi1n xn maximum n runs clearly przn k prxikn 1 cak n przn k 1 bak n integers k log1a clower bound let tn log1a n ln n yn tn need ntn runs reach sum nnn ntn 1 discounting incomplete runtn atn n 1pryn tn prz tn 1 tn 1 batn tn 1 1 batnlimn atn ntn 1 limx0 1 bx1x eb limn pryn tn 0note eyn tn 1 pryn tn desired boundupper bound clearly yn zn eyn ezn let zn maximum n iid geometricrandom variables x1 xn prxi k 1 akcompare ezn expected value variable zn loss generality c 1real x log1a c 1przn x 1 cax n1 axlog1a c1 axlog1a c1przn x log1a c 1przn log1a c 1 xinequality holds x log1a c 1 righthand zero caseezn ezn log1a c1 ezn o1 expected value zn log1a nolog n14 proves claimresults lemma 3 characterization run length distributionslemma 2 conclude symmetric twostate hmms expected maximum memoryrequired process uniform iid input sequence length n 1 ln1 coskln nolog n3 taylor expansion constant term k grows infinity 1 ln1 cosk2k 2 2 o1 obtain maximum memory grows approximately 2k 2 2 ln nasymptotic bound log n easily extended sequences generatedsymmetric hmm instead uniform iid underlying process described randomwalk approximately 2k states 0 k lines line corresponding sequence symbolsgenerated states distribution run lengths decays geometricallyrequired lemma 3 base exponent largest eigenvalue transition matrixabsorbing states omitted 15 claim 2situation complicated case nonsymmetric twostate hmmsrandom walks proceed steps arbitrary real numbers different directionaware results help directly analyze distributions runs modelsconjecture size longest run log n obtain boundslength distribution runs approximate behaviour nondiscrete randomwalks different model example 16 ch7multistate hmmsanalysis technique easily extended hmms states twostate hmmsnew coalescence event clears memory execution algorithmdivided independent runs coalescent event multistate hmm resultsnontrivial tree left memory substantial depth sizes consecutiveruns longer independent figure 3aomitted run different starting point follow distribution outlinedlemma 2 expected length run depend n contributes lowerorderterm omitted runs length start outside interval 0 k runs contributelower order terms lower bound40kaverage maximum memory100kactual memory30k20k10k152m80khuman genome 35hmm generated 100random iid 3560k40k20k153m154m155msection chromosome 110m15m20msequence lengthfig 3 memory requirements gene finding hmm actual length table segment humanchromosome 1 b average maximum table length needed prefixes 20 mb sequencesevaluate memory requirements algorithm multistate hmms implemented algorithm performed experiments simulated biological sequences generalized symmetric hmms previous section multiple statessymmetric hmm m states emits symbols mletter alphabet stateemits symbol higher probability symbols transition probabilitiesequiprobable selftransitions tested algorithm m 6 sequencesgenerated uniform iid process hmm observed data consistentlogarithmic growth average maximum memory needed decode sequence lengthn data shownevaluated algorithm simplified hmm gene finding 265 statesemission probabilities states defined 4th order markov chainsstructure hmm reflects known properties genes similar structure shown17 hmm trained refseq annotations human chromosomes 1 22gene finding segment input dna sequence exons proteincoding sequence intervals introns noncoding sequence separating exons gene intergenic regions sequence separating genes common measure accuracy exon sensitivity real exonssuccesfuly exactly predicted implementation exon sensitivity 37testing set genes guigo et al 18 realistic gene finder exonhunter 19 traineddata set achieves sensitivity 53 difference additional featuresimplemented test gc content levels nongeometric length distributionssophisticated signal modelstested algorithm 20 mb long sequences regions human genomesimulated sequences generated hmm iid sequences regions human genomechosen hg18 assembly contain sequencing gaps distributioniid sequences mirrors distribution bases human chromosome 1results shown figure 3b average maximum length tablesamples appears grow faster logarithmically length sequencebounded polylogarithmic function clear faster growthartifact disapear longer sequences higher number sampleshmm gene finding special structure copies state intronsemission probabilities selftransition probability twostatesymmetric hmms similar emission probabilities states lead increase lengthindividual runs intron states gene finder extreme example phenomenonnonetheless average table length roughly 100000 sufficient process sequenceslength 20 mb 200fold improvement compared trivial viterbi algorithmaddition length table exceed 222000 20mb human segmentsfigure 3a time program keeps relatively short table averagelength human segments 11000 low average length significant advantagemultiple processes share memoryconclusionpaper introduced online viterbi algorithm algorithm based efficient detection coalescence points trees representing statepaths consideration dynamicprogramming algorithm algorithm requires variable space depends hmmlocal properties analyzed sequence twostate symmetric hmms shownexpected maximum memory analysis sequence length n approximately2k 2 2 ln n experiments simulated real data suggest asymptoticbound m ln n extend multistate hmms fact timeexecution algorithm memoryadvantage algorithm online processing streamedsequences previous algorithms guaranteed produce optimal state path requiresequence read output startedopen problems able analyze algorithm twostate hmms trends predicted analysis generalize complex casesanalysis extended multistate hmms apparently design hmm affectsmemory needed decoding algorithm example presence states similar emissionprobabilities tends increase memory requirements possible characterize hmmsrequire large amounts memory decode characterize states likely servecoalescence pointsacknowledgments authors like thank richard durrett useful discussions recentlyparallel work problem performed research group 20focus work implementation algorithm similar online viterbi algorithmgene finder possible applications parallelization focus expectedspace analysisreferences1 burge c karlin s prediction complete gene structures human genomic dna journal molecularbiology 2681 1997 78942 krogh larsson b von heijne g sonnhammer el predicting transmembrane protein topologyhidden markov model application complete genomes journal molecular biology 3053 2001 5675703 rabiner lr tutorial hidden markov models selected applications speech recognition proceedingsieee 772 1989 2572864 forney jr gd viterbi algorithm proceedings ieee 613 1973 2682785 grice ja hughey r speck d reduced space sequence alignment applications biosciences131 1997 45536 tarnas c hughey r reduced space hidden markov model training bioinformatics 145 1998 4014067 wheeler r hughey r optimizing reducedspace sequence analysis bioinformatics 1612 2000 108210908 henderson j salzberg s fasman kh finding genes dna hidden markov model journalcomputational biology 42 1997 1271319 hemmati f costello d j truncation error probability viterbi decoding ieee transactions communications 255 1977 53053210 onyszchuk truncation length viterbi decoding ieee transactions communications 397 19911023102611 feller w introduction probability theory applications edition volume 1 wiley 196812 guibas lj odlyzko long repetitive patterns random sequences probability theory relatedfields 53 1980 24126213 gordon l schilling mf waterman ms extreme value theory long head runs probability theoryrelated fields 72 1986 27928714 schuster ef overwhelming numerical evidence settling kinneys waitingtime conjecture siamjournal scientific statistical computing 64 1985 97798215 buhler j keich u sun y designing seeds similarity search genomic dna journalsciences 703 2005 34236316 durrett r probability theory examples duxbury press 199617 brejova b brown dg vinar t advances hidden markov models sequence annotation mandoiuzelikovski eds bioinformatics algorithms techniques applications wiley 2007 appear18 guigo r et al egasp human encode genome annotation assessment project genome biology7s1 2006 13119 brejova b brown dg li m vinar t exonhunter comprehensive approach gene finding bioinformatics 21s1 2005 i576520 keibler e brent m personal communication 2006