evaluating groundedness in dialogue systems the begin benchmark
nouha dziri  hannah rashkin tal linzen  david reitter



university of alberta
google research
new york university
hrashkinreittergooglecom
dziricsualbertaca
linzennyuedu

arxiv210500071v1 cscl 30 apr 2021

abstract
knowledgegrounded dialogue agents are systems
designed to conduct a conversation based on externally provided background information such
as a wikipedia page such dialogue agents especially those based on neural network language
models often produce responses that sound fluent
but are not justified by the background information progress towards addressing this problem
requires developing automatic evaluation metrics
that can quantify the extent to which responses
are grounded in background information to facilitate evaluation of such metrics we introduce
the benchmark for evaluation of grounded interaction begin begin consists of 8113 dialogue turns generated by languagemodelbased
dialogue systems accompanied by humans annotations specifying the relationship between the systems response and the background information
these annotations are based on an extension of
the natural language inference paradigm we use
the benchmark to demonstrate the effectiveness of
adversarially generated data for improving an evaluation metric based on existing natural language
inference datasets

1

introduction

neural network language models vaswani et al
2017 radford et al 2019 have been increasingly
adopted as a central part of opendomain dialogue
systems wolf et al 2019 zhang et al 2020
roller et al 2020 adiwardana et al 2020 utterances sampled from such language models sound
natural as reflected in these systems high scores
in human evaluations focused on measures such
as engagingness or humanlikeness while
fluent however the responses generated by these
systems are often only locally coherent or contain
confabulated statements see the red portions of the
response in figure 1 for illustration



equal contribution
work done while at google research

figure 1 an example of a hallucinated response
generated by the gpt2 language model finetuned
on the wizard of wikipedia dataset dinan et al
2019 the response was conditioned on a passage
of text from wikipedia and the previous utterance
the response in yellow is on topic and appears to
be plausible but the information it contains is not
supported by the document
in this work we introduce a new classification task and benchmark for evaluating knowledgegrounded dialogue systems systems that are expected to conduct a conversation based on a particular source of information with the goal of making
unstructured information more accessible to a user
it is critical for such a system to avoid producing
utterances that appear to convey information but
in reality are not supported by the document or
even contradict it the system should also avoid
responses that fail to respond to the users question
because they are accurate but offtopic eg the
university of michigan is located in ann arbor
or because they are excessively general eg i
dont know much about nyc in figure 1
existing automatic evaluation metrics for dialog
such as bleu papineni et al 2002 rouge
lin 2004 and maude sinha et al 2020 are
illsuited to detecting these issues and correlate
poorly with human judgments liu et al 2016
dziri et al 2019b sai et al 2019 to facilitate progress towards reliable evaluation metrics
for grounded dialog we propose a new classifi

cation task extending the natural language inference nli paradigm dagan et al 2005 bowman
et al 2015 williams et al 2018 nli seeks to
determine given a premise p and a hypothesis h
whether p entails h contradicts it or is neutral
with respect to it for our taxonomy we adopt
the entailment and contradiction labels from the
nli paradigm but split the neutral label into three
subcategories hallucination responses which are
topical but include unverifiable information offtopic responses and generic responses which are
too vague to be verified as a testbed for evaluation metrics based on this taxonomy we create the
benchmark for evaluation of grounded interaction begin a dataset of 8113 dialogue responses
generated by language models finetuned on the
wizard of wikipedia dataset dinan et al 2019
and ask annotators to categorize these responses
using the proposed taxonomy
we establish baseline performance on this benchmark using two pretrained transformer models
bert devlin et al 2019 and t5 raffel et al
2020 we finetune them on two existing nli
datasets mnli williams et al 2018 and dnli
welleck et al 2019 as these nli datasets only
support the coarsegrained distinction between entailment contradiction and neutral we additionally
use perturbation techniques to generate examples
for each of the five categories of our taxonomy and
finetune the pretrained models on this extended
dataset we find that there is considerable room
for improvement between the best model we train
slightly above 70 and human performance estimated from interannotator agreement on the benchmark around 90 agreement with majority suggesting that there are opportunities for developing
stronger metrics for grounded dialog evaluation
the main contributions of this work are
a we propose a taxonomy of responses generated by a knowledgegrounded conversation
system this taxonomy extends the natural
language inference framework
b we present a new benchmark begin consisting of knowledgegrounded dialogue system responses annotated according to this taxonomy
c we establish baseline performance on begin
using bert and t5 finetuned on standard
nli datasets and improve upon it using our
own adversariallycreated dataset

2

constructing the begin dataset

to generate dialogue responses for the begin
dataset we finetuned two dialogue agents on
an existing knowledgegrounded dialogue dataset
based on error patterns commonly produced by
these dialogue agents we created a taxonomy of
grounded dialog responses we then constructed
begin by asking human annotators to categorize
a sample of dialogue system responses according
to this taxonomy
21

training knowledgegrounded agents

dataset we finetune our knowledgegrounded
dialogue models on the wizard of wikipedia
dataset wow dinan et al 2019 wow consists of
crowdsourced english dialogues between a wizard and an apprentice where the goal of the
wizard is to convey to the apprentice information
about a particular topic the apprentice in turn
is expected to seek information about the topic at
each turn of the conversation the wizard is presented with passages from wikipedia and chooses
an evidence span typically a sentence to use as
supporting evidence in their response not all utterances in wow are grounded in external evidence
unlike the wizard the apprentice is not presented
with wikipedia sentences when produce an utterance and the wizard is allowed to produce an
utterance that does not use the evidence
task formulation we trained our models to generate the wizards response based on a concatenation of two inputs an evidence span the wikipedia
sentence presented to the wizard and the previous
dialogue turn produced by the apprentice we
omitted evidence span previous turn response
triples in which the wizard did not explicitly select
a passage as evidence for the response we used
82722 triples for training 8800 triples for development and 8690 triples for test
models we finetuned the base gpt2 model
radford et al 2019 and the base version of t5
raffel et al 2020 on the wow dataset we filtered out responses that the google perspective
api deemed to have a greater than 50 likelihood
of containing toxic language
for gpt2 we framed response generation as
language modeling cf dialoggpt zhang et al
2020 we concatenated the evidence the previous
turn and the response and continued training gpt2 using crossentropy over the response tokens we

used the same hyperparameters as in wolf et al
2019 we refer to this model as gpt2w ow
for t5 which is an encoderdecoder model the
encoder was provided with the concatenation of
the evidence span and the previous turn and the
decoder was trained to predict each token in the
response given the previous tokens we used the
hyperparameters found using grid search on the dev
set we refer to this model as t5w ow neither
of these finetuned models is intended to advance
the state of the art in grounded dialogue generation
rather we used them to investigate the errors made
by typical neural dialogue systems
22

response taxonomy for grounded
dialogue systems

a manual inspection of 200 of the responses generated by gpt2w ow revealed that in addition
to responses that were entailed by the document as
desired there were five common error types this
section defines and illustrates each of the six response types using examples from the manually
inspected sample of responses

ive been to the hospital before or i think justin
trudeau won the elections in 2015 while such
responses may be acceptable in human dialogues
in the context of a knowledgegrounded dialogue
system we consider them to be hallucinations
generic these are neutral sentences that are general enough to fit into a large number of possible
contexts even if they are ostensibly about the same
topic as the document they are vague and do not
provide information true or not eg
evidence a ski is a narrow strip of semirigid
material worn underfoot to glide over snow
previous turn skiing is really a lot of fun nothing
like finding some fresh powder
response it seems you might like skiing in the
winter

offtopic in contrast to hallucinations which are
semantically close to the evidence but add small
amounts of unverifiable information offtopic responses are unrelated to the evidence eg

entailment entailed responses are those that are
faithfully supported by the evidence span

evidence toyota is the worlds market leader in
sales of hybrid electric vehicles and one of the
largest companies to encourage the mass  market
adoption of hybrid vehicles across the globe

evidence robert norman ross october 29
1942  july 4 1995 was an american painter
art instructor and television host

previous turn hi i have never had a toyota but i
know a lot of people like them

previous turn i would like to know more about
bob ross

response the era of manufactured fibers began
with the development of rayon in france in the
1890s

response yes absolutely he was an american
painter and television host

hallucination hallucinated responses are topical but state information that cannot be verified
using the source document eg
evidence the tucson metro area is served by
many local television stations and is the 68th
largest designated market area dma in the us
with 433310 homes 039 of the total us
previous turn have you ever heard about the
tuscon metro area
response yes one of the most visited us cities
is the tucson metro which was largely influenced
by the television culture

we also include in the hallucination category
responses that convey personal or subjective opinions experiences feelings and so on as such statements cannot be verified using the given evidence
some examples are i love to take walks in the park

contradiction these are informative sentences
that directly contradict the evidence eg
evidence although most law schools only offer
the traditional three  year program several us
law schools offer an accelerated jd program
previous turn because i did not want to go
through all the schooling do you know how long
law school is
response most law schools only offer a 10 year
program 

uncooperative responses human dialogues are
characterized by cooperative responses that follow
the conversational expectations set out by grices
maxims grice 1989 typical speakers do not intentionally mislead the listener change the topic or
act unhelpfully in any other way dialogue system
responses may be inappropriate if they are not cooperative in this sense even when they are entailed
by the evidence document for example

evidence starbucks was founded in seattle
washington in 1971
previous turn i love eating at starbucks have
you been there
response the original location of starbucks is in
seattle which was founded in 1971

ultimately dialogue evaluation metrics should
take cooperativeness into account and as such we
asked our raters to score the cooperativeness of
dialogue responses for the time being however
we limit the scope of our experiments below to
evaluating faithfulness to the document and leave
modeling cooperativeness to future work
23

annotation procedure

rather than asking raters to explicitly classify responses based on the proposed taxonomy we broke
down the task into hierarchical questions with likert scales from 1 to 5 we summarize this procedure below and provide the exact questions in
appendix a responses often consist of multiple
sentences because each sentence may display different degrees of faithfulness we asked annotators
to rate each sentence in the response separately
first we asked annotators to judge whether the
response was about the same topic as the evidence
and if not whether it was best described as generic
or offtopic we additionally asked them if the
response was cooperative in the next stage we
asked the raters if the response was objective or
contained personal and subjective opinions if the
rater judged that the response was objective we
asked them if in their judgment the response was
intended to provide information about the evidence
in the document or anything else if the answer
to the last question was affirmative we presented
them with two followup questions first we asked
them if the response was fully supported by the
evidence and second we asked if any part of the
response contradicted the evidence
we collected annotations for 8113 dialogue responses which we split into a development 10
of the examples and test 90 of examples set
we release the data at httpsgithubcom
googlebegindataset examples were
randomly divided into dev and test set partitions
in such a way that examples using the same input
context would only appear in the same partition
we did not create a training set to discourage the
development of evaluation metrics that overfit to
the specific features of begin

in postprocessing we converted the numerical
ratings assigned by the annotators to one of our
category labels using the procedure described in
appendix b we note that the categories are not always mutually exclusive for example in a conversation about bees the response they have pretty big
personalities would be both offtopic and generic
the appropriate label may also depend on linguistic ambiguity that cannot be resolved from the context given to the annotators in one example the
response oppenheimer as he is known as i think
in neonatal med  ophthalmology was generated
about a document that says he was the director
of pediatric neurosurgery at johns hopkins hospital in maryland from 1984 until his retirement
in 2013 because the pronoun he in the document
doesnt resolve to an antecedent it is hard to determine whether this utterance is better described as
a hallucination attributing a medical specialty not
mentioned in the document or offtopic this document was probably not about oppenheimer at all
which is what the rater ultimately selected based
on the annotations 78 of the generic responses
and 71 of the offtopic responses in our development set may also contain hallucinated information
but we label these overlapping cases as generic or
offtopic respectively since these broader issues
often subsume the hallucination problems
we include examples from the development set
in table 1 along with the label breakdown we
note that the labels are unevenly distributed hallucinations and generic comments make up two of
the biggest categories of responses by contrast
contradictions make up a small fraction of the distribution this suggests that lmbased dialogue
agents like gpt2w ow and t5w ow are more
likely to add extra confabulated information rather
than directly contradict the evidence
to evaluate interannotator agreement we obtained two additional annotations from the same
pool of raters for approximately 15 of the responses the average krippendorfs alpha on the
responses to the different questions was around
041 this denotes relatively lowtomoderate
agreement one factor that may impact the scoring is slight disagreements between likert scores
such as the difference between a 4 and a 5 which
were counted as partial agreements scaled by the
distance between the responses further reducing
agreement are cases where a disagreement in an
earlier question propagated to the followup ques

category

frequency

example

contradiction

06

evidence
previous turn
response

broccoli is often boiled or steamed but may be eaten raw
it actually does vegetable of course like broccoli and spinach
broccoli can be eaten raw but not boiled

offtopic

61

evidence

a programming language is a formal language that specifies a set of
instructions that can be used to produce various kinds of output
is it programming
yes and i think that is why the united states still has the highest
population of any country

previous turn
response
generic

275

evidence
previous turn
response

hallucination

322

evidence
previous turn
response

entailment

336

evidence
previous turn
response

almost as soon as automobiles had been invented races of various sorts
were organised with the first recorded as early as 1867
thats so cool i guess thats just our competitive spirit
thats what makes it such a interesting history to behold
generally the heavier the ball the more pins that will topple on two
equivalent shots
yea but sadly bowling just isnt as demanding and difficult a sport as
football so its fallen off while football is as prominent as ever
when they first came out in the 70s they used to have at least ten percent
of the ball on two equivalent shots
elvis aaron presley january 8 1935  august 16 1977 was an
american singer musician and actor
i like to listen to elvis the king of rock and roll
elvis presley was born in 1935 and his death was august 16 1977

table 1 examples of each of the categories from the development set of begin and their frequency in
the development set all responses were generated from gpt2 finetuned on wizard of wikipedia based
on the evidence and the previous turn shown in the table labels were annotated by human raters
tions eg they answered differently to whether the
response was intended to be informative and so one
of them left blank the followup question on how
supported the information is but we counted agreement on each of these questions as if they were
independent of each other another factor that may
affect human performance is ambiguous cases or
instances where response categories are not always
mutually exclusive as mentioned above

3

classifying responses using existing
nli datasets

we establish baseline performance on begin using models based on bert devlin et al 2019
and t5 raffel et al 2020 we first finetune
the models on existing nli datasets since these
datasets are only labelled for the traditional threeway nli classification entailment contradiction
and neutral in these experiments we collapse the
three sublabels that correspond to neutral in our
finegrained classification in section 4 we train a
classifier for the full 5way categorization scheme
by creating adversarial data
the first dataset we use mnli williams et al
2018 is a collection of 433k premisehypothesis

pairs where three hypotheses one for each label were generated by crowdworkers based on a
premise drawn from a corpus the second is dnli
welleck et al 2019 which consists of 343k pairs
of dialogue utterances and persona attributes curated from the personachat dataset zhang et al
2018 eg a personadescribing attribute like i
have two cats may be contradicted by a conversation utterance saying i dont have any pets each
persona sentence and each utterance were associated with humanlabeled triples subject predicate
object a number of approaches were used to
form nli examples by linking dialogue utterances
and persona sentences for example each unique
pair of sentences that shared the same triple were
labeled as entailment and each pair of sentences
that were from contradictory triples were labeled
as contradiction

4

adversarially augmented training set

the experiments described in section 3 were based
on existing nli datasets which support a coarsegrained threeway classification but not the full
fiveway taxonomy we introduced in section 22
in this section we introduce a strategy to automat

evidence

previous turn

response

method

label

the islands geography
comprises relatively lowlying
mountains surrounding a central
plain with several navigable
rivers extending inland

yes is there many
mountains there

the geography is
mostly low lying
mountains which
surround a central plain
and many rivers
extending inland

none

entailment

a 2009 report found that the
skateboarding market is worth
an estimated 48 billion in
annual revenue with 1108
million active skateboarders in
the world

i have heard that
skateboarding is fun

the skateboarding
market is not estimated
to be 48 billion dollars

response
negation

contradiction

it is located on the cumberland
river in the north central part
of the state

i would really like to
visit that river someday

it is also in the south
peripheral part of the
state

antonym

contradiction

elvis aaron presley january
8 1935  august 16 1977 was
an american singer musician
and actor

elvis presley was ahead
of his time and really
brought in a new era of
music

i dont know much
about music

gpt2wow
with low
temperature

generic

the fia formula one world
championship has been one of
the premier forms of racing
around the world since its
inaugural season in 1950

what is the formula 1
championship called

he is right ive been to
one but they have tvs
set up the cars go fast
though because there is
minimum weight that
includes driver

random
utterance

offtopic

a examples generated without perturbing the evidence by perturbing the response by generating a new response
using gpt2wow or by selecting existing responses from the dataset
original evidence

perturbed evidence

gpt2wow response

method

label

the chihuahua is the
smallest breed of dog and is
named after the state of
chihuahua in mexico

the chihuahua is the
smallest breed of dog and is
named after the state of
maine in rochester

the chihuahua is
known to be very
friendly and maines
mayor love them

entity
swapping

hallucination

baking chocolate also
called bitter chocolate
contains cocoa solids and
cocoa butter in varying
proportions without any
added sugars

cocoa solids also called
bitter chocolate contains
baking chocolate and
cocoa butter in varying
proportions without any
added sugars

the consumption of
coco solids has many
benefits

subjectobject
inversion

hallucination

b examples generated by perturbing the evidence the response is a hallucination with respect to the original
evidence

table 2 examples from the automaticallygenerated adversarial data bold text highlights segments in the
source documents that are either supported contradicted or neutral by the response red text highlights
the justification for why the responses are annotated with a specific label

ically create silver training data for a classifier
that produces the full taxonomy we avoid training on begin because as we mentioned before
we see it as a testonly dataset recent work has
shown that neural networks can overfit to irrelevant
features of the dataset when trained on one part of
it and tested on another part we generated a balanced dataset of 7900 evidence dialogue history
response triples ie each label constituted 20 of
the data using the procedures described for each
target label in the remainder of this section see
table 2 for examples of our silver data

contradiction adversariallygenerated contradiction examples include two types of cases the
first is negated sentences created based on an english resource grammar erg parse flickinger
et al 2014 for example the skateboarding market is estimated to be around eight billion dollars
was replaced with the skateboarding market is not
estimated to be around eight billion dollars in
the second type of case adjectives are replaced
with their wordnet antonyms miller 1998 ancient greece was home to the first pentathlon is
replaced with ancient greece was home to the last
pentathlon that was documented

entailment we use the original human generated responses but to avoid opinions or subjective
experiences we subsample from the portion of examples where the response doesnt use first person
pronouns selected from a word list and at least
25 of the words in the response are in the evidence to avoid responses that are only tangentially
related to the evidence

unlike hallucination examples where we perturb the document and then feed it to gpt2wow
the contradiction examples are generated by directly perturbing the human response from the
wow dataset initial experiments indicated that
gpt2wow is not sensitive to these perturbations
when applied to the evidence in contrast with its
sensitivity to the more substantial perturbation we
used to generate hallucination examples this indicates that this dialogue systems responses are only
grounded in the document to a fairly limited extent

offtopic offtopic responses are sampled from
wow responses that are based on other pieces
of evidence to avoid having offtopic responses
that would be trivial to spot based on lexical cues
we sample from conversations that were about the
same topic as the target conversation
generic generic sentences are generated from
gpt2wow with a low softmax temperature 04
hallucination we perturb evidence spans from
the wow test set and then feed them to gpt2wow in general this results in responses that
could be considered hallucinations with respect
to the original evidence see table 2b we use
three perturbation methods each applied to a different evidence document all of these perturbations
substantially alter the truth of the sentence while
keeping it on topic first we swap the subject and
the object of the original evidence second we
replace up to two verbs in the sentences by verbs of
the same tense finally based on an error analysis
that showed that most hallucination errors made
by our dialogue system involved incorrect entities
we extract all mentioned entities from different
dialogue examples using the spacy ner tagger
honnibal and montani 2017 and replace up to
two randomly chosen entities in the original evidence document with entities of the same type eg
person location or organization

5

experimental setup

each classifier takes as input the contextthe
evidence and the previous conversation turn
concatenated with a separating delimiter and the
response for bert we train a threeway or fiveway classifier over the output cls token for
t5 we follow the mnli setup used in the paper
that introduced t5 raffel et al 2020 the string
premise  is concatenated with the context the
string hypothesis  is concatenated with the response and the concatenation of the two strings is
then passed as input to t5
in addition to separate experiments evaluating
models finetuned on mnli and models finetuned
on our adversarially augmented training data we
also investigated the performance of models trained
first on mnli and then on our adversarial data
all models were trained with a batch size of
32 over 3 epochs using the adam optimizer and
a learning rate of 2  105  we evaluated the
classifiers performance via accuracy and macroaveraged f1 ie computing f1 on each category
before averaging on begin

development set
3way

test set

5way

3way

5way

model

training data

acc

f1

acc

f1

acc

f1

acc

f1

bert

dnli
mnli
adversarial
mnliadvers

507
672
709
696

339
483
485
504

437
464

308
335

511
668
697
685

346
482
481
471

409
438

295
310

t5

dnli
mnli
adversarial
mnliadvers

512
691
693
710

338
503
505
526

452
455

324
335

519
685
683
693

360
491
491
495

422
432

306
314

table 3 accuracy and macrof1 scores on the development and test sets for the 3way and 5way
classification tasks

6

results

table 3 summarizes the results of our experiments
mnli is clearly a better fit to this task than dnli
finetuning on the adversarial data on its own is
fairly effective even though it is a significantly
smaller resource than dnli or mnli finally finetuning first on mnli and then on the adversarial
data produces higher accuracy than training on the
adversarial data alone
none of our models exceeds 71 accuracy in the
threeway classification setting or 465 accuracy
in fiveway classification by comparing individual
annotator ratings and the majorityvoted label in
the tripleannotated subset of begin we estimate
that human accuracy is about 90 for 3way classification and 75 for 5way classification while
humans do not agree perfectly there is still a lot of
room for improvement between these models and
human performance finally we note that accuracy
is similar across bert and t5 despite the fact that
t5 contains orders of magnitude more parameters
and was pretrained on a much larger corpus this
suggests that scaling up the pretrained model may
not be sufficient to make progress on this task using
the training datasets we have explored
61

error analysis

in table 4 we show some examples of errors made
by different bertbased models one possible
source of mistakes is misleading lexical cues in the
first example all three models label the response
as entailed which may be due to the high degree of
lexical overlap with the evidence however the semantic meaning of the information in the response
is a bit different from the evidence which is why
humans annotated it as a hallucination in the sec

ond example two of the bert models misidentify
the response as a contradiction which may be due
to the models relying too much on the negative
word didnt in the response
62

label confusion

figure 2 compares the predictions of three finetuned versions of bert to the gold labels all
three variants are poor at predicting contradiction
the model finetuned on mnli overpredicted contradictions while the model finetuned on the adversarial data has low recall for contradiction prediction the model trained on both resources performed better at predicting contradictions but still
misclassified most of them as hallucinations the
offtopic examples are also difficult for the models to classify while they are only rarely confused
with contradiction or entailment they were often
confused with the other neutral subcategories hallucination and generic
all three models displayed a substantial degree
of confusion between the hallucination and entailment labels but not as much between entailment
and generic or offtopic examples this difficulty
of distinguishing hallucinated and faithful information would be obscured in the 3way nli categorization scheme where hallucination is aggregated
with offtopic and generic in other words our 5way taxonomy makes it possible to identify this as
a particular set of neutral examples that is more
likely to be confused with entailment

7

related work

nli for dialogue system evaluation welleck
et al 2019 propose using nli to improve dialogue consistency they create the dialogue nli

evidence
previous turn
response
evidence
previous turn

response
evidence
previous turn
response
evidence
previous turn
response
evidence
previous turn
response

early skiers used one long pole or spear
thats amazing i sometimes wonder why its not as popular as football
basketball and the rest though its an amazing sport
they were the first to use a long pole or spear

g hallucination
m entailment
a entailment
ma entailment

historically archery has been used for hunting and combat
yes it does take skill i did not know what i was doing and ended up
burning or scratching the inside of my arm with the tail of the arrow im
not sure if its something you can develop with practice or not
you didnt do archery while hunting or doing combat 

g hallucination
m contradiction
a contradiction
ma hallucination

skiing can be a means of transport a recreational activity or a competitive
winter sport in which the participant uses skis to glide on snow
yea seems easy but it isnt
the easiest way to get in shape is to go down to the slopes of a volcano
and practice snowboarding

g offtopic
m neutral
a hallucination
ma hallucination

cheerleading is an activity wherein the participants referred to as cheerleaders cheer for their team as a form of encouragement
i did a little bit of cheerleading when i was younger how about you
no but i do have a lot of experience cheering for my team in the olympics

g hallucination
m neutral
a offtopic
ma offtopic

skiing can be a means of transport a recreational activity or a competitive
winter sport in which the participant uses skis to glide on snow
my brother is a professional skier
i have never tried skiing

g generic
m contradiction
a offtopic
ma offtopic

table 4 example outputs of bertbased models on the development set g gold label m bert
finetuned on mnli a bert finetuned on the adversarial data ma bert finetuned on mnli and
then on the adversarial data m was trained on the threeway classification task entailment neutral
contradiction while a and ma were trained on the full fiveway classification
bert mnli

bert advers

bert mnliadvers

figure 2 predictions vs gold label on the development set for bert finetuned on mnli left our
adversarially augmented data middle and mnli followed by the adversarial data right
dataset composed of premise hypothesis pairs
curated from the personachat dataset zhang et al
2018 and annotated with textual entailment labels
by humans they demonstrate the effectiveness of
models trained on dnli in reranking candidate
responses by penalizing responses that contradict
socalled persona sentences which express properties of the speaker i am a vegetarian dziri et al
2019a also used nli to evaluate dialogue consistency they generated a largescale noisy synthetic
dataset of premise hypothesis pairs tailored for
dialog also based on zhang et al 2018

hallucination in neural text generation the
hallucination issue affects a range of tasks that involve generating text from a neural language model
tian et al 2019 maynez et al 2020 across
tasks such models are typically trained to maximize the likelihood of the reference at test time
this leads the decoder to produce an output with a
high likelihood under the language model regardless of whether the output is faithful to the input
holtzman et al 2019 tian et al 2019 previous works attempting to quantify this issue have
focused on the task of summarization for exam

ple kryscinski et al 2020 proposed a synthetic
dataset for determining whether a summary is consistent with the source document similar to our
adversarial training with noisily supervised examples they train a classifier on a dataset constructed
by applying a number of syntactic transformations
to reference summaries besides the different target task dialogue in our case our work differs
from kryscinski et al 2020 in two ways first we
propose a finegrained categorization of responses
tailored for the dialogue task inspired by a similar
effort for abstractive summarization maynez et al
2020 and second we train an evaluation system
using an adversarial dataset where responses result from perturbing the grounding document and
feeding the result to a dialogue system an alternative approach for assessing faithfulness in abstractive summarization which also uses an auxiliary
language understanding task measures whether a
question answering system produces the same responses for the source and the summary durmus
et al 2020 wang et al 2020

annotators were additionally provided with instructions definitions and examples to help them
answer the questions

8

b

conclusion

in this paper we introduced a new taxonomy for
evaluating the faithfulness of knowledgegrounded
systems we presented the begin benchmark for
testing grounded dialog evaluation metrics consisting of around 8k responses generated by two
neural dialogue agents lastly to establish baseline performance on this task we finetuned bert
and t5 to classify a dialog response into one of the
five categories of our taxonomy using existing nli
datasets as well as adversarially created indomain
data while this baseline performed reasonably
well there is significant room for future work to
improve performance on our benchmark which
in turn will lead to stronger metrics for grounded
dialog evaluation

a

annotation protocol

we gave each rater a document evidence span
coming from wizard of wikipedia a conversation
history previous turn in a conversation coming
from a wizard of wikipedia test set example and a
generated response from either wowt5 or wowgpt2 raters were asked the following questions
all responses were on a 15 likert scale
1 is this utterance about the same topic as the
document

a if not score 13 then please identify it
as either generic offtopic both or neither
2 is this a relevant utterance  something that a
cooperative communicator whos not trying
to intentionally mislead change the topic or
be unhelpful in any other way would say
3 does this utterance describe any personal experiences or personal opinions
a if not containing personal experiences
then is part of the utterance intended
to convey information regardless of
whether its true or not
i if so does the information partially
or fully contradict the document
ii if so is all of the information supported by the document

cutoffs for determining labels

we derive labels from the annotators ratings using the following procedure if the rater judged
in question 1a that the response was generic or
offtopic we assign that label to the response otherwise if the rater judged that it contained personal
information score  3 in question 2 or that not
all of the information is supported by the document
score  3 in question 3aii we label the example
as a hallucination if they gave it a score of  3
on the contradiction question 3ai we label it as
contradiction finally if they said that all of the information is supported by the document score  4
in question 3aii we label it as entailment the
procedure ends as soon as a label is assigned such
that generic for example takes precedence over
hallucination

acknowledgements
we thank jennimaria palomaki dipanjan das tom
kwiatkowski and slav petrov for helpful feedback
we also thank ashwin kakarla and his team for
helping with the annotations

references
daniel adiwardana minhthang luong david r
so jamie hall noah fiedel romal thoppi

lan zi yang apoorv kulshreshtha gaurav
nemade yifeng lu et al 2020 towards
a humanlike opendomain chatbot arxiv
preprint arxiv200109977
samuel r bowman gabor angeli christopher
potts and christopher d manning 2015 a
large annotated corpus for learning natural language inference in proceedings of the 2015
conference on empirical methods in natural
language processing pages 632642 lisbon
portugal association for computational linguistics
ido dagan oren glickman and bernardo magnini
2005 the pascal recognising textual entailment challenge in machine learning challenges workshop pages 177190 springer
jacob devlin mingwei chang kenton lee and
kristina toutanova 2019 bert pretraining
of deep bidirectional transformers for language
understanding in proceedings of the 2019 conference of the north american chapter of the
association for computational linguistics human language technologies volume 1 long
and short papers pages 41714186 minneapolis minnesota association for computational
linguistics
emily dinan stephen roller kurt shuster angela fan michael auli and jason weston 2019
wizard of wikipedia knowledgepowered conversational agents in 7th international conference on learning representations iclr 2019
new orleans la usa may 69 2019 openreviewnet

pages 38063812 minneapolis minnesota association for computational linguistics
nouha dziri ehsan kamalloo kory mathewson
and osmar r zaiane 2019b augmenting neural
response generation with contextaware topical
attention in proceedings of the first workshop
on nlp for conversational ai pages 1831
dan flickinger emily m bender and stephan
oepen 2014 erg semantic documentation
accessed on 20200825
h paul grice 1989 studies in the way of words
harvard university press
ari holtzman jan buys li du maxwell forbes
and yejin choi 2019 the curious case of neural
text degeneration in international conference
on learning representations
matthew honnibal and ines montani 2017 spacy
2 natural language understanding with bloom
embeddings convolutional neural networks and
incremental parsing
wojciech kryscinski bryan mccann caiming
xiong and richard socher 2020 evaluating
the factual consistency of abstractive text summarization in proceedings of the 2020 conference on empirical methods in natural language
processing emnlp pages 93329346
chinyew lin 2004 rouge a package for automatic evaluation of summaries in text summarization branches out pages 7481 barcelona
spain association for computational linguistics

esin durmus he he and mona diab 2020
feqa a question answering evaluation framework for faithfulness assessment in abstractive
summarization in proceedings of the 58th annual meeting of the association for computational linguistics pages 50555070 online association for computational linguistics

chiawei liu ryan lowe iulian serban mike
noseworthy laurent charlin and joelle pineau
2016 how not to evaluate your dialogue system an empirical study of unsupervised evaluation metrics for dialogue response generation in
proceedings of the 2016 conference on empirical methods in natural language processing
pages 21222132 austin texas association
for computational linguistics

nouha dziri ehsan kamalloo kory mathewson
and osmar zaiane 2019a evaluating coherence
in dialogue systems using entailment in proceedings of the 2019 conference of the north
american chapter of the association for computational linguistics human language technologies volume 1 long and short papers

joshua maynez shashi narayan bernd bohnet
and ryan mcdonald 2020 on faithfulness and
factuality in abstractive summarization in proceedings of the 58th annual meeting of the association for computational linguistics pages
19061919 online association for computational linguistics

george a miller 1998 wordnet an electronic
lexical database mit press
kishore papineni salim roukos todd ward and
weijing zhu 2002 bleu a method for automatic evaluation of machine translation in
proceedings of 40th annual meeting of the association for computational linguistics pages
311318 philadelphia pennsylvania usa association for computational linguistics
alec radford jeffrey wu rewon child david
luan dario amodei and ilya sutskever 2019
language models are unsupervised multitask
learners openai blog 18
colin raffel noam shazeer adam roberts
katherine lee sharan narang michael matena
yanqi zhou wei li and peter j liu 2020 exploring the limits of transfer learning with a unified texttotext transformer journal of machine
learning research 21167
stephen roller emily dinan naman goyal da ju
mary williamson yinhan liu jing xu myle
ott kurt shuster eric m smith et al 2020
recipes for building an opendomain chatbot
arxiv preprint arxiv200413637
ananya b sai mithun das gupta mitesh m
khapra and mukundhan srinivasan 2019 reevaluating adem a deeper look at scoring dialogue responses in proceedings of the aaai
conference on artificial intelligence volume 33
pages 62206227
koustuv sinha prasanna parthasarathi jasmine
wang ryan lowe william l hamilton and
joelle pineau 2020 learning an unreferenced
metric for online dialogue evaluation in proceedings of the 58th annual meeting of the association for computational linguistics pages
24302441
ran tian shashi narayan thibault sellam and
ankur p parikh 2019 sticking to the facts
confident decoding for faithful datatotext generation arxiv preprint arxiv191008684
ashish vaswani noam shazeer niki parmar
jakob uszkoreit llion jones aidan n gomez
ukasz kaiser and illia polosukhin 2017 attention is all you need in advances in neural information processing systems pages 59986008

alex wang kyunghyun cho and mike lewis
2020 asking and answering questions to evaluate the factual consistency of summaries in proceedings of the 58th annual meeting of the association for computational linguistics pages
50085020
sean welleck jason weston arthur szlam and
kyunghyun cho 2019 dialogue natural language inference in proceedings of the 57th
annual meeting of the association for computational linguistics pages 37313741 florence
italy association for computational linguistics
adina williams nikita nangia and samuel bowman 2018 a broadcoverage challenge corpus
for sentence understanding through inference
in proceedings of the 2018 conference of the
north american chapter of the association for
computational linguistics human language
technologies volume 1 long papers pages
11121122 new orleans louisiana association for computational linguistics
thomas wolf victor sanh julien chaumond and
clement delangue 2019 transfertransfo a
transfer learning approach for neural network
based conversational agents arxiv preprint
arxiv190108149
saizheng zhang emily dinan jack urbanek
arthur szlam douwe kiela and jason weston
2018 personalizing dialogue agents i have a
dog do you have pets too in proceedings of
the 56th annual meeting of the association for
computational linguistics volume 1 long papers pages 22042213 melbourne australia
association for computational linguistics
yizhe zhang siqi sun michel galley yenchun
chen chris brockett xiang gao jianfeng gao
jingjing liu and bill dolan 2020 dialogpt
 largescale generative pretraining for conversational response generation in proceedings of
the 58th annual meeting of the association for
computational linguistics system demonstrations pages 270278 online association for
computational linguistics

